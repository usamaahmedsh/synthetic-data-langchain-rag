Ambisonics is a full-sphere surround sound format created by a group of English researchers — among them Michael A. Gerzon, Peter Barnes Fellgett, and John Stuart Wright — under support of the National Research Development Corporation (NRDC) of the United Kingdom. In addition to the horizontal plane, the format incorporates sound sources above and below the listener. The term is used as both a generic name and formerly as a trademark. 
Unlike some other multichannel surround formats, its transmission channels do not carry speaker signals. Instead, they contain a speaker-independent representation of a sound field called B-format, which is then decoded to the listener's speaker setup. This extra step allows the producer to think in terms of source directions rather than loudspeaker positions, and offers the listener a considerable degree of flexibility as to the layout and number of speakers used for playback.
Ambisonics was developed in the UK in the 1970s under the auspices of the British National Research Development Corporation.
Despite its solid technical foundation and many advantages, ambisonics had not until recently been a commercial success, and survived only in niche applications and among recording enthusiasts.
With the widespread availability of powerful digital signal processing (as opposed to the expensive and error-prone analog circuitry that had to be used during its early years) and the successful market introduction of home theatre surround sound systems since the 1990s, interest in ambisonics among recording engineers, sound designers, composers, media companies, broadcasters and researchers has returned and continues to increase.
In particular, it has proved an effective way to present spatial audio in Virtual Reality applications (e.g. YouTube 360 Video), as the B-Format scene can be rotated to match the user's head orientation, and then be decoded as binaural stereo.


== Introduction ==
Ambisonics can be understood as a three-dimensional extension of M/S (mid/side) stereo, adding additional difference channels for height and depth. The resulting signal set is called B-format. Its component channels are labelled 
  
    
      
        W
      
    
    {\displaystyle W}
  
 for the sound pressure (the M in M/S), 
  
    
      
        X
      
    
    {\displaystyle X}
  
 for the front-minus-back sound pressure gradient, 
  
    
      
        Y
      
    
    {\displaystyle Y}
  
 for left-minus-right (the S in M/S) and 
  
    
      
        Z
      
    
    {\displaystyle Z}
  
 for up-minus-down.
The 
  
    
      
        W
      
    
    {\displaystyle W}
  
 signal corresponds to an omnidirectional microphone, whereas 
  
    
      
        X
        Y
        Z
      
    
    {\displaystyle XYZ}
  
 are the components that would be picked up by figure-of-eight capsules oriented along the three spatial axes.


=== Panning a source ===
A simple Ambisonic panner (or encoder) takes a source signal 
  
    
      
        S
      
    
    {\displaystyle S}
  
 and two parameters, the horizontal angle 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 and the elevation angle 
  
    
      
        ϕ
      
    
    {\displaystyle \phi }
  
. It positions the source at the desired angle by distributing the signal over the Ambisonic components with different gains:

  
    
      
        W
        =
        S
        ⋅
        
          
            1
            
              2
            
          
        
      
    
    {\displaystyle W=S\cdot {\frac {1}{\sqrt {2}}}}
  

  
    
      
        X
        =
        S
        ⋅
        cos
        ⁡
        θ
        cos
        ⁡
        ϕ
      
    
    {\displaystyle X=S\cdot \cos \theta \cos \phi }
  

  
    
      
        Y
        =
        S
        ⋅
        sin
        ⁡
        θ
        cos
        ⁡
        ϕ
      
    
    {\displaystyle Y=S\cdot \sin \theta \cos \phi }
  

  
    
      
        Z
        =
        S
        ⋅
        sin
        ⁡
        ϕ
      
    
    {\displaystyle Z=S\cdot \sin \phi }
  

Being omnidirectional, the 
  
    
      
        W
      
    
    {\displaystyle W}
  
 channel always gets the same constant input signal, regardless of the angles. So that it has more-or-less the same average energy as the other channels, W is attenuated by about 3 dB (precisely, divided by the square root of two). The terms for 
  
    
      
        X
        Y
        Z
      
    
    {\displaystyle XYZ}
  
 actually produce the polar patterns of figure-of-eight microphones (see illustration on the right, second row). We take their value at 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 and 
  
    
      
        ϕ
      
    
    {\displaystyle \phi }
  
, and multiply the result with the input signal. The result is that the input ends up in all components exactly as loud as the corresponding microphone would have picked it up.


=== Virtual microphones ===

The B-format components can be combined to derive virtual microphones with any first-order polar pattern (omnidirectional, cardioid, hypercardioid, figure-of-eight or anything in between) pointing in any direction. Several such microphones with different parameters can be derived at the same time, to create coincident stereo pairs (such as a Blumlein) or surround arrays.

A horizontal virtual microphone at horizontal angle 
  
    
      
        Θ
      
    
    {\displaystyle \Theta }
  
 with pattern 
  
    
      
        0
        ≤
        p
        ≤
        1
      
    
    {\displaystyle 0\leq p\leq 1}
  
 is given by

  
    
      
        M
        (
        Θ
        ,
        p
        )
        =
        p
        
          
            2
          
        
        W
        +
        (
        1
        −
        p
        )
        (
        cos
        ⁡
        Θ
        X
        +
        sin
        ⁡
        Θ
        Y
        )
      
    
    {\displaystyle M(\Theta ,p)=p{\sqrt {2}}W+(1-p)(\cos \Theta X+\sin \Theta Y)}
  
.
This virtual mic is free-field normalised, which means it has a constant gain of one for on-axis sounds. The illustration on the left shows some examples created with this formula.
Virtual microphones can be manipulated in post-production: desired sounds can be picked out, unwanted ones suppressed, and the balance between direct and reverberant sound can be fine-tuned during mixing.


=== Decoding ===

A basic Ambisonic decoder is very similar to a set of virtual microphones. For perfectly regular layouts, a simplified decoder can be generated by pointing a virtual cardioid microphone in the direction of each speaker. Here is a square:

  
    
      
        L
        F
        =
        (
        
          
            2
          
        
        W
        +
        X
        +
        Y
        )
        
          
            8
          
        
      
    
    {\displaystyle LF=({\sqrt {2}}W+X+Y){\sqrt {8}}}
  

  
    
      
        L
        B
        =
        (
        
          
            2
          
        
        W
        −
        X
        +
        Y
        )
        
          
            8
          
        
      
    
    {\displaystyle LB=({\sqrt {2}}W-X+Y){\sqrt {8}}}
  

  
    
      
        R
        B
        =
        (
        
          
            2
          
        
        W
        −
        X
        −
        Y
        )
        
          
            8
          
        
      
    
    {\displaystyle RB=({\sqrt {2}}W-X-Y){\sqrt {8}}}
  

  
    
      
        R
        F
        =
        (
        
          
            2
          
        
        W
        +
        X
        −
        Y
        )
        
          
            8
          
        
      
    
    {\displaystyle RF=({\sqrt {2}}W+X-Y){\sqrt {8}}}
  

The signs of the 
  
    
      
        X
      
    
    {\displaystyle X}
  
 and 
  
    
      
        Y
      
    
    {\displaystyle Y}
  
 components are the important part, the rest are gain factors. The 
  
    
      
        Z
      
    
    {\displaystyle Z}
  
 component is discarded, because it is not possible to reproduce height cues with just four loudspeakers in one plane.
In practice, a real Ambisonic decoder requires a number of psycho-acoustic optimisations to work properly.
Currently, the All-Round Ambisonic Decoder (AllRAD) can be regarded as the standard solution for loudspeaker-based playback, and Magnitude Least Squares (MagLS) or binaural decoding, as implemented for instance in the IEM and SPARTA Ambisonic production tools.
Frequency-dependent decoding can also be used to produce binaural stereo; this is particularly relevant in Virtual Reality applications.


=== Higher-order ambisonics ===

The spatial resolution of first-order ambisonics as described above is quite low. In practice, that translates to slightly blurry sources, but also to a comparably small usable listening area or sweet spot. The resolution can be increased and the sweet spot enlarged by adding groups of more selective directional components to the B-format. These no longer correspond to conventional microphone polar patterns, but rather look like clover leaves. The resulting signal set is then called second-, third-, or collectively, higher-order ambisonics.
For a given order 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
  
, full-sphere systems require 
  
    
      
        (
        ℓ
        +
        1
        
          )
          
            2
          
        
      
    
    {\displaystyle (\ell +1)^{2}}
  
 signal components, and 
  
    
      
        2
        ℓ
        +
        1
      
    
    {\displaystyle 2\ell +1}
  
 components are needed for horizontal-only reproduction.

Historically there have been several different format conventions for higher-order ambisonics; for details see Ambisonic data exchange formats.


=== Comparison to other surround formats ===
Ambisonics differs from other surround formats in a number of aspects:

It requires only three channels for basic horizontal surround, and four channels for a full-sphere soundfield. Basic full-sphere replay requires a minimum of six loudspeakers (a minimum of four for horizontal).
The same program material can be decoded for varying numbers of loudspeakers. Moreover, a width-height mix can be played back on horizontal-only, stereo or even mono systems without losing content entirely (it will be folded to the horizontal plane and to the frontal quadrant, respectively). This allows producers to embrace with-height production without worrying about loss of information.
Ambisonics can be scaled to any desired spatial resolution at the cost of additional transmission channels and more speakers for playback. Higher-order material remains downwards compatible and can be played back at lower spatial resolution without requiring a special downmix.
The core technology of ambisonics is free of patents, and a complete tool chain for production and listening is available as free software for all major operating systems.
On the downside, ambisonics is:

Prone to strong coloration from comb filtering artifacts due to high coherence of neighbouring loudspeaker signals at lower orders
Unable to deliver the particular spaciousness of spaced omnidirectional microphones preferred by many classical sound engineers and listeners
Not supported by any major record label or media company. Although a number of Ambisonic UHJ format (UHJ) encoded tracks (principally classical) can be located, if with some difficulty, on services such as Spotify.
Conceptually difficult for people to grasp, as opposed to the conventional "one channel, one speaker" paradigm.
More complicated for the consumer to set up, because of the decoding stage.
Sweet spot which is not found in other forms of surround sound such as VBAP
Worse localisation for point sources than amplitude panning and counter phase signals blurring imaging
Much more sensitive to speaker placement than other forms of surround sound that use amplitude panning


== Theoretical foundation ==


=== Soundfield analysis (encoding) ===
The B-format signals comprise a truncated spherical harmonic decomposition of the sound field. They correspond to the sound pressure 
  
    
      
        W
      
    
    {\displaystyle W}
  
, and the three components of the pressure gradient 
  
    
      
        X
        Y
        Z
      
    
    {\displaystyle XYZ}
  
 (not to be confused with the related particle velocity) at a point in space. Together, these approximate the sound field on a sphere around the microphone; formally the first-order truncation of the multipole expansion. 
  
    
      
        W
      
    
    {\displaystyle W}
  
 (the mono signal) is the zero-order information, corresponding to a constant function on the sphere, while 
  
    
      
        X
        Y
        Z
      
    
    {\displaystyle XYZ}
  
 are the first-order terms (the dipoles or figures-of-eight). This first-order truncation is only an approximation of the overall sound field.
The higher orders correspond to further terms of the multipole expansion of a function on the sphere in terms of spherical harmonics. In practice, higher orders require more speakers for playback, but increase the spatial resolution and enlarge the area where the sound field is reproduced perfectly (up to an upper boundary frequency).
The radius 
  
    
      
        r
      
    
    {\displaystyle r}
  
 of this area for Ambisonic order 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
  
 and frequency 
  
    
      
        f
      
    
    {\displaystyle f}
  
 is given by

  
    
      
        r
        ≈
        
          
            
              ℓ
              c
            
            
              2
              π
              f
            
          
        
      
    
    {\displaystyle r\approx {\frac {\ell c}{2\pi f}}}
  
,
where 
  
    
      
        c
      
    
    {\displaystyle c}
  
 denotes the speed of sound.
This area becomes smaller than a human head above 600 Hz for first order or 1800 Hz for third-order. Accurate reproduction in a head-sized volume up to 20 kHz would require an order of 32 or more than 1000 loudspeakers.
At those frequencies and listening positions where perfect soundfield reconstruction is no longer possible, ambisonics reproduction has to focus on delivering correct directional cues to allow for good localisation even in the presence of reconstruction errors.


=== Psychoacoustics ===

The human hearing apparatus has very keen localisation on the horizontal plane (as fine as 2° source separation in some experiments). Two predominant cues, for different frequency ranges, can be identified:


==== Low-frequency localisation ====
At low frequencies, where the wavelength is large compared to the human head, an incoming sound diffracts around it, so that there is virtually no acoustic shadow and hence no level difference between the ears. In this range, the only available information is the phase relationship between the two ear signals, called interaural time difference, or ITD. Evaluating this time difference allows for precise localisation within a cone of confusion: the angle of incidence is unambiguous, but the ITD is the same for sounds from the front or from the back. As long as the sound is not totally unknown to the subject, the confusion can usually be resolved by perceiving the timbral front-back variations caused by the ear flaps (or pinnae).


==== High-frequency localisation ====
As the wavelength approaches twice the size of the head, phase relationships become ambiguous, since it is no longer clear whether the phase difference between the ears corresponds to one, two, or even more periods as the frequency goes up. Fortunately, the head will create a significant acoustic shadow in this range, which causes a slight difference in level between the ears. This is called the interaural level difference, or ILD (the same cone of confusion applies). Combined, these two mechanisms provide localisation over the entire hearing range.


==== ITD and ILD reproduction in ambisonics ====
Gerzon has shown that the quality of localisation cues in the reproduced sound field corresponds to two objective metrics: the length of the particle velocity vector 
  
    
      
        
          
            
              
                r
                
                  V
                
              
              →
            
          
        
      
    
    {\displaystyle {\vec {r_{V}}}}
  
 for the ITD, and the length of the energy vector 
  
    
      
        
          
            
              
                r
                
                  E
                
              
              →
            
          
        
      
    
    {\displaystyle {\vec {r_{E}}}}
  
 for the ILD. Gerzon and Barton (1992) define a decoder for horizontal surround to be Ambisonic if

the directions of 
  
    
      
        
          
            
              
                r
                
                  V
                
              
              →
            
          
        
      
    
    {\displaystyle {\vec {r_{V}}}}
  
 and 
  
    
      
        
          
            
              
                r
                
                  E
                
              
              →
            
          
        
      
    
    {\displaystyle {\vec {r_{E}}}}
  
 agree up to at least 4 kHz,
at frequencies below about 400 Hz, 
  
    
      
        ‖
        
          
            
              
                r
                
                  V
                
              
              →
            
          
        
        ‖
        =
        1
      
    
    {\displaystyle \|{\vec {r_{V}}}\|=1}
  
 for all azimuth angles, and
at frequencies from about 700 Hz to 4 kHz, the magnitude of 
  
    
      
        
          
            
              
                r
                
                  E
                
              
              →
            
          
        
      
    
    {\displaystyle {\vec {r_{E}}}}
  
 is "substantially maximised across as large a part of the 360° sound stage as possible".
In practice, satisfactory results are achieved at moderate orders even for very large listening areas.


==== Monoaural HRTF cue ====

Humans are also able to derive information about sound source location in 3D-space, taking into account height. Much of this ability is due to the shape of the head (especially the pinna) producing a variable frequency response depending on the angle of the source. The response can be measured by placing a microphone in a person's ear canal, then playing back sounds from various directions. The recorded head-related transfer function (HRTF) can then be used for rendering ambisonics to headphones, mimicking the effect of the head. HRTFs differ among person to person due to head shape variations, but a generic one can produce a satisfactory result.


=== Soundfield synthesis (decoding) ===
In principle, the loudspeaker signals are derived by using a linear combination of the Ambisonic component signals, where each signal is dependent on the actual position of the speaker in relation to the center of an imaginary sphere the surface of which passes through all available speakers. In practice, slightly irregular distances of the speakers may be compensated with delay.
True ambisonics decoding however requires spatial equalisation of the signals to account for the differences in the high- and low-frequency sound localisation mechanisms in human hearing. A further refinement accounts for the distance of the listener from the loudspeakers (near-field compensation).

A variety of more modern decoding methods are also in use.


== Compatibility with existing distribution channels ==
Ambisonics decoders are not currently being marketed to end users in any significant way, and no native Ambisonic recordings are commercially available. Hence, content that has been produced in ambisonics must be made available to consumers in stereo or discrete multichannel formats.


=== Stereo ===
Ambisonics content can be folded down to stereo automatically, without requiring a dedicated downmix. The most straightforward approach is to sample the B-format with a virtual stereo microphone. The result is equivalent to a coincident stereo recording. Imaging will depend on the microphone geometry, but usually rear sources will be reproduced more softly and diffuse. Vertical information (from the 
  
    
      
        Z
      
    
    {\displaystyle Z}
  
 channel) is omitted.
Alternatively, the B-format can be matrix-encoded into UHJ format, which is suitable for direct playback on stereo systems. As before, the vertical information will be discarded, but in addition to left-right reproduction, UHJ tries to retain some of the horizontal surround information by translating sources in the back into out-of-phase signals. This gives the listener some sense of rear localisation.
Two-channel UHJ can also be decoded back into horizontal ambisonics (with some loss of accuracy), if an Ambisonic playback system is available. Lossless UHJ up to four channels (including height information) exists but has never seen wide use. In all UHJ schemes, the first two channels are conventional left and right speaker feeds.


=== Multichannel formats ===
Likewise, it is possible to pre-decode ambisonics material to arbitrary speaker layouts, such as Quad, 5.1, 7.1, Auro 11.1, or even 22.2, again without manual intervention. The LFE channel is either omitted, or a special mix is created manually. Pre-decoding to 5.1 media has been known as G-Format during the early days of DVD audio, although the term is not in common use anymore.
The obvious advantage of pre-decoding is that any surround listener can be able to experience ambisonics; no special hardware is required beyond that found in a common home theatre system. The main disadvantage is that the flexibility of rendering a single, standard ambisonics signal to any target speaker array is lost: the signal is assumes a specific "standard" layout and anyone listening with a different array may experience a degradation of localisation accuracy.
Target layouts from 5.1 upwards usually surpass the spatial resolution of first-order ambisonics, at least in the frontal quadrant. For optimal resolution, to avoid excessive crosstalk, and to steer around irregularities of the target layout, pre-decodings for such targets should be derived from source material in higher-order ambisonics.


== Production workflow ==
Ambisonic content can be created in two basic ways: by recording a sound with a suitable first- or higher-order microphone, or by taking separate monophonic sources and panning them to the desired positions. Content can also be manipulated while it is in B-format.


=== Ambisonic microphones ===


==== Native B-format arrays ====

Since the components of first-order ambisonics correspond to physical microphone pickup patterns, it is entirely practical to record B-format directly, with three coincident microphones: an omnidirectional capsule, one forward-facing figure-8 capsule, and one left-facing figure-8 capsule, yielding the 
  
    
      
        W
      
    
    {\displaystyle W}
  
, 
  
    
      
        X
      
    
    {\displaystyle X}
  
 and 
  
    
      
        Y
      
    
    {\displaystyle Y}
  
 components. This is referred to as a native or Nimbus/Halliday microphone array, after its designer Dr Jonathan Halliday at Nimbus Records, where it is used to record their extensive and continuing series of Ambisonic releases. An integrated native B-format microphone, the C700S has been manufactured and sold by Josephson Engineering since 1990.
The primary difficulty inherent in this approach is that high-frequency localisation and clarity relies on the diaphragms approaching true coincidence. By stacking the capsules vertically, perfect coincidence for horizontal sources is obtained. However, sound from above or below will theoretically suffer from subtle comb filtering effects in the highest frequencies. In most instances this is not a limitation as sound sources far from the horizontal plane are typically from room reverberation. In addition, stacked figure-8 microphone elements have a deep null in the direction of their stacking axis such that the primary transducer in those directions is the central omnidirectional microphone. In practice this can produce less localisation error than either of the alternatives (tetrahedral arrays with processing, or a fourth microphone for the Z axis.)
Native arrays are most commonly used for horizontal-only surround, because of increasing positional errors and shading effects when adding a fourth microphone.


==== The tetrahedral microphone ====
Since it is impossible to build a perfectly coincident microphone array, the next-best approach is to minimize and distribute the positional error as uniformly as possible. This can be achieved by arranging four cardioid or sub-cardioid capsules in a tetrahedron and equalising for uniform diffuse-field response. The capsule signals are then converted to B-format with a matrix operation.
The Core Sound TetraMic  was the first commercially available A-format ambisonic microphone. Introduced in 2006, it uses four cardioid capsules. Each TetraMic is individually calibrated, and a calibration file and A- to B-format encoder plug-in are provided with each microphone. 

Outside ambisonics, tetrahedral microphones have become popular with location recording engineers working in stereo or 5.1 for their flexibility in post-production; here, the B-format is only used as an intermediate to derive virtual microphones.


==== Higher-order microphones ====
Above first-order, it is no longer possible to obtain Ambisonic components directly with single microphone capsules. Instead, higher-order difference signals are derived from several spatially distributed (usually omnidirectional) capsules using very sophisticated digital signal processing.
The Core Sound OctoMic  was the first commercially available second-order ambisonic microphone. Introduced in 2018, it uses eight cardioid capsules. Each OctoMic is individually calibrated, and a calibration file and A- to B-format encoder plug-in are provided with each microphone. 
The ZYLIA ZM-1 is a commercially available microphone capable of generating third-order ambisonic recordings, using 19 omni-directional capsules.
The em64 Eigenmike from mh acoustics is a 64-channel spherical microphone array capable of sixth-order capture. The production of the em64 has superseded their previous em32 microphone.
The spacemic from Harpex Audio GmbH is an 84-channel double-sided planar array. Current versions of its encoder as of late 2025 support fifth-order spherical capture.
A recent paper by Peter Craven et al. (subsequently patented) describes the use of bi-directional capsules for higher order microphones to reduce the extremity of the equalisation involved. No microphones have yet been made using this idea.


=== Ambisonic panning ===
The most straightforward way to produce Ambisonic mixes of arbitrarily high order is to take monophonic sources and position them with an Ambisonic encoder.
A full-sphere encoder usually has two parameters, azimuth (or horizon) and elevation angle. The encoder will distribute the source signal to the Ambisonic components such that, when decoded, the source will appear at the desired location. More sophisticated panners will additionally provide a radius parameter that will take care of distance-dependent attenuation and bass boost due to near-field effect.
Hardware panning units and mixers for first-order ambisonics have been available since the 1980s and have been used commercially. Today, panning plugins and other related software tools are available for all major digital audio workstations, often as free software. However, due to arbitrary bus width restrictions, few professional digital audio workstations (DAW) support orders higher than second. Notable exceptions are REAPER, Pyramix, ProTools, Nuendo and Ardour.


=== Ambisonic manipulation ===
First order B-format can be manipulated in various ways to change the contents of an auditory scene. Well known manipulations include "rotation" and "dominance" (moving sources towards or away from a particular direction).
Additionally, linear time-invariant signal processing such as equalisation can be applied to B-format without disrupting sound directions, as long as it applied to all component channels equally.
More recent developments in higher order ambisonics enable a wide range of manipulations including rotation, reflection, movement, 3D reverb, upmixing from legacy formats such as 5.1 or first order, visualisation and directionally-dependent masking and equalisation.


=== Data exchange ===
Transmitting Ambisonic B-format between devices and to end-users requires a standardized exchange format. While traditional first-order B-format is well-defined and universally understood, there are conflicting conventions for higher-order ambisonics, differing both in channel order and weighting, which might need to be supported for some time. Traditionally, the Furse-Malham (FuMa) higher order format in the .amb container based on Microsoft's WAVE-EX file format. It scales up to third order and has a file size limitation of 4GB.
The current B-format standard format is AmbiX proposal, which adopts the .caf file format and does away with the 4GB limit. It scales to arbitrarily high orders and is based on SN3D encoding. SN3D encoding has been adopted by Google as the basis for its YouTube 360 format.


=== Compressed distribution ===
To effectively distribute Ambisonic data to non-professionals, lossy compression is desired to keep the data size acceptable. However, simple multi-mono compression is not sufficient, as lossy compression tends to destroy phase information and thus degrade localization in the form of spatial reduction, blur, and phantom source. Reduction of redundancy among channels is desired, not only to enhance compression, but also to reduce the risk of dicernable phase errors. (It is also possible to use post-processing to hide the artifacts.)
As with mid-side joint stereo encoding, a static matrixing scheme (as in Opus) is usable for first-order ambisonics, but not optimal in case of multiple sources. A number of schemes such as DirAC use a scheme similar to parametric stereo, where a downmixed signal is encoded, the principal direction recorded, and some description of ambiance added. MPEG-H 3D Audio, drawing on some work from MPEG Surround, extends the concept to handle multiple sources. MPEG-H uses principal component analysis to determine the main sources and then encodes a multi-mono signal corresponding to the principal directions. These parametric methods provide good quality, so long as they take good care in smoothing sound directions among frames. PCA/SVD is applicable for first-order as well as high-order ambisonics input.


== Decoding ==

This section focusses on decoding of classic first-order ambisonics. The Ambisonic B-format WXYZ signals define what the listener should hear. How these signals are presented to the listener by the speakers for best results, depends on the number of speakers and their location. Ambisonics treats directions where no speakers are placed with as much importance as speaker positions. It is undesirable for the listener to be conscious that the sound is coming from a discrete number of speakers. Some simple decoding equations are known to give good results for common speaker arrangements.
But Ambisonic Speaker Decoders can use much more information about the position of speakers, including their exact position and distance from the listener. Because human beings use different mechanisms to locate sound, Classic Ambisonic Decoders it is desirable to modify the speaker feeds at each frequency to present the best information using Shelf Filters.
Some views on the complexities of Shelf Filters and Distance Compensation are explained in "Ambisonic Surround Decoders" and "SHELF FILTERS for Ambisonic Decoders".
There are specialised decoders for large audiences in large spaces.
Hardware decoders have been commercially available since the late 1970s; currently, ambisonics is standard in surround products offered by Meridian Audio, Ltd. Ad hoc software decoders are also available.
There are five main types of decoder:


=== Diametric decoders ===
This design is intended for a domestic, small room setting, and allows speakers to be arranged in diametrically opposed pairs.


=== Regular polygon decoders ===
This design is intended for a domestic, small room setting. The speakers are equidistant from the listener and lie equally spaced on the circumference of a circle. The simplest Regular Polygon decoder is a Square with the listener in the centre.  At least four speakers are required. Triangles do not work, exhibiting large "holes" between the speakers. Regular Hexagons perform better than Squares especially to the sides.
For the simplest (two dimensional) case (no height information), and spacing the loudspeakers equally in a circle, we derive the loudspeaker signals from the B-format W, X and Y channels:

  
    
      
        
          P
          
            n
          
        
        =
        W
        +
        X
        cos
        ⁡
        
          θ
          
            n
          
        
        +
        Y
        sin
        ⁡
        
          θ
          
            n
          
        
      
    
    {\displaystyle P_{n}=W+X\cos \theta _{n}+Y\sin \theta _{n}}
  

where 
  
    
      
        
          θ
          
            n
          
        
      
    
    {\displaystyle \theta _{n}}
  
 is the direction of the speaker under consideration.
The most useful of these is the Square 4.0 decoder.
The coordinate system used in ambisonics follows the right hand rule convention with positive X pointing forwards, positive Y pointing to the left and positive Z pointing upwards. Horizontal angles run anticlockwise from due front and vertical angles are positive above the horizontal, negative below.


=== Auditorium decoders ===
This design is intended for a large, public space setting.


=== "Vienna" decoders ===
These are so named because the paper introducing deriving Ambisonic Decoders for irregular loudspeaker layouts was presented at the 1992 AES conference held in Vienna. The design was covered by a 1998 patent. from Trifield Productions. The technology provides one approach to the decoding of ambisonic signals to irregular loudspeaker arrays (such as ITU) commonly used for 5.1 surround sound replay.  A slight flaw in the 1992 published papers decoder coefficients, and the use of heuristic search algorithms in order to solve the set of non-linear simultaneous equations needed to generate the decoders was published by Wiggins et al. in 2003, and later extended to higher order irregular decoders in 2004


=== Parametric decoders ===
The idea behind parametric decoding is to treat the sound's direction of incidence as a parameter that can be estimated through time–frequency analysis. A large body of research into human spatial hearing suggests that our auditory cortex applies similar techniques in its auditory scene analysis, which explains why these methods work.
The major benefits of parametric decoding is a greatly increased angular resolution and the separation of analysis and synthesis into separate processing steps. This separation allows B-format recordings to be rendered using any panning technique, including delay panning, VBAP and HRTF-based synthesis.
Parametric decoding was pioneered by Lake DSP in the late 1990s and independently suggested by Farina and Ugolotti in 1999. Later work in this domain includes the DirAC method and the Harpex method.


=== Irregular layout decoders ===
The Rapture3D decoder from Blue Ripple Sound supports this and is already used in a number of computer games using OpenAL.


== Current development ==


=== Open source ===
Since 2018 a free and open source implementation exists in the IEM Plugin Suite and the SPARTA suite that implement the recent academic developments and the sound codec Opus. Opus provides two channel encoding modes: one that simply stores channels individually, and another that weights the channels through a fixed, invertible matrix to reduce redundancy. A listening-test of Opus ambisonics was published in 2020, as calibration for AMBIQUAL, an objective metric for compressed ambisonics by Google. Opus third-order ambisonics at 256 kbps has similar localization accuracy compared to Opus first-order ambisonics at 128 kbps.


=== Corporate interest ===
Since its adoption by Google and other manufacturers as the audio format of choice for virtual reality, ambisonics has seen a surge of interest.
In 2018, Sennheiser released its VR microphone, and Zoom released an Ambisonics Field Recorder. Both are implementations of the tetrahedral microphone design which produces first order ambisonics.
A number of companies are currently conducting research in ambisonics:

BBC
Technicolor Research and Innovation/Thomson Licensing
Dolby Laboratories have expressed "interest" in ambisonics by acquiring (and liquidating) Barcelona-based ambisonics specialist imm sound prior to launching Dolby Atmos, which, although its precise workings are undisclosed, does implement decoupling between source direction and actual loudspeaker positions.  Atmos takes a fundamentally different approach in that it does not attempt to transmit a sound field; it transmits discrete premixes or stems (i.e., raw streams of sound data) along with metadata about what location and direction they should appear to be coming from. The stems are then decoded, mixed, and rendered in real time using whatever loudspeakers are available at the playback location.


=== Use in gaming ===
Higher-order ambisonics has found a niche market in video games developed by Codemasters. Their first game to use an Ambisonic audio engine was Colin McRae: DiRT, however, this only used ambisonics on the PlayStation 3 platform. Their game Race Driver: GRID extended the use of ambisonics to the Xbox 360 platform, and Colin McRae: DiRT 2 uses ambisonics on all platforms including the PC.
The recent games from Codemasters, F1 2010, Dirt 3, F1 2011 and Dirt: Showdown, use fourth-order ambisonics on faster PCs, rendered by Blue Ripple Sound's Rapture3D OpenAL driver and pre-mixed Ambisonic audio produced using Bruce Wiggins' WigWare Ambisonic Plug-ins.
OpenAL Soft [1], a free and open source implementation of the OpenAL specification, also uses ambisonics to render 3D audio. OpenAL Soft can often be used as a drop-in replacement for other OpenAL implementations, enabling  several games that use the OpenAL API to benefit from rendering audio with ambisonics.
For many games that do not make use of the OpenAL API natively, the use of a wrapper or a chain of wrappers can help to make these games indirectly use the OpenAL API. Ultimately, this leads to the sound being rendered in ambisonics if a capable OpenAL driver such as OpenAL Soft is being used.
The Unreal Engine supports soundfield ambisonics rendering since version 4.25. The Unity engine supports working with ambisonics audio clips since version 2017.1.


== Patents and trademarks ==
Most of the patents covering Ambisonic developments have now expired (including those covering the Soundfield microphone) and, as a result, the basic technology is available for anyone to implement.
The "pool" of patents comprising ambisonics technology was originally assembled by the UK Government's National Research & Development Corporation (NRDC), which existed until the late 1970s to develop and promote British inventions and license them to commercial manufacturers – ideally to a single licensee. The system was ultimately licensed to Nimbus Records (now owned by Wyastone Estate Ltd).
The "interlocking circles" Ambisonic logo (UK trademarks UK00001113276 and UK00001113277), and the text marks "AMBISONIC" and "A M B I S O N" (UK trademarks UK00001500177 and UK00001112259), formerly owned by Wyastone Estate Ltd., have expired as of 2010.


== See also ==
Ambisonic reproduction systems
Ambisonic decoding
Ambisonic UHJ Format
Gaussian splatting
List of Ambisonic hardware
Meridian Audio, Ltd., manufacturer of hardware decoders
Nimbus Records
Soundfield microphone


== Notes ==


== References ==


== External links ==
Ambisonic.net website
Ambisonia, a repository of Ambisonic recordings and compositions
Ambisonic.info, website of Ambisonic field recordist Paul Hodges
Ambisonics resources at the University of Parma
Ambisonic resources at the University of York
Higher Order Ambisonic Technical Notes at Blue Ripple Sound
Ambisonics on Xiph wiki, a resource aimed at file format developers
Europe's (Annual) Student 3D Audio Production Competition S3DAPC, 2017-


=== Decoders ===
Ambisonic Surround Sound FAQ (Sections 17 and 18 for hardware decoders)
Ambisonia website Bruce Wiggins's WAD decoders for 4.0, 6.0 and 8.0 are nearly Classic Ambisonic Decoders and easy to use plugins for Windows Media Player.
B2X Plug-Ins B2D, B2G and B2Stereo software decoders, in VST and Audio Unit formats, for Mac OS X
Shelf Filters and Distance Compensation "Ambisonic Surround Decoder" and "SHELF FILTERS for Ambisonic Decoders" explain these important features of Classic Ambisonic Decoders for those designing software decoders
Harpex Ltd (for stand-alone and plug-in versions of the Harpex method)
Blue Ripple Sound Limited Rapture3D and TOA regular and irregular speaker decoders, binaural stereo and more.