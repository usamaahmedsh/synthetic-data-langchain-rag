A Likert scale ( LIK-ərt,) is a psychometric scale named after its inventor, American social psychologist Rensis Likert, which is commonly used in research questionnaires.  It is the most widely used approach to scaling responses in survey research, such that the term (or more fully the Likert-type scale) is often used interchangeably with rating scale, although there are other types of rating scales.
Likert distinguished between a scale proper, which emerges from collective responses to a set of items (usually eight or more), and the format in which responses are scored along a range. Technically speaking, a Likert scale refers only to the former. The difference between these two concepts has to do with the distinction Likert made between the underlying phenomenon being investigated and the means of capturing variation that points to the underlying phenomenon.
When responding to a Likert item, respondents specify their level of agreement or disagreement on a symmetric agree-disagree scale for a series of statements. Thus, the range captures the intensity of their feelings for a given item.
A scale can be created as the simple sum or average of questionnaire responses over the set of individual items (questions). In so doing, Likert scaling assumes distances between each choice (answer option) are equal. Many researchers employ a set of such items that are highly correlated (that show high internal consistency) but also that together will capture the full domain under study (which requires less-than perfect correlations). Others hold to a standard by which "All items are assumed to be replications of each other or in other words items are considered to be parallel instruments". By contrast, modern test theory treats the difficulty of each item (the ICCs) as information to be incorporated in scaling items.


== Composition ==

A Likert scale is the sum of responses on several Likert items.  Because many Likert scales pair each constituent Likert item with its own instance of a visual analogue scale (e.g., a horizontal line, on which the subject indicates a response by circling or checking tick-marks), an individual item is itself sometimes erroneously referred to as being or having a scale, with this error creating pervasive confusion in the literature and parlance of the field.
A Likert item is simply a statement that the respondent is asked to evaluate by giving it a quantitative value on any kind of subjective or objective dimension, with level of agreement/disagreement being the dimension most commonly used.  Well-designed Likert items exhibit both "symmetry" and "balance". Symmetry means that they contain equal numbers of positive and negative positions whose respective distances apart are bilaterally symmetric about the "neutral"/zero value (whether or not that value is presented as a candidate). Balance means that the distance between each candidate value is the same, allowing for quantitative comparisons such as averaging to be valid across items containing more than two candidate values.
The format of a typical five-level Likert item, for example, could be:

Strongly disagree
Disagree
Neither agree nor disagree
Agree
Strongly agree
Likert scaling is a bipolar scaling method, measuring either positive or negative response to a statement. Sometimes an even-point scale is used, where the middle option of "neither agree nor disagree" is not available. This is sometimes called a "forced choice" method, since the neutral option is removed. The neutral option can be seen as an easy option to take when a respondent is unsure, and so whether it is a true neutral option is questionable. A 1987 study found negligible differences between the use of "undecided" and "neutral" as the middle option in a five-point Likert scale.
 Likert scales may be subject to distortion from several causes. Respondents may:

Avoid using extreme response categories (central tendency bias), especially out of a desire to avoid being perceived as having extremist views (an instance of social desirability bias). This effect may appear early in a test due to an expectation that questions which the subject has stronger views on may follow, such that on earlier questions one "leaves room" for stronger responses later in the test. This expectation creates bias that is especially pernicious in that its effects are not uniform throughout the test and cannot be corrected for through simple across-the-board normalization;
Agree with statements as presented (acquiescence bias), for example, agreeing with both Statement A, and its opposite. This effect is especially strong among children, people with developmental disabilities, elderly people, and individuals who are subjected to a culture of institutionalization that encourages and incentivizes eagerness to please;
Disagree with sentences as presented out of a defensive desire to avoid making erroneous statements and/or avoid negative consequences that respondents may fear will result from their answers being used against them, especially if misinterpreted and/or taken out of context;
Provide answers that they believe will be evaluated as indicating strength or lack of weakness/dysfunction ("faking good");
Provide answers that they believe will be evaluated as indicating weakness or presence of impairment/pathology ("faking bad");
Try to portray themselves or their organization in a light that they believe the examiner or society to consider more favorable than their true beliefs (social desirability bias, the intersubjective version of objective "faking good" discussed above);
Try to portray themselves or their organization in a light that they believe the examiner or society to consider less favorable/more unfavorable than their true beliefs (norm defiance, the intersubjective version of objective "faking bad" discussed above).
Designing a scale with balanced keying (an equal number of positive and negative statements and, especially, an equal number of positive and negative statements regarding each position or issue in question) can obviate the problem of acquiescence bias, since acquiescence on positively keyed items will balance acquiescence on negatively keyed items, but defensive, central tendency, and social desirability biases are somewhat more problematic.


== Scoring and analysis ==
After the questionnaire is completed, each item may be analyzed separately or in some cases item responses may be summed to create a score for a group of items. Hence, Likert scales are often called summative scales.
Whether individual Likert items can be considered as interval-level data, or whether they should be treated as ordered-categorical data is the subject of considerable disagreement in the literature, with strong convictions on what are the most applicable methods.  This disagreement can be traced back, in many respects, to the extent to which Likert items are interpreted as being ordinal data.
Two primary considerations guide the discussion. First, Likert scales are arbitrary. The value assigned to a Likert item has no objective numerical basis, either in terms of measure theory or scale (from which a distance metric can be determined).  The value assigned to each Likert item is simply determined by the researcher designing the survey, who makes the decision based on a desired level of detail. By convention, however, Likert items tend to be assigned progressive positive integer values. Likert scales typically range from 2 to 10 – with 3, 5, or, 7 being the most common. Furthermore, the progressive structure of the scale is such that each successive Likert item is treated as indicating a 'better' response than the preceding value. This can differ in cases where reverse ordering of the Likert scale is needed.
The second, and possibly more important point, is whether the "distance" between each successive item category is equivalent, which is traditionally inferred or assumed. For example, in the above five-point Likert item, the inference or assumption is that the 'distance' between category 1 and 2 is the same as between category 3 and 4. In terms of good research practice, an equidistant presentation by the researcher is important; otherwise, a bias in the analysis can result. For example, a four-point Likert item with categories "Poor", "Average", "Good", and "Very Good" is unlikely to have all equidistant categories, since only one category can receive a below-average rating. This would arguably bias any result in favor of a positive outcome. On the other hand, even if a researcher presents what they believe to be equidistant categories, the respondent might well interpret it differently.
A good Likert scale, as above, will present a symmetry of categories about a midpoint, with clearly defined linguistic qualifiers. In such symmetric scaling, equidistant attributes will typically be more clearly observed or, at least, inferred. When a Likert scale is symmetric and equidistant, it will behave more like an interval-level measurement. So, while a Likert scale is indeed ordinal, if well-presented it can nevertheless approximate an interval-level measurement. This can be beneficial since, if it were treated just as an ordinal scale, then some valuable information could be lost if the 'distance' between Likert items were not available for consideration. The important idea here is that the appropriate type of analysis is dependent on how the Likert scale has been presented.
The validity of such measures depends on the underlying interval nature of the scale. If interval nature is assumed for a comparison of two groups, the paired samples t-test is not inappropriate. If non-parametric tests are to be performed, the Pratt (1959) modification to the Wilcoxon signed-rank test is recommended over the standard Wilcoxon signed-rank test.
Responses to several Likert questions can be summed providing that all questions use the same Likert scale and that the scale is a defensible approximation to an interval scale, in which case the central limit theorem allows treatment of the data as interval data measuring a latent variable. If the summed responses fulfill these assumptions, parametric statistical tests such as the analysis of variance can be applied. Typical cutoffs for thinking that this approximation will be acceptable is a minimum of four and preferably eight items in the sum.
To model binary Likert responses directly, they can be represented in a binomial form by summing agree and disagree responses separately. The chi-squared, Cochran's Q test, or McNemar test are common statistical procedures used after this transformation. Non-parametric tests, such as chi-squared test, Mann–Whitney test, Wilcoxon signed-rank test, or Kruskal–Wallis test, are often used in the analysis of Likert scale data.
Alternatively, Likert scale responses can be analyzed with an ordered probit model, preserving the ordering of responses without the assumption of an interval scale. The use of an ordered probit model can prevent errors that arise when treating ordered ratings as interval-level measurements. Consensus-based assessment (CBA) can be used to create an objective standard for Likert scales in domains where no generally accepted or objective standard exists. Consensus-based assessment (CBA) can be used to refine or even validate generally accepted standards.


=== Latent variable models ===
A common practice for analyzing responses to collections of Likert scale items is to summarize them via a latent variable model, for example by using factor analysis or item response theory.


==== Rasch model ====
Likert scale data can, in principle, be used as a basis for obtaining interval level estimates on a continuum by applying the polytomous Rasch model, when data can be obtained that fit this model. In addition, the polytomous Rasch model permits testing of the hypothesis that the statements reflect increasing levels of an attitude or trait, as intended. For example, application of the model often indicates that the neutral category does not represent a level of attitude or trait between the disagree and agree categories.
Not every set of Likert scaled items can be used for Rasch measurement. The data has to be thoroughly checked to fulfill the strict formal axioms of the model. However, the raw scores are the sufficient statistics for the Rasch measures, a deliberate choice by Georg Rasch, so, if you are prepared to accept the raw scores as valid, then you can also accept the Rasch measures as valid.


=== Visual presentation of Likert-type data ===
An important part of data analysis and presentation is the visualization (or plotting) of data.  The subject of plotting Likert (and other) rating data is discussed at length in two papers by Robbins and Heiberger.
In the first paper, Robbins and Heiberger recommend the use of what they call diverging stacked bar charts and compare them to other plotting styles.
The second paper describes the use of the Likert function in the HH package for R, and gives many examples of its use.
Another paper by Koo and Yang also provides Python code showing how to create a clustered diverging stacked bar chart of 5-point Likert scale responses.


== Level of measurement ==
The five response categories are often believed to represent an interval level of measurement. However, this can only be the case if the intervals between the scale points correspond to empirical observations in a metric sense. Reips and Funke (2008) show that this criterion is much better met by a visual analogue scale. In fact, there may also appear phenomena which even question the ordinal scale level in Likert scales. For example, in a set of items A, B, C rated with a Likert scale circular relations like A > B, B > C and C > A can appear. This violates the axiom of transitivity for the ordinal scale.
Research by Labovitz and Traylor provide evidence that, even with rather large distortions of perceived distances between scale points, Likert-type items perform closely to scales that are perceived as equal intervals.  So these items and other equal-appearing scales in questionnaires are robust to violations of the equal distance assumption many researchers believe are required for parametric statistical procedures and tests.


== Pronunciation ==
Rensis Likert, the developer of the scale, pronounced his name  LIK-ərt.  (That is, LICK-ert, as opposed to LIKE-ert.) Some have claimed that Likert's name "is among the most mispronounced in [the] field", because many people pronounce the name of the scale as  LY-kərt.


== See also ==
Borg scale – Scale of perceived exertion
Bogardus social distance scale – Scale measuring a person's willingness to engage with various types of people
Diamond of opposites – Plot used in psychodrama groups
Discan scale – Scale and method in clinical psychology
K-factor – Standardized psychometric measure of psychopathology and personality
Guttman scale – Single, ordinal psychometric scale
Ipsative – Attribute of a survey scoring scale
Mokken scale
Phrase completion scales – Psychometric scale used in questionnaires
Questionnaire – Series of questions for gathering information
Questionnaire construction – Design of a questionnaire to gather statistically useful information about a given topic
Rating scale – Type of informational measurement scale
Rating sites – Websites allowing users to rate people, content, or other things.
Rosenberg self-esteem scale – Self-report questionnaire
Satisficing – Cognitive heuristic of searching for an acceptable decision
Semantic differential – Empirical method used in Linguistics
Thurstone scale – First formal technique to measure an attitude
Voting system – Method by which voters make a choice between options


== Notes ==


== References ==


== External links ==
Trochim, William M. K. (October 20, 2006). "Likert Scaling". Research Methods Knowledge Base, 2nd Edition. Retrieved April 30, 2009.
Galili, Tal (2010-04-07). "Correlation scatter-plot matrix for ordered-categorical data". R-statistics blog. Retrieved November 7, 2017.
Uebersax, John S. Likert scales: Dispelling the confusion. 2006.
Jebb, A. T., Ng, V., & Tay, L. (2021). A Review of Key Likert Scale Development Advances: 1995–2019. Frontiers in Psychology, 12, 637547. https://doi.org/10.3389/fpsyg.2021.637547