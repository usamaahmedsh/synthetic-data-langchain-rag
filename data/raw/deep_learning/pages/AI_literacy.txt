AI literacy or artificial intelligence literacy is "a set of competencies that enables individuals to critically evaluate AI technologies; communicate and collaborate effectively with AI; and use AI as a tool online, at home, and in the workplace." 
AI is employed in a variety of applications, including self-driving automobiles, virtual assistants and text generation by generative AI models. Users of these tools should be able to make informed decisions. AI literacy may have an impact on students' future employment prospects.
With the rise of generative AI platforms, AI literacy has become a topic of conversation in the field of education. Some think AI literacy is essential for school and college students, while others restrict or prohibit the use of AI in assignments, viewing it as a form of academic dishonesty. However, many researchers and educational institutions promote a more nuanced approach, encouraging critical engagement with AI while developing policies that balance academic integrity with opportunities for learning.  


== Definitions ==
Other definitions of AI literacy include the ability to understand, use, monitor, and critically reflect on AI applications. That use of the term usually refers to teaching skills and knowledge to the general public, particularly those who are not adept in AI and the ability to understand, use, evaluate, and ethically navigate AI. As research into AI literacy is still emerging and focused on developing context-specific skills, there is not yet a single, broadly agreed-upon definition.
AI literacy is linked to other forms of literacy. AI literacy requires digital literacy, whereas scientific and computational literacy may inform it. Data literacy also significantly overlaps with it.


== Categories ==
AI literacy encompasses multiple categories, including a theoretical understanding of how artificial intelligence works, the usage of artificial intelligence technologies, and the critical appraisal of artificial intelligence, and its ethics.


=== Know and understand AI ===
Knowledge and understanding of AI refers to a basic understanding of what artificial intelligence is and how it works. This includes familiarity with machine learning algorithms and the limitations and biases present in AI systems. Users who know and understand AI should be familiar with various technologies that use artificial intelligence, including cognitive systems, robotics and machine learning. This includes recognizing that large language models (LLMs) are statistical systems trained on extensive datasets which produce outputs rather than retrieving existing information like a search engine.


=== Use and apply AI ===
Using and applying AI refers to the ability to use AI tools to solve problems and perform tasks such as programming and analyzing big data. Some consider prompt engineering, the practice of designing effective prompts to guide generative AI platforms more effectively, as another competency within AI literacy. 


=== Evaluate and create AI ===
Evaluation and creation refers to the ability to critically evaluate the quality and reliability of AI systems. It also refers to designing and building fair and ethical AI systems. To evaluate correctly, users should also learn in which areas AI is strong, and in which areas it is weak.


=== AI ethics ===
AI ethics refers to understanding the moral implications of AI, and the making informed decisions regarding the use of AI tools. This area includes considerations such as:

Accountability: Hold AI actors accountable for the operation of AI systems and adherence to ethical ideals.
Accuracy: Identify and report sources of error and uncertainty in algorithms and data.
Auditability: Enable other parties to audit and assess algorithm behavior via transparent information sharing.
Explainability: Make sure that algorithmic judgments and the underlying data can be presented in simple language.
Fairness: Prevent biases and consider varied viewpoints. To do so, increase the diversity of researchers in the field.
Human Centricity and Well-being: Prioritize human well-being in AI development and deployment.
Human rights Alignment: Ensure that technology do not infringe internationally recognized human rights.
Inclusivity: Make AI accessible to everyone.
Progress: Choose high value initiatives.
Responsibility, accountability, and transparency: Foster trust via responsibility, accountability, and fairness.
Robustness and Security: Make AI systems safe, secure, and resistant to manipulation or data breach.
Sustainability: Choose implementations that generate long-term, useful benefits.


=== Enabling AI ===
Support AI by developing associated knowledge and skills such as programming and statistics.


== Promoting AI literacy ==
Several governments have recognized the need to promote AI literacy, including among adults. Such programs have been published in the United States, China, Germany and Finland. Programs intended for the general public usually consist of short and easy to understand online study units. Programs intended for children are usually project-based. Programs for students at colleges and universities often address the specific professional needs of the student, depending on their field of study. Beyond the education system, AI literacy can also be developed in the community, for example in museums.


=== Schools ===
Schools use diverse pedagogies to promote AI literacy. These include:

Performing a Turing test with an intelligent agent
Creating chatbots
Building apps using Blockly-based programming
Project-based learning
Building robots
Data visualization
Training AI models
Artificial intelligence curricula can improve students' understanding of topics such as machine learning, neural networks, and deep learning.


==== Case study: DAILy ====
The DAILy (Developing AI Literacy) program was developed by MIT and Boston University with the goal of increasing AI literacy among middle school students. The program is structured as a 30-hour workshop that includes the topics of introduction to artificial intelligence, logical systems (decision trees), supervised learning, neural networks, computational learning, deepfake, and natural language generators. Students examine the moral and social implications of each topic, as well as its occupational implications.


=== Higher education ===
Before the second decade of the 21st century, artificial intelligence was studied mainly in STEM courses. Later, projects emerged to increase artificial intelligence education, specifically to promote AI literacy. Most courses start with one or more study units that deal with basic questions such as what artificial intelligence is, where it comes from, what it can do and what it can't do. Most courses also refer to machine learning and deep learning. Some of the courses deal with moral issues in artificial intelligence.


==== Disciplinary policy ====
As a response to the increase of generative AI use in education, several disciplines formed committees or task forces to examine context-specific approaches toward AI literacy. In spring 2025, the Modern Language Association and Conference on College Composition and Communication Joint Task Force finished development of three working papers, a guide on AI literacy for students, and a collection of resources addressing AI use in writing. The task force emphasized the need for “a culture of critical AI literacy” and included guidelines not only for students but also educators and institutions, highlighting the need for modeling ethical AI use in planning processes.    
Similarly, a committee formed by the American Historical Association Council published “Guiding Principles for Artificial Intelligence in History Education” which encouraged “clear and transparent engagement with generative AI.” The guidelines demonstrate the value of criticality when working with generative AI in thinking and research.  


== See also ==
Artificial intelligence
Digital literacy
Ethics of artificial intelligence


== References ==


== External links ==
Times Higher Education: How can we teach AI literacy skills?