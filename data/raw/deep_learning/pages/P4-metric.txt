The P4 metric
 (also known as FS or Symmetric F ) enables performance evaluation of a binary classifier.
The P4 metric is calculated from precision, recall, specificity, and NPV (negative predictive value).
The definition of the P4 metric is similar to that of the F1 metric, however the P4 metric definition addresses criticisms leveled against the definition of the F1 metric. The definition of the P4 metric may, therefore, be understood as an extension of the F1 metric.
Like the other known metrics, the P4 metric is a function of: TP (true positives), TN (true negatives), FP (false positives), FN (false negatives).


== Justification ==
The key concept of the P4 metric is to leverage the four key conditional probabilities:

  
    
      
        P
        (
        +
        ∣
        C
        
          +
        
        )
      
    
    {\displaystyle P(+\mid C{+})}
  
 — the probability that the sample is positive, provided the classifier result was positive.

  
    
      
        P
        (
        C
        
          +
        
        ∣
        +
        )
      
    
    {\displaystyle P(C{+}\mid +)}
  
 — the probability that the classifier result will be positive, provided the sample is positive.

  
    
      
        P
        (
        C
        
          −
        
        ∣
        −
        )
      
    
    {\displaystyle P(C{-}\mid -)}
  
 — the probability that the classifier result will be negative, provided the sample is negative.

  
    
      
        P
        (
        −
        ∣
        C
        
          −
        
        )
      
    
    {\displaystyle P(-\mid C{-})}
  
 — the probability the sample is negative, provided the classifier result was negative.
The main assumption behind this metric is that all the probabilities mentioned above are close to 1 for a properly designed binary classifier. Indeed, 
  
    
      
        
          
            P
          
          
            4
          
        
        =
        1
      
    
    {\displaystyle \mathrm {P} _{4}=1}
  
 if, and only if, all of the probabilities above are equal to 1. Another important feature is that 
  
    
      
        
          
            P
          
          
            4
          
        
      
    
    {\displaystyle \mathrm {P} _{4}}
  
 tends to zero any of the above probabilities tend to zero.


== Definition ==
P4 is defined as a harmonic mean of four key conditional probabilities:

  
    
      
        
          
            P
          
          
            4
          
        
        =
        
          
            4
            
              
                
                  1
                  
                    P
                    (
                    +
                    ∣
                    C
                    
                      +
                    
                    )
                  
                
              
              +
              
                
                  1
                  
                    P
                    (
                    C
                    
                      +
                    
                    ∣
                    +
                    )
                  
                
              
              +
              
                
                  1
                  
                    P
                    (
                    C
                    
                      −
                    
                    ∣
                    −
                    )
                  
                
              
              +
              
                
                  1
                  
                    P
                    (
                    −
                    ∣
                    C
                    
                      −
                    
                    )
                  
                
              
            
          
        
        =
        
          
            4
            
              
                
                  1
                  
                    p
                    r
                    e
                    c
                    i
                    s
                    i
                    o
                    n
                  
                
              
              +
              
                
                  1
                  
                    r
                    e
                    c
                    a
                    l
                    l
                  
                
              
              +
              
                
                  1
                  
                    s
                    p
                    e
                    c
                    i
                    f
                    i
                    c
                    i
                    t
                    y
                  
                
              
              +
              
                
                  1
                  
                    N
                    P
                    V
                  
                
              
            
          
        
        .
      
    
    {\displaystyle \mathrm {P} _{4}={\frac {4}{{\frac {1}{P(+\mid C{+})}}+{\frac {1}{P(C{+}\mid +)}}+{\frac {1}{P(C{-}\mid -)}}+{\frac {1}{P(-\mid C{-})}}}}={\frac {4}{{\frac {1}{\mathit {precision}}}+{\frac {1}{\mathit {recall}}}+{\frac {1}{\mathit {specificity}}}+{\frac {1}{\mathit {NPV}}}}}.}
  

In terms of TP,TN,FP,FN it can be calculated as follows:

  
    
      
        
          
            P
          
          
            4
          
        
        =
        
          
            
              4
              ⋅
              
                T
                P
              
              ⋅
              
                T
                N
              
            
            
              4
              ⋅
              
                T
                P
              
              ⋅
              
                T
                N
              
              +
              (
              
                T
                P
              
              +
              
                T
                N
              
              )
              ⋅
              (
              
                F
                P
              
              +
              
                F
                N
              
              )
            
          
        
        .
      
    
    {\displaystyle \mathrm {P} _{4}={\frac {4\cdot \mathrm {TP} \cdot \mathrm {TN} }{4\cdot \mathrm {TP} \cdot \mathrm {TN} +(\mathrm {TP} +\mathrm {TN} )\cdot (\mathrm {FP} +\mathrm {FN} )}}.}
  


== Evaluation of the binary classifier performance ==
Evaluating the performance of binary classifiers is a multidisciplinary concept. It spans from the evaluation of medical tests, psychiatric tests to machine learning classifiers from a variety of fields. Thus, many of the metrics in use exist under several names, some defined independently.


== Properties of P4 metric ==
Symmetry — contrasting to the F1 metric, P4 is symmetrical. It means - it does not change its value when dataset labeling is changed - positives named negatives and negatives named positives.
Range: 
  
    
      
        
          
            P
          
          
            4
          
        
        ∈
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle \mathrm {P} _{4}\in [0,1]}
  
.
Achieving 
  
    
      
        
          
            P
          
          
            4
          
        
        ≈
        1
      
    
    {\displaystyle \mathrm {P} _{4}\approx 1}
  
 requires all the key four conditional probabilities being close to 1.
For 
  
    
      
        
          
            P
          
          
            4
          
        
        ≈
        0
      
    
    {\displaystyle \mathrm {P} _{4}\approx 0}
  
 it is sufficient that one of the key four conditional probabilities is close to 0.


== Examples, comparing with the other metrics ==
Dependency table for selected metrics ("true" means depends, "false" - does not depend): 

Metrics that do not depend on a given probability are prone to misrepresentation when the probability approaches 0.


=== Example 1: Rare disease detection test ===
Let us consider a medical test used to detect a rare disease. Suppose a population size of 100000 and 0.05% of the population is infected. Further suppose the following test performance: 95% of all positive individuals are classified correctly (TPR=0.95) and 95% of all negative individuals are classified correctly (TNR=0.95).
In such a case, due to high population imbalance and in spite of having high test accuracy (0.95), the probability that an individual who has been classified as positive is in fact positive is very low: 

  
    
      
        P
        (
        +
        ∣
        C
        
          +
        
        )
        =
        0.0095.
      
    
    {\displaystyle P(+\mid C{+})=0.0095.}
  

We can observe how this low probability is reflected in some of the metrics:

  
    
      
        
          
            P
          
          
            4
          
        
        =
        0.0370
      
    
    {\displaystyle \mathrm {P} _{4}=0.0370}
  
,

  
    
      
        
          
            F
          
          
            1
          
        
        =
        0.0188
      
    
    {\displaystyle \mathrm {F} _{1}=0.0188}
  
,

  
    
      
        
          J
        
        =
        
          0.9100
        
      
    
    {\displaystyle \mathrm {J} =\mathbf {0.9100} }
  
 (Informedness / Youden index),

  
    
      
        
          M
          K
        
        =
        0.0095
      
    
    {\displaystyle \mathrm {MK} =0.0095}
  
 (Markedness).


=== Example 2: Image recognition — cats vs dogs ===
Consider the problem of training a neural network based image classifier with only two types of images: those containing dogs (labeled as 0) and those containing cats (labeled as 1). Thus, the goal is to distinguish between the cats and dogs. Suppose that the classifier overpredicts in favour of cats ("positive" samples): 99.99% of cats are classified correctly and only 1% of dogs are classified correctly. Further, suppose that the image dataset consists of 100000 images, 90% of which are pictures of cats and 10% are pictures of dogs. In this situation, the probability that the picture containing dog will be classified correctly is pretty low:

  
    
      
        P
        (
        C
        −
        
          |
        
        −
        )
        =
        0.01.
      
    
    {\displaystyle P(C-|-)=0.01.}
  

Not all metrics are notice this low probability:

  
    
      
        
          
            P
          
          
            4
          
        
        =
        0.0388
      
    
    {\displaystyle \mathrm {P} _{4}=0.0388}
  
,

  
    
      
        
          
            F
          
          
            1
          
        
        =
        
          0.9478
        
      
    
    {\displaystyle \mathrm {F} _{1}=\mathbf {0.9478} }
  
,

  
    
      
        
          J
        
        =
        0.0099
      
    
    {\displaystyle \mathrm {J} =0.0099}
  
 (Informedness / Youden index),

  
    
      
        
          M
          K
        
        =
        
          0.8183
        
      
    
    {\displaystyle \mathrm {MK} =\mathbf {0.8183} }
  
 (Markedness).


== See also ==
F-score
Informedness
Markedness
Matthews correlation coefficient
Precision and Recall
Sensitivity and Specificity
NPV
Confusion matrix


== References ==