Open-source artificial intelligence is an AI system that is freely available to use, study, modify, and share. This includes datasets used to train the model, its code, and model parameters, promoting a collaborative and transparent approach to AI development. Free and open-source software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.
The open-source model provides wider access to AI technology, allowing more individuals and organizations to participate in AI research and development. In contrast, closed-source artificial intelligence is proprietary, restricting access to the source code and internal components. Companies often develop closed products in an attempt to keep a competitive advantage in the marketplace. However, some experts suggest that open-source AI tools may have a development advantage over closed-source products and have the potential to overtake them in the marketplace.
Popular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots. For software developers to produce open-source artificial intelligence (AI) resources, they must trust the various other open-source software components they use in its development. Open-source AI software has been speculated to have potentially increased risk compared to closed-source AI as bad actors may remove safety protocols of public models as they wish. Similarly, closed-source AI has also been speculated to have an increased risk compared to open-source AI due to issues of dependence, privacy, opaque algorithms, corporate control and limited availability while potentially slowing beneficial innovation.
There also is a debate about the openness of AI systems as openness is differentiated – an article in Nature suggests that some systems presented as open, such as Meta's Llama 3, "offer little more than an API or the ability to download a model subject to distinctly non-open use restrictions". Such software has been criticized as "openwashing" systems that are better understood as closed. There are some works and frameworks that assess the openness of AI systems as well as a definition by the Open Source Initiative about what constitutes open source AI. Some large language models are released as open-weight, which means that their trained parameters are publicly available, even if the training code and data are not.


== History ==

The history of open-source artificial intelligence is intertwined with both the development of AI technologies and the growth of the open-source software movement. Open-source AI has evolved significantly over the past few decades, with contributions from various academic institutions, research labs, tech companies, and independent developers. This section explores the major milestones in the development of open-source AI, from its early days to its current state.


=== 1990s: Early development of AI and open-source software ===
The concept of AI dates back to the mid-20th century, when computer scientists like Alan Turing and John McCarthy laid the groundwork for modern AI theories and algorithms. An early form of AI, the natural language processing "doctor" ELIZA, was re-implemented and shared in 1977 by Jeff Shrager as a BASIC program, and soon translated to many other languages. Early AI research focused on developing symbolic reasoning systems and rule-based expert systems.
During this period, the idea of open-source software was beginning to take shape, with pioneers like Richard Stallman advocating for free software as a means to promote collaboration and innovation in programming. The Free Software Foundation, founded in 1985 by Stallman, was one of the first major organizations to promote the idea of software that could be freely used, modified, and distributed. The ideas from this movement eventually influenced the development of open-source AI, as more developers began to see the potential benefits of open collaboration in software creation, including AI models and algorithms.
In the 1990s, open-source software began to gain more traction, the rise of machine learning and statistical methods also led to the development of more practical AI tools. In 1993, the CMU Artificial Intelligence Repository was initiated, with a variety of openly shared software.


=== 2000s: Emergence of open-source AI ===
In the early 2000s open-source AI began to take off, with the release of more user-friendly foundational libraries and frameworks that were available for anyone to use and contribute to.
OpenCV was released in 2000 with a variety of traditional AI algorithms like decision trees, k-Nearest Neighbors (kNN), Naive Bayes and Support Vector Machines (SVM).
In 2007, Scikit-learn was released. It became one of the most widely used libraries for general-purpose machine learning due to its ease of use and robust functionality, providing implementations of common algorithms like regression, classification, and clustering. Theano was also released in the same year.


=== Rise of open-source AI frameworks (2010s) ===
Open-source deep learning framework as Torch was released in 2002 and made open-source with Torch7 in 2011, and was later augmented by PyTorch, and TensorFlow.
AlexNet was released in 2012.


=== Open-source and open-weights generative AI (2020s–Present) ===
With the announcement of GPT-2, OpenAI originally planned to keep the source code of their models private citing concerns about malicious applications. After OpenAI faced public backlash, however, it released the source code for GPT-2 to GitHub three months after its release. OpenAI did not publicly release the source code or pretrained weights for the GPT-3 model. At the time of GPT-3's release GPT-2 was still the most powerful open source language model in the world. for open source competitors like EleutherAI. 2022 also saw the rise of larger and more powerful models under licenses of varying openness including Meta's OPT.
The Open Source Initiative consulted experts over two years to create a definition of "open-source" that would fit the needs of AI software and models. The most controversial aspect relates to data access, since some models are trained on sensitive data which can't be released. In 2024, they published the Open Source AI Definition 1.0 (OSAID 1.0). It requires full release of the software for processing the data, training the model and making inferences from the model. For the data, it only requires access to details about the data used to train the AI so others can understand and re-create it.
In 2023, Llama 1 and 2 and Mistral AI's Mistral and Mixtral open-weight models were first released, along with MosaicML's MPT open-source model. 
In 2024, Meta released a collection of large AI models, including Llama 3.1 405B, which was competitive with less open models. The company claimed its approach to AI would be open-source, differing from other major tech companies. The Open Source Initiative and others stated that Llama is not open-source despite Meta describing it as open-source, due to Llama's software license prohibiting it from being used for some purposes.
DeepSeek released their V3 LLM in December 2024, and their R1 reasoning model on January 20, 2025, both as open-weights models under the MIT license.
Since the release of OpenAI's proprietary ChatGPT model in late 2022, there have been only a few fully open (weights, data, code, etc.) large language models released. In September 2025, a Swiss consortium added to this short list by releasing a fully open model named Apertus. Latam-GPT, an open Latin America-focused model, launched in 2025 as a regional effort that trains primarily Spanish and Portuguese-language content.


== Applications ==


=== Healthcare ===

In the healthcare industry, open-source AI has been used in diagnostics, patient care, and personalized treatment options. Open-source libraries have been used for medical imaging for tasks such as tumor detection, improving the speed and accuracy of diagnostic processes. Additionally, OpenChem, an open-source library specifically geared toward chemistry and biology applications, enables the development of predictive models for drug discovery, helping researchers identify potential compounds for treatment.


=== Military ===

Meta's Llama models, which have been described as open-source by Meta, were adopted by U.S. defense contractors like Lockheed Martin and Oracle after unauthorized adaptations by Chinese researchers affiliated with the People's Liberation Army (PLA) came to light. The Open Source Initiative and others have contested Meta's use of the term open-source to describe Llama, due to Llama's license containing an acceptable use policy that prohibits use cases including non-U.S. military use. Chinese researchers used an earlier version of Llama to develop tools like ChatBIT, optimized for military intelligence and decision-making, prompting Meta to expand its partnerships with U.S. contractors to ensure the technology could be used strategically for national security. These applications now include logistics, maintenance, and cybersecurity enhancements.


== Benefits ==


=== Privacy and independence ===
A Nature editorial suggests medical care could become dependent on AI models that could be taken down at any time, are difficult to evaluate, and may threaten patient privacy. Its authors propose that health-care institutions, academic researchers, clinicians, patients and technology companies worldwide should collaborate to build open-source models for health care of which the underlying code and base models are easily accessible and can be fine-tuned freely with own data sets.


=== Collaboration and faster advancements ===
Large-scale collaborations, such as those seen in the development of open-source frameworks like TensorFlow and PyTorch, have accelerated advancements in machine learning (ML) and deep learning. The open-source nature of these platforms also facilitates rapid iteration and improvement, as contributors from across the globe can propose modifications and enhancements to existing tools.
Beyond enhancements directly within ML and deep learning, this collaboration can lead to faster advancements in the products of AI, as shared knowledge and expertise are pooled together. By sharing code, data, and research findings, open-source AI enables collective problem-solving and innovation.


=== Democratizing access ===
Open-source AI democratizes access to cutting-edge tools, lowering entry barriers for individuals and smaller organizations that may lack resources. By making these technologies freely available, open-source AI allows developers to innovate and create AI solutions that might have been otherwise inaccessible due to financial constraints, enabling independent developers and researchers, smaller organizations, and startups to utilize advanced AI models without the financial burden of proprietary software licenses. This affordability encourages innovation in niche or specialized applications, as developers can modify existing models to meet unique needs.


=== Equitable development ===
The openness of the development process encourages diverse contributions, making it possible for underrepresented groups to shape the future of AI. This inclusivity not only fosters a more equitable development environment but also helps to address biases that might otherwise be overlooked by larger, profit-driven corporations. With contributions from a broad spectrum of perspectives, open-source AI has the potential to create more fair, accountable, and impactful technologies that better serve global communities.


=== Transparency and obscurity ===

One key benefit of open-source AI is the increased transparency it offers compared to closed-source alternatives. With open-source models, the underlying algorithms and code are accessible for inspection, which promotes accountability and helps developers understand how a model reaches its conclusions. Additionally, open-weight models, such as Llama and Stable Diffusion, allow developers to directly access model parameters, potentially facilitating the reduced bias and increased fairness in their applications. This transparency can help create systems with human-readable outputs, or "explainable AI", which is a growingly key concern, especially in high-stakes applications such as healthcare, criminal justice, and finance, where the consequences of decisions made by AI systems can be significant.


== Concerns ==


=== Quality and security ===
Open-source AI may allow bioterrorism groups like Aum Shinrikyo to remove fine-tuning and other safeguards of AI models to get AI to help develop more devastating terrorist schemes. In July 2024, the United States released a presidential report saying it did not find sufficient evidence to restrict revealing model weights at that time.
Once an open-source model is public, it cannot be rolled back or updated if serious security issues are detected. The main barrier to developing real-world terrorist schemes lies in stringent restrictions on necessary materials and equipment. Furthermore, the rapid pace of AI advancement makes it less appealing to use older models, which are more vulnerable to attacks but also less capable.


=== Equity, social, and ethical implications ===
There have been numerous cases of artificial intelligence leading to unintentionally biased products. Some notable examples include AI software predicting higher risk of future crime and recidivism for African-Americans when compared to white individuals, voice recognition models performing worse for non-native speakers, and facial-recognition models performing worse for women and darker-skinned individuals.
Researchers have also criticized open-source artificial intelligence for existing security and ethical concerns. An analysis of over 100,000 open-source models on Hugging Face and GitHub using code vulnerability scanners like Bandit, FlawFinder, and Semgrep found that over 30% of models have high-severity vulnerabilities. Furthermore, closed models typically have fewer safety risks than open-sourced models. The freedom to augment open-source models has led to developers releasing models without ethical guidelines, such as GPT4-Chan.


=== Data quality ===
There are numerous systemic problems that may contribute to inequitable and biased AI outcomes, stemming from causes such as biased data, flaws in model creation, and failing to recognize or plan for the possibility of these outcomes. As highlighted in research, poor data quality—such as the underrepresentation of specific demographic groups in datasets—and biases introduced during data curation lead to skewed model outputs.
A study of open-source AI projects revealed a failure to scrutinize for data quality, with less than 28% of projects including data quality concerns in their documentation. This study also showed a broader concern that developers do not place enough emphasis on the ethical implications of their models, and even when developers do take ethical implications into consideration, these considerations overemphasize certain metrics (behavior of models) and overlook others (data quality and risk-mitigation steps).


=== Transparency and "black boxes" ===
Another key concern with many AI systems with respect to issues such as safety and bias is their lack of transparency. Many open-source AI models operate as "black boxes", where their decision-making process is not easily understood, even by their creators. This lack of interpretability can hinder accountability, making it difficult to identify why a model made a particular decision or to ensure it operates fairly across diverse groups.
Furthermore, when AI models are closed-source (proprietary), this can facilitate biased systems slipping through the cracks, as was the case for numerous widely adopted facial recognition systems. These hidden biases can persist when those proprietary systems fail to publicize anything about the decision process which could help reveal those biases, such as confidence intervals for decisions made by AI. Especially for systems like those used in healthcare, being able to see and understand systems' reasoning or getting "an [accurate] explanation" of how an answer was obtained is "crucial for ensuring trust and transparency".


== See also ==

Explainable artificial intelligence
Artificial intelligence in Wikimedia projects
Lists of open-source artificial intelligence software


== References ==


== External links ==
Is keeping AI closed source safer and better for society than open sourcing AI?, interactive argument map on Kialo