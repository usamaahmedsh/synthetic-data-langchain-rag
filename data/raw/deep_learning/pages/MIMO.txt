Multiple-input and multiple-output (MIMO) () is a wireless technology that multiplies the capacity of a radio link using multiple transmit and receive antennas. MIMO has become a core technology for broadband wireless communications, including mobile standards—4G WiMAX (802.16 e, m), and 3GPP 4G LTE and 5G NR, as well as Wi-Fi standards, IEEE 802.11n, ac, and ax.
MIMO uses the spatial dimension to increase link capacity. The technology requires multiple antennas at both the transmitter and receiver, along with associated signal processing, to deliver data rate speedups roughly proportional to the number of antennas at each end.
MIMO starts with a high-rate data stream, which is de-multiplexed into multiple, lower-rate streams. Each of these streams is then modulated and transmitted in parallel with different coding from the transmit antennas, with all streams in the same frequency channel. These co-channel, mutually interfering streams arrive at the receiver's antenna array, each having a different spatial signature—gain phase pattern at the receiver’s antennas. These distinct array signatures allow the receiver to separate these co-channel streams, demodulate them, and re-multiplex them to reconstruct the original high-rate data stream. This process is sometimes referred to as spatial multiplexing.
The key to MIMO is the sufficient differences in the spatial signatures of the different streams to enable their separation. This is achieved through a combination of angle spread of the multipaths and sufficient spacing between antenna elements. In environments with a rich multipath and high angle spread, common in cellular and Wi-Fi deployments, an antenna element spacing at each end of just a few wavelengths can suffice. However, in the absence of significant multipath spread, larger element spacing (wider angle separation) is required at either the transmit array, the receive array, or at both.


== History ==


=== Early research in multiple antennas ===
MIMO is often traced back to 1970s research papers concerning multi-channel digital transmission systems and interference (crosstalk) between wire pairs in a cable bundle: AR Kaye and DA George (1970), Branderburg and Wyner (1974), and W. van Etten (1975, 1976). Although these are not examples of exploiting multipath propagation to send multiple information streams, some of the mathematical techniques for dealing with mutual interference proved useful to MIMO development. In the mid-1980s Jack Salz at Bell Laboratories took this research a step further, investigating multi-user systems operating over "mutually cross-coupled linear networks with additive noise sources" such as time-division multiplexing and dually-polarized radio systems.
Methods were developed to improve the performance of cellular radio networks and enable more aggressive frequency reuse in the early 1990s. Space-division multiple access (SDMA) uses directional or smart antennas to communicate on the same frequency with users in different locations within range of the same base station. An SDMA system was proposed by Richard Roy and Björn Ottersten, researchers at ArrayComm, in 1991. Their US patent (No. 5515378 issued in 1996) describes a method for increasing capacity using "an array of receiving antennas at the base station" with a "plurality of remote users."


=== MIMO invention ===
In December 1991, while working on a DARPA project involving signal separation algorithms at Stanford University, Arogyaswami Paulraj discovered that signals from two phones held in one hand could be separated using a three-element receive antenna array in a rich multipath environment. This discovery led to the foundational patent on MIMO, filed in February 1992 with Professor Thomas Kailath as a co-inventor. The patent proposed a method for increasing data rates on MIMO links in proportion to the number of antennas used.
While Paulraj’s patent initially emphasized applications in broadcast TV, which he believed would be an early adopter of the technology, it also proposed broader uses for MIMO in cellular communications. Paulraj joined Stanford faculty in 1993, where he built a research group on MIMO. Later in 1998 and 2004, he founded two startups (Iospan Wireless, and Beceem Communications) to commercialize MIMO for mobile networks.
Paulraj has received many recognitions for his work. These include the Royal Academy of Engineering (RAE) Prince Philip Medal, the Institution of Engineering and Technology (IET) Faraday Medal, the IEEE Alexander G. Bell Medal, the Marconi Prize, and induction into the U.S. Patent and Trademark Office's National Inventors Hall of Fame.


=== MIMO advancements ===
In 1995, G. Foschini and Michael Gans of Bell Labs wrote influential papers on MIMO wireless capacity and proposed the BLAST (Bell Labs Layered Space-Time) scheme to layer MIMO data streams and maximize channel capacity. Foschini received the IEEE Alexander Graham Bell Medal.
Many other key publications followed, significantly advancing the field: G. Raleigh and V. Jones introduced space-time methods. E. Telatar established the fundamental capacity limits of MIMO channels. S. Alamouti developed a simple but effective transmit diversity scheme that has been widely adopted. R. Calderbank et al. made crucial contributions to the development of space-time codes. H. Sampath et al. described the first MIMO-OFDM cellular system developed by Iospan Wireless. R. Heath advanced the areas of limited feedback and multi-user MIMO systems.
A torrent of research has followed, and as of 2024, there are over 450,000 research publications on MIMO technology and more than 570,000 global patent publications referencing MIMO or its related techniques.


=== MIMO commercialization ===


==== Mobile networks ====

Iospan Wireless in late 1998 to develop a MIMO-OFDM physical layer based cellular system was Iospan Wireless in late 1998). Iospan’s product (Airburst) consisted of a core network, base stations, and CPE terminals. Airburst did not initially support  mobile handovers. The system was trialed in Santa Clara during 2000-2002 and underwent a  customer trial  in Dubai in 2002. Following the 2001 collapse of the Dot-Com bubble, Iospan could not raise additional venture funding and was acquired by Intel in 2003. Intel integrated Iospan’s MIMO-OFDM  technology into the WiMAX broadband mobile standard, IEEE 802.16e standard in 2004.
In the early 2000s, several semiconductor companies also entered the MIMO-OFDM-based WiMAX technology market. They included Sequans, Samsung, Intel, Alvarion, and Beceem Communications,  who developed modem semiconductors for WiMAX  phones. Beceem gained 65% share of the global market, and was acquired by  Broadcom Corp.
The 3rd Generation Partnership Project (3GPP) standards body adopted MIMO for HSPA+ (Release 7) in 20XX and MIMO-OFDM based 4G Long Term Evolution (LTE) (Release 8) in 2008. MIMO-OFDM has since remained the core technology since 2008 for mobile networks, including 5G NR.
5G added native support for MU-MIMO.


==== WiFi networks ====
In the early 2000s, several companies—Atheros, Cisco, Broadcom, Intel, and Airgo Networks—entered the MIMO‑OFDM Wi‑Fi semiconductor market. Due to competing proposals within the IEEE 802.11, the first MIMO‑OFDM Wi‑Fi standard (802.11n) was not finalized until 2009. Several pre-standard products were developed, but market grew only after the 802.11n standard  was ratified. Airgo Networks was acquired by Qualcomm in December 2006, and Atheros was also acquired by Qualcomm in May 2011. Sequans did an IPO in 2011 and Alviron filed for bankruptcy in 2013.
Wi-Fi 6 added native support for MU-MIMO.


==== MIMO economic impact ====
Currently, 4G/5G and Wi-Fi powered by MIMO enable approximately 70% of internet-based services, accounting for 10% of global GDP. The GSMA industry alliance estimated the global economic value of mobile networks at $5.7 trillion, and the WiFi alliance estimated the corresponding value for WiFi networks at $3.5 trillion in 2023.


== Functions ==
MIMO can be sub-divided into three main categories: precoding, spatial multiplexing (SM), and diversity coding.
Precoding is multi-stream beamforming, in the narrowest definition. In more general terms, it is considered to be all spatial processing that occurs at the transmitter. In (single-stream) beamforming, the same signal is emitted from each of the transmit antennas with appropriate phase and gain weighting such that the signal power is maximized at the receiver input. The benefits of beamforming are to increase the received signal gain – by making signals emitted from different antennas add up constructively – and to reduce the multipath fading effect. In line-of-sight propagation, beamforming results in a well-defined directional pattern. However, conventional beams are not a good analogy in cellular networks, which are mainly characterized by multipath propagation. When the receiver has multiple antennas, the transmit beamforming cannot simultaneously maximize the signal level at all of the receive antennas, and precoding with multiple streams is often beneficial. Precoding requires knowledge of channel state information (CSI) at the transmitter and the receiver.
Spatial multiplexing requires MIMO antenna configuration. In spatial multiplexing, a high-rate signal is split into multiple lower-rate streams and each stream is transmitted from a different transmit antenna in the same frequency channel. If these signals arrive at the receiver antenna array with sufficiently different spatial signatures and the receiver has accurate CSI, it can separate these streams into (almost) parallel channels. Spatial multiplexing is a very powerful technique for increasing channel capacity at higher signal-to-noise ratios (SNR). The maximum number of spatial streams is limited by the lesser of the number of antennas at the transmitter or receiver. Spatial multiplexing can be used without CSI at the transmitter, but can be combined with precoding if CSI is available. Spatial multiplexing can also be used for simultaneous transmission to multiple receivers, known as space-division multiple access or multi-user MIMO, in which case CSI is required at the transmitter. The scheduling of receivers with different spatial signatures allows good separability.
Diversity coding techniques are used when there is no channel knowledge at the transmitter. In diversity methods, a single stream (unlike multiple streams in spatial multiplexing) is transmitted, but the signal is coded using techniques called space-time coding. The signal is emitted from each of the transmit antennas with full or near orthogonal coding. Diversity coding exploits the independent fading in the multiple antenna links to enhance signal diversity. Because there is no channel knowledge, there is no beamforming or array gain from diversity coding. Diversity coding can be combined with spatial multiplexing when some channel knowledge is available at the receiver.


== Forms ==


=== Multi-antenna types ===
Multi-antenna MIMO (or single-user MIMO) technology has been developed and implemented in some standards, e.g., 802.11n products.

SISO/SIMO/MISO are special cases of MIMO.
Multiple-input single-output (MISO) is a special case when the receiver has a single antenna.
Single-input multiple-output (SIMO) is a special case when the transmitter has a single antenna.
Single-input single-output (SISO) is a conventional radio system where neither transmitter nor receiver has multiple antennas.
Principal single-user MIMO techniques
Bell Laboratories Layered Space-Time (BLAST), Gerard. J. Foschini (1996)
Per Antenna Rate Control (PARC), Varanasi, Guess (1998), Chung, Huang, Lozano (2001)
Selective Per Antenna Rate Control (SPARC), Ericsson (2004)
Some limitations
The physical antenna spacing is selected to be large; multiple wavelengths at the base station. The antenna separation at the receiver is heavily space-constrained in handsets, though advanced antenna design and algorithm techniques are under discussion. Refer to: multi-user MIMO


=== Multi-user types ===

Multi-user MIMO (MU-MIMO)
In recent 3GPP and WiMAX standards, MU-MIMO is being treated as one of the candidate technologies adoptable in the specification by a number of companies, including Samsung, Intel, Qualcomm, Ericsson, TI, Huawei, Philips, Nokia, and Freescale. For these and other firms active in the mobile hardware market, MU-MIMO is more feasible for low-complexity cell phones with a small number of reception antennas, whereas single-user SU-MIMO's higher per-user throughput is better suited to more complex user devices with more antennas.
Enhanced multiuser MIMO employs advanced decoding and precoding techniques
SDMA represents either space-division multiple access or super-division multiple access where super emphasises that orthogonal division such as frequency- and time-division is not used but non-orthogonal approaches such as superposition coding are used.
Cooperative MIMO (CO-MIMO)
Uses multiple neighboring base stations to jointly transmit/receive data to/from users. As a result, neighboring base stations don't cause intercell interference as in the conventional MIMO systems.
Macrodiversity MIMO
A form of space diversity scheme which uses multiple transmit or receive base stations for communicating coherently with single or multiple users which are possibly distributed in the coverage area, in the same time and frequency resource.
The transmitters are far apart in contrast to traditional microdiversity MIMO schemes such as single-user MIMO. In a multi-user macrodiversity MIMO scenario, users may also be far apart. Therefore, every constituent link in the virtual MIMO link has distinct average link SNR. This difference is mainly due to the different long-term channel impairments such as path loss and shadow fading which are experienced by different links.
Macrodiversity MIMO schemes pose unprecedented theoretical and practical challenges. Among many theoretical challenges, perhaps the most fundamental challenge is to understand how the different average link SNRs affect the overall system capacity and individual user performance in fading environments.
MIMO routing
Routing a cluster by a cluster in each hop, where the number of nodes in each cluster is larger or equal to one. MIMO routing is different from conventional (SISO) routing since conventional routing protocols route node-by-node in each hop.
Massive MIMO (mMIMO)
A technology where the number of terminals is much less than the number of base station (mobile station) antennas. In a rich scattering environment, the full advantages of the massive MIMO system can be exploited using simple beamforming strategies such as maximum ratio transmission (MRT), maximum ratio-combining (MRC) or zero forcing (ZF). To achieve these benefits of massive MIMO, accurate CSI must be available perfectly. However, in practice, the channel between the transmitter and receiver is estimated from orthogonal pilot sequences which are limited by the coherence time of the channel. Most importantly, in a multicell setup, the reuse of pilot sequences of several co-channel cells will create pilot contamination. When there is pilot contamination, the performance of massive MIMO degrades quite drastically. To alleviate the effect of pilot contamination, Tadilo E. Bogale and Long B. Le propose a simple pilot assignment and channel estimation method from limited training sequences. However, in 2018, research by Emil Björnson, Jakob Hoydis, and Luca Sanguinetti was published which shows that pilot contamination is solvable and that the capacity of a channel can always be increased, both in theory and in practice, by increasing the number of antennas.
Holographic MIMO
Another recent technology is holographic MIMO to realize high energy and spectral efficiency with very high spatial resolution. Holographic MIMO is a key conceptual key enabler that is recently gaining increasing popularity, because of its low-cost transformative wireless structure consisting of sub-wavelength metallic or dielectric scattering particles, which is capable of deforming electromagnetic wave properties, according to some desirable objectives.


== Applications ==

Third generation (3G) (CDMA and UMTS) allows for implementing space-time transmit diversity schemes, in combination with transmit beamforming at base stations. Fourth generation (4G) LTE And LTE Advanced define very advanced air interfaces extensively relying on MIMO techniques. LTE primarily focuses on single-link MIMO relying on spatial multiplexing and space-time coding while LTE-Advanced further extends the design to multi-user MIMO. In wireless local area networks (WLAN), the IEEE 802.11n (Wi-Fi), MIMO technology is implemented in the standard using three different techniques: antenna selection, space-time coding and possibly beamforming.
Spatial multiplexing techniques make the receivers very complex, and therefore they are typically combined with orthogonal frequency-division multiplexing (OFDM) or with orthogonal frequency-division multiple access (OFDMA) modulation, where the problems created by a multi-path channel are handled efficiently. The IEEE 802.16e standard incorporates MIMO-OFDMA. The IEEE 802.11n standard, released in October 2009, recommends MIMO-OFDM.
MIMO is used in mobile radio telephone standards such as 3GPP and 3GPP2. In 3GPP, High-Speed Packet Access plus (HSPA+) and Long Term Evolution (LTE) standards take MIMO into account. Moreover, to fully support cellular environments, MIMO research consortia including IST-MASCOT propose to develop advanced MIMO techniques, e.g., multi-user MIMO (MU-MIMO).
MIMO wireless communications architectures and processing techniques can be applied to sensing problems. This is studied in a sub-discipline called MIMO radar.
MIMO technology can be used in non-wireless communications systems. One example is the home networking standard ITU-T G.9963, which defines a powerline communications system that uses MIMO techniques to transmit multiple signals over multiple AC wires (phase, neutral and ground).


== Mathematical description ==

In MIMO systems, a transmitter sends multiple streams by multiple transmit antennas. The transmit streams go through a matrix channel which consists of all 
  
    
      
        
          N
          
            t
          
        
        
          N
          
            r
          
        
      
    
    {\displaystyle N_{t}N_{r}}
  
 paths between the 
  
    
      
        
          N
          
            t
          
        
      
    
    {\displaystyle N_{t}}
  
 transmit antennas at the transmitter and 
  
    
      
        
          N
          
            r
          
        
      
    
    {\displaystyle N_{r}}
  
 receive antennas at the receiver. Then, the receiver gets the received signal vectors by the multiple receive antennas and decodes the received signal vectors into the original information. A narrowband flat fading MIMO system is modeled as:

  
    
      
        
          y
        
        =
        
          H
        
        
          x
        
        +
        
          n
        
      
    
    {\displaystyle \mathbf {y} =\mathbf {H} \mathbf {x} +\mathbf {n} }
  

where 
  
    
      
        
          y
        
      
    
    {\displaystyle \mathbf {y} }
  
 and 
  
    
      
        
          x
        
      
    
    {\displaystyle \mathbf {x} }
  
 are the receive and transmit vectors, respectively, and 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
 and 
  
    
      
        
          n
        
      
    
    {\displaystyle \mathbf {n} }
  
 are the channel matrix and the noise vector, respectively.

Referring to information theory, the ergodic channel capacity of MIMO systems where both the transmitter and the receiver have perfect instantaneous channel state information is

  
    
      
        
          C
          
            
              p
              e
              r
              f
              e
              c
              t
              −
              C
              S
              I
            
          
        
        =
        E
        
          [
          
            
              max
              
                
                  Q
                
                ;
                
                
                  
                    tr
                  
                
                (
                
                  Q
                
                )
                ≤
                1
              
            
            
              log
              
                2
              
            
            ⁡
            det
            
              (
              
                
                  I
                
                +
                ρ
                
                  H
                
                
                  Q
                
                
                  
                    H
                  
                  
                    H
                  
                
              
              )
            
          
          ]
        
        =
        E
        
          [
          
            
              log
              
                2
              
            
            ⁡
            det
            
              (
              
                
                  I
                
                +
                ρ
                
                  D
                
                
                  S
                
                
                  D
                
              
              )
            
          
          ]
        
      
    
    {\displaystyle C_{\mathrm {perfect-CSI} }=E\left[\max _{\mathbf {Q} ;\,{\mbox{tr}}(\mathbf {Q} )\leq 1}\log _{2}\det \left(\mathbf {I} +\rho \mathbf {H} \mathbf {Q} \mathbf {H} ^{H}\right)\right]=E\left[\log _{2}\det \left(\mathbf {I} +\rho \mathbf {D} \mathbf {S} \mathbf {D} \right)\right]}
  

where 
  
    
      
        (
        
          )
          
            H
          
        
      
    
    {\displaystyle ()^{H}}
  
 denotes Hermitian transpose and 
  
    
      
        ρ
      
    
    {\displaystyle \rho }
  
 is the ratio between transmit power and noise power (i.e., transmit SNR). The optimal signal covariance 
  
    
      
        
          Q
        
        =
        
          
            V
            S
            V
          
          
            H
          
        
      
    
    {\displaystyle \mathbf {Q} =\mathbf {VSV} ^{H}}
  
 is achieved through singular value decomposition of the channel matrix 
  
    
      
        
          
            U
            D
            V
          
          
            H
          
        
        
        =
        
        
          H
        
      
    
    {\displaystyle \mathbf {UDV} ^{H}\,=\,\mathbf {H} }
  
 and an optimal diagonal power allocation matrix 
  
    
      
        
          S
        
        =
        
          
            diag
          
        
        (
        
          s
          
            1
          
        
        ,
        …
        ,
        
          s
          
            min
            (
            
              N
              
                t
              
            
            ,
            
              N
              
                r
              
            
            )
          
        
        ,
        0
        ,
        …
        ,
        0
        )
      
    
    {\displaystyle \mathbf {S} ={\textrm {diag}}(s_{1},\ldots ,s_{\min(N_{t},N_{r})},0,\ldots ,0)}
  
. The optimal power allocation is achieved through waterfilling, that is

  
    
      
        
          s
          
            i
          
        
        =
        
          
            (
            
              μ
              −
              
                
                  1
                  
                    ρ
                    
                      d
                      
                        i
                      
                      
                        2
                      
                    
                  
                
              
            
            )
          
          
            +
          
        
        ,
        
        
          
            for
          
        
        
        
        i
        =
        1
        ,
        …
        ,
        min
        (
        
          N
          
            t
          
        
        ,
        
          N
          
            r
          
        
        )
        ,
      
    
    {\displaystyle s_{i}=\left(\mu -{\frac {1}{\rho d_{i}^{2}}}\right)^{+},\quad {\textrm {for}}\,\,i=1,\ldots ,\min(N_{t},N_{r}),}
  

where 
  
    
      
        
          d
          
            1
          
        
        ,
        …
        ,
        
          d
          
            min
            (
            
              N
              
                t
              
            
            ,
            
              N
              
                r
              
            
            )
          
        
      
    
    {\displaystyle d_{1},\ldots ,d_{\min(N_{t},N_{r})}}
  
 are the diagonal elements of 
  
    
      
        
          D
        
      
    
    {\displaystyle \mathbf {D} }
  
, 
  
    
      
        (
        ⋅
        
          )
          
            +
          
        
      
    
    {\displaystyle (\cdot )^{+}}
  
 is zero if its argument is negative, and 
  
    
      
        μ
      
    
    {\displaystyle \mu }
  
 is selected such that 
  
    
      
        
          s
          
            1
          
        
        +
        …
        +
        
          s
          
            min
            (
            
              N
              
                t
              
            
            ,
            
              N
              
                r
              
            
            )
          
        
        =
        
          N
          
            t
          
        
      
    
    {\displaystyle s_{1}+\ldots +s_{\min(N_{t},N_{r})}=N_{t}}
  
.
If the transmitter has only statistical channel state information, then the ergodic channel capacity will decrease as the signal covariance 
  
    
      
        
          Q
        
      
    
    {\displaystyle \mathbf {Q} }
  
 can only be optimized in terms of the average mutual information as

  
    
      
        
          C
          
            
              s
              t
              a
              t
              i
              s
              t
              i
              c
              a
              l
              −
              C
              S
              I
            
          
        
        =
        
          max
          
            
              Q
            
          
        
        E
        
          [
          
            
              log
              
                2
              
            
            ⁡
            det
            
              (
              
                
                  I
                
                +
                ρ
                
                  H
                
                
                  Q
                
                
                  
                    H
                  
                  
                    H
                  
                
              
              )
            
          
          ]
        
        .
      
    
    {\displaystyle C_{\mathrm {statistical-CSI} }=\max _{\mathbf {Q} }E\left[\log _{2}\det \left(\mathbf {I} +\rho \mathbf {H} \mathbf {Q} \mathbf {H} ^{H}\right)\right].}
  

The spatial correlation of the channel has a strong impact on the ergodic channel capacity with statistical information.
If the transmitter has no channel state information it can select the signal covariance 
  
    
      
        
          Q
        
      
    
    {\displaystyle \mathbf {Q} }
  
 to maximize channel capacity under worst-case statistics, which means 
  
    
      
        
          Q
        
        =
        1
        
          /
        
        
          N
          
            t
          
        
        
          I
        
      
    
    {\displaystyle \mathbf {Q} =1/N_{t}\mathbf {I} }
  
 and accordingly

  
    
      
        
          C
          
            
              n
              o
              −
              C
              S
              I
            
          
        
        =
        E
        
          [
          
            
              log
              
                2
              
            
            ⁡
            det
            
              (
              
                
                  I
                
                +
                
                  
                    ρ
                    
                      N
                      
                        t
                      
                    
                  
                
                
                  H
                
                
                  
                    H
                  
                  
                    H
                  
                
              
              )
            
          
          ]
        
        .
      
    
    {\displaystyle C_{\mathrm {no-CSI} }=E\left[\log _{2}\det \left(\mathbf {I} +{\frac {\rho }{N_{t}}}\mathbf {H} \mathbf {H} ^{H}\right)\right].}
  

Depending on the statistical properties of the channel, the ergodic capacity is no greater than 
  
    
      
        min
        (
        
          N
          
            t
          
        
        ,
        
          N
          
            r
          
        
        )
      
    
    {\displaystyle \min(N_{t},N_{r})}
  
 times larger than that of a SISO system.


== MIMO detection ==
The MIMO system can be described by:   
  
    
      
        
          y
        
        =
        
          H
        
        
          x
        
        +
        
          n
        
      
    
    {\displaystyle \mathbf {y} =\mathbf {H} \mathbf {x} +\mathbf {n} }
  
, where 
  
    
      
        
          y
        
      
    
    {\displaystyle \mathbf {y} }
  
 is the received vector, 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
 is the channel matrix, 
  
    
      
        
          x
        
      
    
    {\displaystyle \mathbf {x} }
  
 is the transmitted vector, and 
  
    
      
        
          n
        
      
    
    {\displaystyle \mathbf {n} }
  
 is the noise vector. The goal of MIMO detection is to estimate 
  
    
      
        
          x
        
      
    
    {\displaystyle \mathbf {x} }
  
 from 
  
    
      
        
          y
        
      
    
    {\displaystyle \mathbf {y} }
  
 given knowledge of 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
.This can be posed as a statistical detection problem, and addressed using a variety of techniques including zero-forcing, successive interference cancellation a.k.a. V-blast, maximum likelihood estimation and recently, neural network MIMO detection. Such techniques commonly assume that the channel matrix 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
 is known at the receiver. In practice, in communication systems, the transmitter sends a pilot signal and the receiver learns the state of the channel (i.e., 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
) from the received signal 
  
    
      
        Y
      
    
    {\displaystyle Y}
  
 and the pilot signal 
  
    
      
        X
      
    
    {\displaystyle X}
  
. Recently, there are works on MIMO detection using deep learning tools which have shown to work better than other methods such as zero-forcing.


=== Zero forcing ===
The zero forcing (ZF) detector simply solves for the unknown transmitted signals regardless of the noise. The ZF solution takes the form of:

  
    
      
        
          
            
              
                x
                ^
              
            
          
          
            Z
            F
          
        
        =
        
          G
          
            Z
            F
          
        
        z
        ,
      
    
    {\displaystyle {\hat {x}}_{ZF}=G_{ZF}z,}
  
  where 
  
    
      
        
          G
          
            Z
            F
          
        
      
    
    {\displaystyle G_{ZF}}
  
 is the pseudo-inverse of matrix 
  
    
      
        H
      
    
    {\displaystyle H}
  
 and is given by:

  
    
      
        
          G
          
            Z
            F
          
        
        =
        
          H
          
            †
          
        
        =
        (
        
          H
          
            H
          
        
        H
        
          )
          
            −
            1
          
        
        
          H
          
            H
          
        
        .
      
    
    {\displaystyle G_{ZF}=H^{\dagger }=(H^{H}H)^{-1}H^{H}.}
  

Despite its simplicity, this approach suffers from noise enhancement.
After decoupling by Equation , the ZF solution 
  
    
      
        
          
            
              
                x
                ^
              
            
          
          
            Z
            F
          
        
      
    
    {\displaystyle {\hat {x}}_{ZF}}
  
 is either quantized and demapped to binary bits or used to compute the LLR. Note that such an approximation introduces negligible error rate degradation and significantly reduces the computation needed. As the ZF detection decouples the multiple correlated streams into independent streams, the extrinsic LLR of the 
  
    
      
        j
      
    
    {\displaystyle j}
  
th bit of the current symbol in the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th stream resembles the soft-output equalization, and is given by:

  
    
      
        
          L
          
            j
          
          
            (
            p
            )
            ,
            E
          
        
        =
        
          
            1
            
              ‖
              
                g
                
                  p
                
              
              
                ‖
                
                  2
                
              
            
          
        
        
          (
          
            
              max
              
                
                  X
                  
                    (
                    p
                    )
                  
                
                ∈
                
                  χ
                  
                    1
                    ,
                    j
                  
                
              
            
            
              [
              
                −
                
                  |
                
                
                  
                    
                      
                        X
                        ^
                      
                    
                  
                  
                    Z
                    F
                  
                  
                    (
                    p
                    )
                  
                
                −
                
                  X
                  
                    (
                    p
                    )
                  
                
                
                  
                    |
                  
                  
                    2
                  
                
              
              ]
            
            −
            
              max
              
                
                  X
                  
                    (
                    p
                    )
                  
                
                ∈
                
                  χ
                  
                    −
                    1
                    ,
                    j
                  
                
              
            
            
              [
              
                −
                
                  |
                
                
                  
                    
                      
                        X
                        ^
                      
                    
                  
                  
                    Z
                    F
                  
                  
                    (
                    p
                    )
                  
                
                −
                
                  X
                  
                    (
                    p
                    )
                  
                
                
                  
                    |
                  
                  
                    2
                  
                
              
              ]
            
          
          )
        
        ,
      
    
    {\displaystyle L_{j}^{(p),E}={\frac {1}{\|g_{p}\|^{2}}}\left(\max _{X^{(p)}\in \chi _{1,j}}\left[-|{\hat {X}}_{ZF}^{(p)}-X^{(p)}|^{2}\right]-\max _{X^{(p)}\in \chi _{-1,j}}\left[-|{\hat {X}}_{ZF}^{(p)}-X^{(p)}|^{2}\right]\right),}
  

where 
  
    
      
        
          g
          
            p
          
        
      
    
    {\displaystyle g_{p}}
  
 denotes the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th column vector of matrix 
  
    
      
        
          G
          
            Z
            F
          
          
            T
          
        
      
    
    {\displaystyle G_{ZF}^{T}}
  
, 
  
    
      
        
          
            
              
                X
                ^
              
            
          
          
            Z
            F
          
          
            (
            p
            )
          
        
      
    
    {\displaystyle {\hat {X}}_{ZF}^{(p)}}
  
 is the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th element of the symbol vector 
  
    
      
        
          
            
              
                x
                ^
              
            
          
          
            Z
            F
          
        
      
    
    {\displaystyle {\hat {x}}_{ZF}}
  
, and 
  
    
      
        
          χ
          
            b
            ,
            j
          
        
      
    
    {\displaystyle \chi _{b,j}}
  
 indicates the subset of constellation points whose 
  
    
      
        j
      
    
    {\displaystyle j}
  
th bit has value 
  
    
      
        b
      
    
    {\displaystyle b}
  
.


=== Minimum mean squared error ===
The minimum mean squared error (MMSE) algorithm detects the transmitted signals, 
  
    
      
        
          
            
              
                x
              
              ~
            
          
        
      
    
    {\displaystyle {\tilde {\mathbf {x} }}}
  
, through minimizing the mean squared error (MSE), 
  
    
      
        
          E
        
        {
        (
        
          
            
              
                x
              
              ~
            
          
        
        −
        
          x
        
        )
        (
        
          
            
              
                x
              
              ~
            
          
        
        −
        
          x
        
        
          )
          
            H
          
        
        }
      
    
    {\displaystyle \mathbb {E} \{({\tilde {\mathbf {x} }}-\mathbf {x} )({\tilde {\mathbf {x} }}-\mathbf {x} )^{H}\}}
  
. Computation of the MMSE detection is similar to the ZF detection, thus:

  
    
      
        
          
            
              
                x
              
              ~
            
          
        
        =
        
          
            G
          
          
            
              M
              M
              S
              E
            
          
        
        
          z
        
        
        
          (1.1)
        
      
    
    {\displaystyle {\tilde {\mathbf {x} }}=\mathbf {G} _{\mathrm {MMSE} }\mathbf {z} \quad {\text{(1.1)}}}
  

where

  
    
      
        
          
            G
          
          
            
              M
              M
              S
              E
            
          
        
        =
        
          
            R
          
          
            
              x
              z
            
          
        
        
          
            R
          
          
            
              z
              z
            
          
          
            −
            1
          
        
        
        
          (1.2)
        
      
    
    {\displaystyle \mathbf {G} _{\mathrm {MMSE} }=\mathbf {R} _{\mathbf {xz} }\mathbf {R} _{\mathbf {zz} }^{-1}\quad {\text{(1.2)}}}
  

Note that the cross-correlation matrix 
  
    
      
        
          
            R
          
          
            
              x
              z
            
          
        
      
    
    {\displaystyle \mathbf {R} _{\mathbf {xz} }}
  
 is computed as:

  
    
      
        
          
            R
          
          
            
              x
              z
            
          
        
        =
        
          E
        
        {
        
          x
        
        
          
            z
          
          
            H
          
        
        }
        =
        
          
            R
          
          
            
              x
              x
            
          
        
        
          
            H
          
          
            H
          
        
        =
        
          σ
          
            x
          
          
            2
          
        
        
          
            H
          
          
            H
          
        
        
        
          (1.3)
        
      
    
    {\displaystyle \mathbf {R} _{\mathbf {xz} }=\mathbb {E} \{\mathbf {x} \mathbf {z} ^{H}\}=\mathbf {R} _{\mathbf {xx} }\mathbf {H} ^{H}=\sigma _{x}^{2}\mathbf {H} ^{H}\quad {\text{(1.3)}}}
  

whereas the auto-correlation matrix is given by:

  
    
      
        
          
            R
          
          
            
              z
              z
            
          
        
        =
        
          E
        
        {
        
          z
        
        
          
            z
          
          
            H
          
        
        }
        =
        
          σ
          
            x
          
          
            2
          
        
        (
        
          H
        
        
          
            H
          
          
            H
          
        
        )
        +
        
          σ
          
            v
          
          
            2
          
        
        
          
            I
          
          
            Q
          
        
        
        
          (1.4)
        
      
    
    {\displaystyle \mathbf {R} _{\mathbf {zz} }=\mathbb {E} \{\mathbf {z} \mathbf {z} ^{H}\}=\sigma _{x}^{2}(\mathbf {H} \mathbf {H} ^{H})+\sigma _{v}^{2}\mathbf {I} _{Q}\quad {\text{(1.4)}}}
  

where 
  
    
      
        
          σ
          
            x
          
          
            2
          
        
      
    
    {\displaystyle \sigma _{x}^{2}}
  
 and 
  
    
      
        
          σ
          
            v
          
          
            2
          
        
      
    
    {\displaystyle \sigma _{v}^{2}}
  
 are the signal energy and the noise variance, respectively. Combining the above three equations, one obtains:

  
    
      
        
          
            G
          
          
            
              M
              M
              S
              E
            
          
        
        =
        
          
            H
          
          
            H
          
        
        
          
            (
            
              
                H
              
              
                
                  H
                
                
                  H
                
              
              +
              
                
                  
                    
                      I
                    
                    
                      Q
                    
                  
                  ρ
                
              
            
            )
          
          
            −
            1
          
        
        =
        
          
            (
            
              
                
                  H
                
                
                  H
                
              
              
                H
              
              +
              
                
                  
                    
                      I
                    
                    
                      P
                    
                  
                  ρ
                
              
            
            )
          
          
            −
            1
          
        
        
          
            H
          
          
            H
          
        
      
    
    {\displaystyle \mathbf {G} _{\mathrm {MMSE} }=\mathbf {H} ^{H}\left(\mathbf {H} \mathbf {H} ^{H}+{\frac {\mathbf {I} _{Q}}{\rho }}\right)^{-1}=\left(\mathbf {H} ^{H}\mathbf {H} +{\frac {\mathbf {I} _{P}}{\rho }}\right)^{-1}\mathbf {H} ^{H}}
  
     with the SNR 
  
    
      
        ρ
        =
        
          σ
          
            x
          
          
            2
          
        
        
          /
        
        
          σ
          
            v
          
          
            2
          
        
      
    
    {\displaystyle \rho =\sigma _{x}^{2}/\sigma _{v}^{2}}
  
.
The effective SINR of the signal in the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th stream of the MMSE detection output can be formulated as:

  
    
      
        
          α
          
            (
            p
            )
          
        
        =
        
          
            h
          
          
            p
          
          
            H
          
        
        
          
            (
            
              
                
                  H
                
                
                  (
                  −
                  p
                  )
                
              
              
                
                  H
                
                
                  (
                  −
                  p
                  )
                
                
                  H
                
              
              +
              
                
                  
                    
                      I
                    
                    
                      Q
                    
                  
                  ρ
                
              
            
            )
          
          
            −
            1
          
        
        
          
            h
          
          
            p
          
        
        
        
          (1.5)
        
      
    
    {\displaystyle \alpha ^{(p)}=\mathbf {h} _{p}^{H}\left(\mathbf {H} _{(-p)}\mathbf {H} _{(-p)}^{H}+{\frac {\mathbf {I} _{Q}}{\rho }}\right)^{-1}\mathbf {h} _{p}\quad {\text{(1.5)}}}
  

where 
  
    
      
        
          
            H
          
          
            (
            −
            p
            )
          
        
      
    
    {\displaystyle \mathbf {H} _{(-p)}}
  
 represents the matrix 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
 with the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th column removed, and 
  
    
      
        
          
            h
          
          
            p
          
        
      
    
    {\displaystyle \mathbf {h} _{p}}
  
 is the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th column vector of 
  
    
      
        
          H
        
      
    
    {\displaystyle \mathbf {H} }
  
.
Equation (1.1) is referred to as the biased MMSE detector because the detected signal power is smaller than the transmitted signal power by a factor of 
  
    
      
        
          α
          
            (
            p
            )
          
        
        
          /
        
        (
        
          α
          
            (
            p
            )
          
        
        +
        1
        )
      
    
    {\displaystyle \alpha ^{(p)}/(\alpha ^{(p)}+1)}
  
. To avoid this degradation, an unbiased MMSE detector has been proposed:

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            
              M
              M
              S
              E
            
          
        
        =
        
          B
        
        
          
            G
          
          
            
              M
              M
              S
              E
            
          
        
        
          z
        
        
        
          (1.6)
        
      
    
    {\displaystyle {\hat {\mathbf {x} }}_{\mathrm {MMSE} }=\mathbf {B} \mathbf {G} _{\mathrm {MMSE} }\mathbf {z} \quad {\text{(1.6)}}}
  

where 
  
    
      
        
          B
        
      
    
    {\displaystyle \mathbf {B} }
  
 is a diagonal matrix with the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th diagonal element equal to 
  
    
      
        (
        
          α
          
            (
            p
            )
          
        
        +
        1
        )
        
          /
        
        
          α
          
            (
            p
            )
          
        
      
    
    {\displaystyle (\alpha ^{(p)}+1)/\alpha ^{(p)}}
  
. The unbiased MMSE detection solution has better BER performance than the biased MMSE detection solution. Interestingly, this phenomenon implies that minimizing the MSE does not necessarily minimize the BER.
The soft-output unbiased MMSE detection is similar to the soft-output ZF detection, thus:

  
    
      
        
          L
          
            j
          
          
            (
            p
            )
            ,
            E
          
        
        =
        
          α
          
            (
            p
            )
          
        
        
          (
          
            
              max
              
                
                  X
                  
                    (
                    p
                    )
                  
                
                ∈
                
                  χ
                  
                    1
                    ,
                    j
                  
                
              
            
            
              [
              
                −
                
                  
                    |
                    
                      
                        
                          
                            
                              X
                              ^
                            
                          
                        
                        
                          
                            M
                            M
                            S
                            E
                          
                        
                        
                          (
                          p
                          )
                        
                      
                      −
                      
                        X
                        
                          (
                          p
                          )
                        
                      
                    
                    |
                  
                  
                    2
                  
                
              
              ]
            
            −
            
              max
              
                
                  X
                  
                    (
                    p
                    )
                  
                
                ∈
                
                  χ
                  
                    −
                    1
                    ,
                    j
                  
                
              
            
            
              [
              
                −
                
                  
                    |
                    
                      
                        
                          
                            
                              X
                              ^
                            
                          
                        
                        
                          
                            M
                            M
                            S
                            E
                          
                        
                        
                          (
                          p
                          )
                        
                      
                      −
                      
                        X
                        
                          (
                          p
                          )
                        
                      
                    
                    |
                  
                  
                    2
                  
                
              
              ]
            
          
          )
        
      
    
    {\displaystyle L_{j}^{(p),E}=\alpha ^{(p)}\left(\max _{X^{(p)}\in \chi _{1,j}}\left[-\left|{\hat {X}}_{\mathrm {MMSE} }^{(p)}-X^{(p)}\right|^{2}\right]-\max _{X^{(p)}\in \chi _{-1,j}}\left[-\left|{\hat {X}}_{\mathrm {MMSE} }^{(p)}-X^{(p)}\right|^{2}\right]\right)}
  


=== Ordered successive interference cancellation (OSIC, V-BLAST) ===
Both the ZF and the MMSE detectors are linear. There also exist nonlinear methods that solve the MIMO detection problem for spatially multiplexed MIMO systems. Among these nonlinear algorithms, the OSIC is the simplest one. 
In the 
  
    
      
        i
      
    
    {\displaystyle i}
  
th iteration, the symbol is detected by:

  
    
      
        
          
            
              
                X
                ^
              
            
          
          
            (
            p
            )
          
        
        =
        Q
        
          (
          
            
              
                g
              
              
                p
                (
                i
                )
              
              
                T
              
            
            
              
                z
              
              
                (
                i
                )
              
            
          
          )
        
        
      
    
    {\displaystyle {\hat {X}}^{(p)}=Q\left(\mathbf {g} _{p(i)}^{T}\mathbf {z} ^{(i)}\right)\quad }
  

where 
  
    
      
        Q
        (
        ⋅
        )
      
    
    {\displaystyle Q(\cdot )}
  
 denotes the quantizer and 
  
    
      
        
          
            g
          
          
            p
            (
            i
            )
          
        
      
    
    {\displaystyle \mathbf {g} _{p(i)}}
  
 is the column vector of 
  
    
      
        
          
            G
          
          
            (
            i
            )
            T
          
        
      
    
    {\displaystyle \mathbf {G} ^{(i)T}}
  
.
Then, the interference from 
  
    
      
        
          
            
              
                X
                ^
              
            
          
          
            (
            p
            )
          
        
      
    
    {\displaystyle {\hat {X}}^{(p)}}
  
 is removed:

  
    
      
        
          
            z
          
          
            (
            i
            +
            1
            )
          
        
        =
        
          
            z
          
          
            (
            i
            )
          
        
        −
        
          
            h
          
          
            p
          
        
        
          
            
              
                X
                ^
              
            
          
          
            (
            p
            )
          
        
      
    
    {\displaystyle \mathbf {z} ^{(i+1)}=\mathbf {z} ^{(i)}-\mathbf {h} _{p}{\hat {X}}^{(p)}}
  

Note that OSIC is known to perform better than linear detectors at high SNR, but it is worse at low SNR. Therefore, adequately switching between linear detection and OSIC can further improve the error rate performance.


==== Example ====
Assume that the 2×2 channel matrix is:

  
    
      
        
          H
        
        =
        
          
            [
            
              
                
                  H
                  (
                  0
                  ,
                  0
                  )
                
                
                  H
                  (
                  0
                  ,
                  1
                  )
                
              
              
                
                  H
                  (
                  1
                  ,
                  0
                  )
                
                
                  H
                  (
                  1
                  ,
                  1
                  )
                
              
            
            ]
          
        
      
    
    {\displaystyle \mathbf {H} ={\begin{bmatrix}H(0,0)&H(0,1)\\H(1,0)&H(1,1)\end{bmatrix}}}
  

The OSIC scheme checks rows of matrix 
  
    
      
        
          G
        
      
    
    {\displaystyle \mathbf {G} }
  
, and if:

  
    
      
        
          |
        
        H
        (
        0
        ,
        0
        )
        
          
            |
          
          
            2
          
        
        +
        
          |
        
        H
        (
        1
        ,
        0
        )
        
          
            |
          
          
            2
          
        
        <
        
          |
        
        H
        (
        0
        ,
        1
        )
        
          
            |
          
          
            2
          
        
        +
        
          |
        
        H
        (
        1
        ,
        1
        )
        
          
            |
          
          
            2
          
        
        ,
      
    
    {\displaystyle |H(0,0)|^{2}+|H(1,0)|^{2}<|H(0,1)|^{2}+|H(1,1)|^{2},}
  

then the detected signal can be computed by:

  
    
      
        
          
            
              
                X
                ~
              
            
          
          
            (
            1
            )
          
        
        =
        
          
            1
            
              det
              (
              
                H
              
              )
            
          
        
        
          
            [
            
              
                
                  −
                  H
                  (
                  1
                  ,
                  0
                  )
                
                
                  H
                  (
                  0
                  ,
                  0
                  )
                
              
            
            ]
          
        
        
          
            [
            
              
                
                  Z
                  (
                  0
                  )
                
              
              
                
                  Z
                  (
                  1
                  )
                
              
            
            ]
          
        
        ,
        
        
          
            
              
                X
                ^
              
            
          
          
            (
            1
            )
          
        
        =
        Q
        (
        
          
            
              
                X
                ~
              
            
          
          
            (
            1
            )
          
        
        )
      
    
    {\displaystyle {\tilde {X}}^{(1)}={\frac {1}{\det(\mathbf {H} )}}{\begin{bmatrix}-H(1,0)&H(0,0)\end{bmatrix}}{\begin{bmatrix}Z(0)\\Z(1)\end{bmatrix}},\quad {\hat {X}}^{(1)}=Q({\tilde {X}}^{(1)})}
  

and

  
    
      
        
          
            
              
                X
                ~
              
            
          
          
            (
            0
            )
          
        
        =
        
          
            1
            
              
                |
              
              H
              (
              0
              ,
              0
              )
              
                
                  |
                
                
                  2
                
              
              +
              
                |
              
              H
              (
              1
              ,
              0
              )
              
                
                  |
                
                
                  2
                
              
            
          
        
        
          
            [
            
              
                
                  H
                  (
                  0
                  ,
                  0
                  
                    )
                    
                      ∗
                    
                  
                
                
                  H
                  (
                  1
                  ,
                  0
                  
                    )
                    
                      ∗
                    
                  
                
              
            
            ]
          
        
        
          (
          
            
              
                [
                
                  
                    
                      Z
                      (
                      0
                      )
                    
                  
                  
                    
                      Z
                      (
                      1
                      )
                    
                  
                
                ]
              
            
            −
            
              
                
                  
                    X
                    ^
                  
                
              
              
                (
                1
                )
              
            
            
              
                [
                
                  
                    
                      H
                      (
                      0
                      ,
                      1
                      )
                    
                  
                  
                    
                      H
                      (
                      1
                      ,
                      1
                      )
                    
                  
                
                ]
              
            
          
          )
        
        ,
        
        
          
            
              
                X
                ^
              
            
          
          
            (
            0
            )
          
        
        =
        Q
        (
        
          
            
              
                X
                ~
              
            
          
          
            (
            0
            )
          
        
        )
      
    
    {\displaystyle {\tilde {X}}^{(0)}={\frac {1}{|H(0,0)|^{2}+|H(1,0)|^{2}}}{\begin{bmatrix}H(0,0)^{*}&H(1,0)^{*}\end{bmatrix}}\left({\begin{bmatrix}Z(0)\\Z(1)\end{bmatrix}}-{\hat {X}}^{(1)}{\begin{bmatrix}H(0,1)\\H(1,1)\end{bmatrix}}\right),\quad {\hat {X}}^{(0)}=Q({\tilde {X}}^{(0)})}
  

Otherwise, if:

  
    
      
        
          |
        
        H
        (
        0
        ,
        0
        )
        
          
            |
          
          
            2
          
        
        +
        
          |
        
        H
        (
        1
        ,
        0
        )
        
          
            |
          
          
            2
          
        
        ≥
        
          |
        
        H
        (
        0
        ,
        1
        )
        
          
            |
          
          
            2
          
        
        +
        
          |
        
        H
        (
        1
        ,
        1
        )
        
          
            |
          
          
            2
          
        
        ,
      
    
    {\displaystyle |H(0,0)|^{2}+|H(1,0)|^{2}\geq |H(0,1)|^{2}+|H(1,1)|^{2},}
  

then:

  
    
      
        
          
            
              
                X
                ~
              
            
          
          
            (
            0
            )
          
        
        =
        
          
            1
            
              det
              (
              
                H
              
              )
            
          
        
        
          
            [
            
              
                
                  −
                  H
                  (
                  0
                  ,
                  1
                  )
                
                
                  H
                  (
                  1
                  ,
                  1
                  )
                
              
            
            ]
          
        
        
          
            [
            
              
                
                  Z
                  (
                  1
                  )
                
              
              
                
                  Z
                  (
                  0
                  )
                
              
            
            ]
          
        
        ,
        
        
          
            
              
                X
                ^
              
            
          
          
            (
            0
            )
          
        
        =
        Q
        (
        
          
            
              
                X
                ~
              
            
          
          
            (
            0
            )
          
        
        )
      
    
    {\displaystyle {\tilde {X}}^{(0)}={\frac {1}{\det(\mathbf {H} )}}{\begin{bmatrix}-H(0,1)&H(1,1)\end{bmatrix}}{\begin{bmatrix}Z(1)\\Z(0)\end{bmatrix}},\quad {\hat {X}}^{(0)}=Q({\tilde {X}}^{(0)})}
  

and

  
    
      
        
          
            
              
                X
                ~
              
            
          
          
            (
            1
            )
          
        
        =
        
          
            1
            
              
                |
              
              H
              (
              1
              ,
              1
              )
              
                
                  |
                
                
                  2
                
              
              +
              
                |
              
              H
              (
              0
              ,
              1
              )
              
                
                  |
                
                
                  2
                
              
            
          
        
        
          
            [
            
              
                
                  H
                  (
                  1
                  ,
                  1
                  
                    )
                    
                      ∗
                    
                  
                
                
                  H
                  (
                  0
                  ,
                  1
                  
                    )
                    
                      ∗
                    
                  
                
              
            
            ]
          
        
        
          (
          
            
              
                [
                
                  
                    
                      Z
                      (
                      1
                      )
                    
                  
                  
                    
                      Z
                      (
                      0
                      )
                    
                  
                
                ]
              
            
            −
            
              
                
                  
                    X
                    ^
                  
                
              
              
                (
                0
                )
              
            
            
              
                [
                
                  
                    
                      H
                      (
                      1
                      ,
                      0
                      )
                    
                  
                  
                    
                      H
                      (
                      0
                      ,
                      0
                      )
                    
                  
                
                ]
              
            
          
          )
        
        ,
        
        
          
            
              
                X
                ^
              
            
          
          
            (
            1
            )
          
        
        =
        Q
        (
        
          
            
              
                X
                ~
              
            
          
          
            (
            1
            )
          
        
        )
      
    
    {\displaystyle {\tilde {X}}^{(1)}={\frac {1}{|H(1,1)|^{2}+|H(0,1)|^{2}}}{\begin{bmatrix}H(1,1)^{*}&H(0,1)^{*}\end{bmatrix}}\left({\begin{bmatrix}Z(1)\\Z(0)\end{bmatrix}}-{\hat {X}}^{(0)}{\begin{bmatrix}H(1,0)\\H(0,0)\end{bmatrix}}\right),\quad {\hat {X}}^{(1)}=Q({\tilde {X}}^{(1)})}
  


=== Maximum likelihood detection ===
The maximum likelihood (ML) detector exhaustively searches all possible transmitted symbol vectors 
  
    
      
        
          x
        
      
    
    {\displaystyle \mathbf {x} }
  
 and selects the one that minimizes the Euclidean distance:

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            M
            L
          
        
        =
        arg
        ⁡
        
          min
          
            
              x
            
            ∈
            
              χ
              
                
                  N
                  
                    t
                  
                
              
            
          
        
        ‖
        
          y
        
        −
        
          H
        
        
          x
        
        
          ‖
          
            2
          
        
      
    
    {\displaystyle {\hat {\mathbf {x} }}_{ML}=\arg \min _{\mathbf {x} \in \chi ^{N_{t}}}\|\mathbf {y} -\mathbf {H} \mathbf {x} \|^{2}}
  

Although ML provides optimal performance, its complexity grows exponentially with the number of transmit antennas and modulation order, making it impractical for large MIMO systems.


=== Sphere decoder ===
The ML solution to the MIMO detection problem simultaneously determines the 
  
    
      
        P
      
    
    {\displaystyle P}
  
 spatially-multiplexed symbols by:

  
    
      
        
          
            x
          
          
            
              M
              L
            
          
        
        =
        arg
        ⁡
        
          min
          
            
              x
            
            ∈
            
              χ
              
                P
              
            
          
        
        
          
            ‖
            
              
                z
              
              −
              
                H
              
              
                x
              
            
            ‖
          
          
            2
          
        
        =
        arg
        ⁡
        
          min
          
            
              x
            
            ∈
            
              χ
              
                P
              
            
          
        
        M
        (
        
          x
        
        )
        
      
    
    {\displaystyle \mathbf {x} _{\mathrm {ML} }=\arg \min _{\mathbf {x} \in \chi ^{P}}\left\|\mathbf {z} -\mathbf {H} \mathbf {x} \right\|^{2}=\arg \min _{\mathbf {x} \in \chi ^{P}}M(\mathbf {x} )\quad }
  

where 
  
    
      
        
          χ
          
            P
          
        
      
    
    {\displaystyle \chi ^{P}}
  
 is the 
  
    
      
        P
      
    
    {\displaystyle P}
  
-fold Cartesian product over constellation set 
  
    
      
        χ
      
    
    {\displaystyle \chi }
  
, and 
  
    
      
        M
        (
        
          x
        
        )
      
    
    {\displaystyle M(\mathbf {x} )}
  
 is the metric value of a symbol vector. The ML detector must search all possible combinations of 
  
    
      
        P
      
    
    {\displaystyle P}
  
 symbols, thus the complexity grows exponentially with 
  
    
      
        P
      
    
    {\displaystyle P}
  
.
In light of this huge complexity, the sphere decoder (SD) was proposed to reduce the search space in an ML MIMO detector. The SD only searches those constellation points lying within a 
  
    
      
        P
      
    
    {\displaystyle P}
  
-dimensional hypersphere. This is effective only when the radius 
  
    
      
        d
      
    
    {\displaystyle d}
  
 is large enough to include the ML solution:    
  
    
      
        M
        (
        
          x
        
        )
        <
        
          d
          
            2
          
        
        
      
    
    {\displaystyle M(\mathbf {x} )<d^{2}\quad }
  

The QR decomposition (QRD) is typically applied to convert the exhaustive search into a constrained tree search:

  
    
      
        
          
            x
          
          
            
              M
              L
            
          
        
        =
        arg
        ⁡
        
          min
          
            
              x
            
            ∈
            
              χ
              
                P
              
            
          
        
        
          
            ‖
            
              
                
                  
                    
                      z
                    
                    ~
                  
                
              
              −
              
                R
              
              
                x
              
            
            ‖
          
          
            2
          
        
        ,
        
        
          where
        
        
        
          
            
              
                z
              
              ~
            
          
        
        =
        
          
            Q
          
          
            H
          
        
        
          z
        
        
      
    
    {\displaystyle \mathbf {x} _{\mathrm {ML} }=\arg \min _{\mathbf {x} \in \chi ^{P}}\left\|{\tilde {\mathbf {z} }}-\mathbf {R} \mathbf {x} \right\|^{2},\quad {\text{where}}\quad {\tilde {\mathbf {z} }}=\mathbf {Q} ^{H}\mathbf {z} \quad }
  

Let the 
  
    
      
        (
        i
        ,
        j
        )
      
    
    {\displaystyle (i,j)}
  
th element in 
  
    
      
        
          R
        
      
    
    {\displaystyle \mathbf {R} }
  
 be 
  
    
      
        
          R
          
            i
            ,
            j
          
        
      
    
    {\displaystyle R_{i,j}}
  
 and the 
  
    
      
        p
      
    
    {\displaystyle p}
  
th element in 
  
    
      
        
          
            
              
                z
              
              ~
            
          
        
      
    
    {\displaystyle {\tilde {\mathbf {z} }}}
  
 be 
  
    
      
        
          
            
              Z
              ~
            
          
        
        (
        p
        )
      
    
    {\displaystyle {\tilde {Z}}(p)}
  
. 
Then the metric 
  
    
      
        M
        (
        
          x
        
        )
      
    
    {\displaystyle M(\mathbf {x} )}
  
 can be expressed as:  
  
    
      
        M
        (
        
          x
        
        )
        =
        
          ∑
          
            p
            =
            0
          
          
            P
            −
            1
          
        
        T
        (
        p
        )
        
      
    
    {\displaystyle M(\mathbf {x} )=\sum _{p=0}^{P-1}T(p)\quad }
  

where the partial distance (PD) is defined as:   
  
    
      
        T
        (
        p
        )
        =
        
          
            |
            
              
                
                  
                    Z
                    ~
                  
                
              
              (
              p
              )
              −
              
                ∑
                
                  j
                  =
                  p
                
                
                  P
                  −
                  1
                
              
              
                R
                
                  p
                  ,
                  j
                
              
              X
              (
              j
              )
            
            |
          
          
            2
          
        
      
    
    {\displaystyle T(p)=\left|{\tilde {Z}}(p)-\sum _{j=p}^{P-1}R_{p,j}X(j)\right|^{2}}
  
. The resulting sphere decoding process becomes a 
  
    
      
        P
      
    
    {\displaystyle P}
  
-level tree search. 
In level 
  
    
      
        L
      
    
    {\displaystyle L}
  
, only child nodes from parent nodes satisfying: 
  
    
      
        
          ∑
          
            p
            =
            L
            +
            1
          
          
            P
            −
            1
          
        
        T
        (
        p
        )
        <
        
          d
          
            2
          
        
      
    
    {\displaystyle \sum _{p=L+1}^{P-1}T(p)<d^{2}}
  
  are considered. Once the accumulated partial distance:  
  
    
      
        T
        (
        L
        )
        +
        
          ∑
          
            p
            =
            L
            +
            1
          
          
            P
            −
            1
          
        
        T
        (
        p
        )
      
    
    {\displaystyle T(L)+\sum _{p=L+1}^{P-1}T(p)}
  
  exceeds 
  
    
      
        
          d
          
            2
          
        
      
    
    {\displaystyle d^{2}}
  
, all nodes in the subtree rooted at that child node are removed from the search space.
When nodes at the bottommost layer are visited, the ML solution:  
  
    
      
        
          
            x
          
          
            
              M
              L
            
          
        
        =
        
          [
          
            
              
                
                  X
                  ^
                
              
            
            (
            0
            )
            ,
            
              
                
                  X
                  ^
                
              
            
            (
            1
            )
            ,
            …
            ,
            
              
                
                  X
                  ^
                
              
            
            (
            P
            −
            1
            )
          
          ]
        
      
    
    {\displaystyle \mathbf {x} _{\mathrm {ML} }=\left[{\hat {X}}(0),{\hat {X}}(1),\dots ,{\hat {X}}(P-1)\right]}
  

is the path with the minimum metric value. For example, one starts from variable 
  
    
      
        X
        (
        P
        −
        1
        )
      
    
    {\displaystyle X(P-1)}
  
 and discards all the nodes where:

  
    
      
        T
        (
        P
        −
        1
        )
        >
        
          d
          
            2
          
        
      
    
    {\displaystyle T(P-1)>d^{2}}
  
. Then, for surviving 
  
    
      
        X
        (
        P
        −
        1
        )
      
    
    {\displaystyle X(P-1)}
  
 nodes, the SD procedure proceeds to examine all the underlying 
  
    
      
        X
        (
        P
        −
        2
        )
      
    
    {\displaystyle X(P-2)}
  
 and again discards those partial vectors 
  
    
      
        [
        X
        (
        P
        −
        1
        )
        ,
        X
        (
        P
        −
        2
        )
        ]
      
    
    {\displaystyle [X(P-1),X(P-2)]}
  
 for which:  
  
    
      
        T
        (
        P
        −
        1
        )
        +
        T
        (
        P
        −
        2
        )
        >
        
          d
          
            2
          
        
      
    
    {\displaystyle T(P-1)+T(P-2)>d^{2}}
  
.
Since 
  
    
      
        T
        (
        p
        )
        >
        0
      
    
    {\displaystyle T(p)>0}
  
, the accumulated PDs increase monotonically, and more nodes are pruned at lower layers. With careful design of the radius and search strategy, sphere decoding can approach ML performance with significantly lower average complexity.
Different tree search algorithms significantly affect the sphere decoder's efficiency. In algorithm design, tree search strategies are commonly categorized into three major types: depth-first search, breadth-first search, and best-first search.


==== 1. Depth-first tree search ====
As its name implies, this algorithm explores the tree by diving down to the bottommost layer first — called the forward step — until a leaf node is reached or the accumulated partial distance (PD) exceeds the radius constraint. When the forward step cannot proceed, a backward step returns the search to the upper layer, and the algorithm continues down another branch. This process repeats until all nodes satisfying the radius constraint are visited.
In the natural span scheme, the next node is selected randomly. Its advantage is that it avoids enumerating all possible child nodes, which is a major source of complexity in the closest-point-first scheme.


==== Radius update ====
In the closest-point-first method, the next node is chosen based on the smallest PD. When this method is combined with depth-first search, the first full symbol vector found is known as the Babai point. 
The radius constraint 
  
    
      
        
          d
          
            2
          
        
      
    
    {\displaystyle d^{2}}
  
 of the sphere decoder can then be updated to the metric value of the Babai point, effectively shrinking the search space. If another full leaf node is later discovered with an even smaller metric, the radius can again be updated, reducing the search space further.


==== Characteristics ====
Depth-first tree search is favored for its speed. The first valid full solution (the Babai point) can be found by visiting only 
  
    
      
        P
      
    
    {\displaystyle P}
  
 nodes. When combined with radius update, the ML solution is often identified quickly. Thus, this approach is especially suitable for hard-output MIMO detectors.
However, its drawbacks include variable latency and runtime complexity. In some cases, especially under low SNR, the algorithm may need to explore many nodes before finding the ML solution, particularly when it is far from the Babai point.
To address this, the run-time constraint concept is introduced: a fixed upper limit is imposed on the number of visited nodes. Once the limit is reached, the search terminates early.
In summary, the depth-first tree search method is best suited for hard-output MIMO detection in high-SNR environments due to its speed and efficiency, especially when combined with radius update strategies.


==== 2. Breadth-first tree search ====
The breadth-first tree search algorithm features two main properties: (1) multiple nodes are visited simultaneously within a layer, and (2) only forward traversal is allowed (no backward step). As a result, all symbol vectors that satisfy the radius constraint are found concurrently once the search reaches the bottommost layer.
Unlike depth-first search, the sphere radius cannot be dynamically updated in breadth-first search. The initial radius is the sole parameter to balance between complexity and performance. If the radius is too small, no valid solution may be found and the search must be restarted with a larger radius. Conversely, if the radius is too large, the search may visit too many unnecessary nodes and their descendants.
A notable issue with this algorithm is the variable number of visited nodes per layer, which poses implementation challenges, especially in hardware design that must accommodate the worst-case scenario.


==== K-best algorithm ====
A well-known derivative of the breadth-first search is the K-best tree search. Here, 
  
    
      
        K
      
    
    {\displaystyle K}
  
 represents the number of nodes retained at each layer for further downward traversal. Therefore, the **search complexity is fixed**, determined by 
  
    
      
        K
      
    
    {\displaystyle K}
  
 and the number of tree layers.
Several strategies exist to enumerate the best 
  
    
      
        K
      
    
    {\displaystyle K}
  
 nodes at a given layer. One common approach: 1. Enumerate the best child node of each surviving parent node. 2. Among these children, determine the overall best node. 3. From the parent whose best child was selected, enumerate its second-best child. 4. Repeat the selection and enumeration process until the top 
  
    
      
        K
      
    
    {\displaystyle K}
  
 nodes are determined.
This procedure continues layer by layer. A visualization of the K-best tree search is often represented.
In a typical K-best Sphere Decoder (SD), the radius is implicitly set to infinity. However, it is possible to combine a fixed radius constraint with the K-best criterion: among nodes with PD below the radius, only 
  
    
      
        K
      
    
    {\displaystyle K}
  
 may be selected. If the radius is small, fewer than 
  
    
      
        K
      
    
    {\displaystyle K}
  
 nodes might be available in a layer, making 
  
    
      
        K
      
    
    {\displaystyle K}
  
 act more like a layer-wise runtime constraint.
The choice of 
  
    
      
        K
      
    
    {\displaystyle K}
  
 is critical to achieving a good tradeoff between complexity and detection performance. For instance, in a 4×4 MIMO system, the maximum affordable number of visited nodes may be around 100; thus, 
  
    
      
        K
        ≈
        25
      
    
    {\displaystyle K\approx 25}
  
. However, in real implementations, 
  
    
      
        K
      
    
    {\displaystyle K}
  
 is often smaller. For small 
  
    
      
        K
      
    
    {\displaystyle K}
  
, it is possible that the ancestor of the ML solution is pruned, because although the ML path has the smallest total metric, its early PDs may be larger than other nodes at the same layer.


===== 3. Best-first tree search =====
Unlike depth-first and breadth-first tree search algorithms, the best-first tree search does not follow strict layer boundaries. In this approach, candidate nodes are defined as all nodes that can be visited next, regardless of their depth in the tree. At each traversal step, the best candidate node, i.e., the one with the smallest accumulated partial distance (PD), is visited.
To manage cross-layer candidates, a node pool is maintained to store all viable candidate nodes and their PDs. This method achieves the lowest average complexity among ML tree searches. While both depth-first and best-first can achieve the ML solution, their behavior differs fundamentally:

Depth-first cannot confirm the ML solution until all valid paths are explored.
Best-first proceeds from low to high PD values and guarantees the ML solution upon reaching the first full-length leaf node, since its metric must be the lowest.
However, the best-first tree search has some limitations: 1. Memory usage: A large node pool is required. 2. Enumeration overhead: Dynamic control logic is needed to manage the pool. 3. Soft-output inefficiency: Few full-length solutions may be found, which is problematic for soft-output MIMO detection.
To address these limitations, two variants are introduced:


==== Modified best-first tree search ====
The modified best-first (MBF) tree search transforms the M-ary search tree into a binary tree using a first-child/next-sibling structure. Instead of pushing all 
  
    
      
        M
      
    
    {\displaystyle M}
  
 children of a node into the pool, only: - the best child in the next layer, and - the best unvisited sibling are added when a node is visited. The current node is then removed from the pool. This encoding reduces the branching factor and keeps the node pool more compact, improving search efficiency while preserving forward and horizontal traversal capabilities. This technique is similar to standard binary tree encoding in data structures.


==== Modified best-first with fast descent ====
The modified best-first with fast descent (MBF-FD) further improves MBF by combining it with depth-first traversal principles. The idea is to descend quickly along the best child path to reach a leaf node, while pushing best sibling nodes encountered along the way into the pool. Once a leaf is found, a new search begins from the next best node in the pool. This method ensures more full-length paths are explored, which is especially beneficial for soft-output MIMO detection requiring multiple high-quality symbol vectors. It retains the efficiency of MBF while expanding search diversity and depth.


== Testing ==
MIMO signal testing focuses first on the transmitter/receiver system. The random phases of the sub-carrier signals can produce instantaneous power levels that cause the amplifier to compress, momentarily causing distortion and ultimately symbol errors. Signals with a high peak-to-average ratio (PAR) can cause amplifiers to compress unpredictably during transmission. OFDM signals are very dynamic and compression problems can be hard to detect because of their noise-like nature.
Knowing the quality of the signal channel is also critical. A channel emulator can simulate how a device performs at the cell edge, can add noise or can simulate what the channel looks like at speed. To fully qualify the performance of a receiver, a calibrated transmitter, such as a vector signal generator (VSG), and channel emulator can be used to test the receiver under a variety of different conditions. Conversely, the transmitter's performance under a number of different conditions can be verified using a channel emulator and a calibrated receiver, such as a vector signal analyzer (VSA).
Understanding the channel allows for manipulation of the phase and amplitude of each transmitter in order to form a beam. To correctly form a beam, the transmitter needs to understand the characteristics of the channel. This process is called channel sounding or channel estimation. A known signal is sent to the mobile device that enables it to build a picture of the channel environment. The mobile device sends back the channel characteristics to the transmitter. The transmitter can then apply the correct phase and amplitude adjustments to form a beam directed at the mobile device. This is called a closed-loop MIMO system. For beamforming, it is required to adjust the phases and amplitude of each transmitter. In a beamformer optimized for spatial diversity or spatial multiplexing, each antenna element simultaneously transmits a weighted combination of two data symbols.


== Literature ==


=== Principal researchers ===
Papers by Gerard J. Foschini and Michael J. Gans, Foschini and Emre Telatar have shown that the channel capacity (a theoretical upper bound on system throughput) for a MIMO system is increased as the number of antennas is increased, proportional to the smaller of the number of transmit antennas and the number of receive antennas. This is known as the multiplexing gain and this basic finding in information theory is what led to a spurt of research in this area. Despite the simple propagation models used in the aforementioned seminal works, the multiplexing gain is a fundamental property that can be proved under almost any physical channel propagation model and with practical hardware that is prone to transceiver impairments.
A textbook by A. Paulraj, R. Nabar and D. Gore has published an introduction to this area. There are many other principal textbooks available as well.


=== Diversity–multiplexing tradeoff ===
There exists a fundamental tradeoff between transmit diversity and spatial multiplexing gains in a MIMO system (Zheng and Tse, 2003). In particular, achieving high spatial multiplexing gains is of profound importance in modern wireless systems.


=== Other applications ===
Given the nature of MIMO, it is not limited to wireless communication. It can be used for wire line communication as well. For example, a new type of DSL technology (gigabit DSL) has been proposed based on binder MIMO channels.


=== Sampling theory in MIMO systems ===
An important question which attracts the attention of engineers and mathematicians is how to use the multi-output signals at the receiver to recover the multi-input signals at the transmitter. In Shang, Sun and Zhou (2007), sufficient and necessary conditions are established to guarantee the complete recovery of the multi-input signals.


== See also ==


== References ==


== External links ==
NIST UWB-MIMO Channel Propagation Measurements in the 2–8 GHz Spectrum
Literature review of MIMO
Antenna and Wireless Multipath Virtual Channel Interaction