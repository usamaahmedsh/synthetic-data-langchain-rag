The right to reality refers to the right to consume organic content as opposed to content created by artificial intelligence, or more broadly speaking, to experience life and the world as they are, not through simulations and simulacra. It was once defined as "the latest in a series of novel rights set forth in response to a sizable jump in technology".
A right to reality can also refer to the right to consume real news in opposition to fake news, as well as the right to receive information when in a news desert.


== Proposed definitions ==
A 2024 article by Digital Frontier describes Newcastle University Law scholar Lilian Edwards as an early proponent of the right to reality, an idea she came across during a 2019 lecture at the Turing Institute, when an attendee asked her if the younger generation were  "getting easier with the idea of unreality" while not "knowing what canonical reality is", and that made her reflect on the possibility of "reality" being a human right, much like privacy or freedom of speech.
In an article for a 2025 special edition of Stanford Social Innovation Review Brasil, Brazilian proponent Eduardo Saron defined the right to reality as "the right to a non-distorted and authentic perception of reality"; he later elaborates that it is "the possibility to live with density, bond and acting, in contrast with those who, deprived of these anchors, are pushed into isolation, insecurity and precarious shelter in the virtual world" and also saw it as a potential human right.
In an article for Folha de S.Paulo, he also defined it as the right to "experience what cannot be reduced to data or anticipated by statistical models. The right to err, vacillate, improvise. To exist outside of the script." He further advocated for the expansion of our capacity to analyze  and question what we see instead of just absorbing it. According to him, the right to reality would contemplate the idea of 'neurorights' proposed by some researchers.
Saron goes on to explain that generative AI will foster what he calls "synthetic inequality", according to which a part of the population will experience reality in person, as it is, while others will have their experiences more and more mediated by screens, data and simulations. Saron believes that while it seems there's a process towards universal access to the digital world, it could be an illusive and simulated one for many. This could be specially problematic for children, as some would grow up exploring the world with their five senses while others would have their lives mostly filtered by screens. Drawing inspiration from Italian philosopher Luciano Floridi's onlife concept, he believes people lacking discernment, agency or critical capacity are excluded from reality.
He compares the relationship of humans and AI with the concept of Simulacra and Simulation by French philosopher Jean Baudrillard and defends living in a reliable world and preserving subjective experiences as principles to be ensured, specially because the stimuli that the human brain processes in order to build one's perception of reality can be manipulated with mis- and disinformation. The philosophical questions raised by the film The Matrix also permeate Saron's reasoning, including the allegory of the cave, with Saron stating that the cave is no longer rocky, but algorithmic.


== Possible justifications for a right to reality ==
Lawfare senior editor and AI Innovation and Law specialist Kevin Frazier analyzed in a 2023 article that the role of social media platforms as marketplaces of ideas would grow in the following years and that they would probably be full of AI-altered content that users would not be able to distinguish from "organic" content, since the former is increasingly similar to the latter. Indeed, a 2022 report by Europol estimated that 90% of online material would be produced by AI by 2026, while Copenhagen Institute for Futures Studies's Timothy Shoup predicted in the same year that 99%-99.9% of content would be generated by robots by 2025-2030 in case LLMs soar.
Frazier also mentioned a study according to which efforts to help users in detection of artificial content would often backfire and even increase skepticism about the nature of content. Edwards said in September 2024 that people are facing increasing difficulty in telling what's real from what's fake since the rise of political deepfakes.
In an article for Folha de S.Paulo, Eduardo Saron mentions one study by IA Pearl-Censuswide according to which 41% of Generation Z trust AI more than humans and 56% of millennials feel more comfortable asking questions to AIs instead of co-workers. In another study by Microsoft-Carnegie Mellon University, the rise in AI trust could be related to a decrease in critical thinking.

The right to reality may come also as a broader response to AI-related issues, since simply labeling AI content as such may not be enough to tackle broader problems such as diminishing trust in institutions and political processes.


== Applications ==
Frazier advocated in his article for a system of classification of internet content (similar to nutrition labels) that would inform users of the degree to which AI has or has not been used to create said content while also allowing users to even filter content according to their own preferences. He also wrote that the application of a right to reality "would not require the removal of any content nor discrimination based on the viewpoints asserted by that content" but would be "a disclosure requirement". He mentioned Lawrence Lessig's anticipation of the rise of AI-detection tools and that those would become prevalent in the media market.
Edwards supports the labeling of AI-generated content with methods such as watermarkings as proposed by the C2PA and the European Union's AI Act. However, Edwards herself and Fazier admit it may not be enough.
Speaking to Digital Frontier, Frazier said that "even the labelling of a right can have a big impact on the ability of people to advocate for the provision of that right" and compared the advocacy for it to citizens' assemblies.
Saron concedes both that there's no such thing as an "absolute reality", since according to him reality is always filtered by subjective, social and symbolic layers, and that the digital world can also create new realities or amplify existing ones.
The right to reality could take years to translate into actual legal developments, much like the right to privacy is still discussed over a hundred years after the publishing of "The Right to Privacy" or the right to repair, which emerged in the 20th century and was only incorporated in EU and US legislation in the 2020s.


== Limitations ==
Frazier analyses that a "right to reality" in the United States could conflict with the First Amendment. While, according to him, the U.S. Supreme Court has interpreted the Amendment as a guarantee of "an uninhibited marketplace of ideas in which truth will ultimately prevail", said marketplaces, such as social media platforms, will be overrun with AI content to the point that such guarantee is jeopardized if the right to reality is not taken into consideration.
On the other hand, he argues that because social media platforms are not yet seen as public forums by First Amendment jurisprudence, nor as state actors by the Court, "the right to reality may not find a legal home in the U.S. Constitution".
Lilian Edwards pondered that because most of the relevant social media platforms are hosted in the US, UK & Europe-based regulations and legislation are made harder.


== Criticism ==
Brazilian educational researcher Rafael Parente, while agreeing with most of Eduardo Saron's thoughts, believes that the right to reality should be expanded to the right to a "worthy hybrid reality", where human and machine would not be separate, but fairly integrated. Regarding Saron's "synthetic inequality" theory, Parente sees it as an opportunity for "expanded equity" instead, in that marginalized children would have access to the same study paths of students from more affluent regions, while teachers would have real experiences in real schools with assistance from virtual tutors.


== References ==