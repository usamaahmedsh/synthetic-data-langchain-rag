Velvet AI is a family of multilingual generative artificial intelligence models developed by Almawave, an Italian AI company. The Velvet models, including Velvet 14B and Velvet 2B, are foundational large language models (LLMs) designed and developed in Italy on Almawave's proprietary architecture. They were trained on the Leonardo supercomputer managed by CINECA and have been released in open-weight format. The Velvet models are designed to be energy-efficient. They support multiple languages, with an emphasis on Italian.


== Models ==


=== Velvet 2B ===
Velvet 2B, the model with 2 billion parameters, was trained in Italian and English on over 2 trillion tokens of data.


=== Velvet 14B ===
Velvet 14B was trained on over 4 trillion tokens across six languages, with Italian comprising approximately 23% of the data. In addition to linguistic data, Velvet incorporates over 400 billion tokens from more than 100 programming languages to facilitate more structured inferences. 
The development of Velvet AI reflects Almawave's strategic investment in creating high-performance, energy-efficient AI solutions that align with European regulatory frameworks. The models are ready to be used on major market platforms in the cloud, on-premise, and on the edge, and are integrated into Almawave's AIWave platform.


=== Velvet 25B ===


== References ==


== See also ==
CINECA
Istituto Italiano per lâ€™Intelligenza Artificiale (AI4I)