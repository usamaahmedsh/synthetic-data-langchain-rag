Artificial intelligence in healthcare is the application of artificial intelligence (AI) to analyze and understand complex medical and healthcare data. In some cases, it can exceed or augment human capabilities by providing better or faster ways to diagnose, treat, or prevent disease.
As the widespread use of artificial intelligence in healthcare is still relatively new, research is ongoing into its applications across various medical subdisciplines and related industries. AI programs are being applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. Since radiographs are the most commonly performed imaging tests in radiology, the potential for AI to assist with triage and interpretation of radiographs is particularly significant.
Using AI in healthcare presents unprecedented ethical concerns related to issues such as data privacy, automation of jobs, and amplifying already existing algorithmic bias. New technologies such as AI are often met with resistance by healthcare leaders, leading to slow and erratic adoption. There have been cases where AI has been put to use in healthcare without proper testing. A systematic review and thematic analysis in 2023 showed that most stakeholders including health professionals, patients, and the general public doubted that care involving AI could be empathetic. However, a 2025 systematic review and meta-analysis of 15 studies comparing AI chatbots with human healthcare professionals in text-based consultations found that in a large majority of studies participants rated chatbot responses as more empathic than those from clinicians. Meta-studies have found that the scientific literature on AI in healthcare often suffers from a lack of reproducibility.


== Applications in healthcare systems ==


=== Disease diagnosis ===
Accurate and early diagnosis of diseases is still a challenge in healthcare. Recognizing medical conditions and their symptoms is a complex problem. AI can assist clinicians with its data processing capabilities to save time and improve accuracy. Through the use of machine learning, artificial intelligence can be able to substantially aid doctors in patient diagnosis through the analysis of mass electronic health records (EHRs). AI can help early prediction, for example, of Alzheimer's disease and dementias, by looking through large numbers of similar cases and possible treatments.
Doctors' decision making could also be supported by AI in urgent situations, for example in the emergency department. Here AI algorithms can help prioritize more serious cases and reduce waiting time. Decision support systems augmented with AI can offer real-time suggestions and faster data interpretation to aid the decisions made by healthcare professionals.
In 2023 a study reported higher satisfaction rates with ChatGPT-generated responses compared with those from physicians for medical questions posted on Reddit's r/AskDocs. Evaluators preferred ChatGPT's responses to physician responses in 78.6% of 585 evaluations, noting better quality and empathy. The authors noted that these were isolated questions taken from an online forum, not in the context of an established patient-physician relationship. Moreover, responses were not graded on the accuracy of medical information, and some have argued that the experiment was not properly blinded, with the evaluators being coauthors of the study.
Recent developments in statistical physics, machine learning, and inference algorithms are also being explored for their potential in improving medical diagnostic approaches. Also, the establishment of large healthcare-related data warehouses of sometimes hundreds of millions of patients provides extensive training data for AI models.


=== Electronic health records ===
Electronic health records (EHR) are crucial to the digitalization and information spread of the healthcare industry. Now that around 80% of medical practices use EHR, some anticipate the use of artificial intelligence to interpret the records and provide new information to physicians.
One application uses natural language processing (NLP) to make more succinct reports that limit the variation between medical terms by matching similar medical terms. For example, the term heart attack and myocardial infarction mean the same things, but physicians may use one over the other based on personal preferences. NLP algorithms consolidate these differences so that larger datasets can be analyzed. Another use of NLP identifies phrases that are redundant due to repetition in a physician's notes and keeps the relevant information to make it easier to read. Other applications use concept processing to analyze the information entered by the current patient's doctor to present similar cases and help the physician remember to include all relevant details.
Beyond making content edits to an EHR, there are AI algorithms that evaluate an individual patient's record and predict a risk for a disease based on their previous information and family history. One general algorithm is a rule-based system that makes decisions similarly to how humans use flow charts. This system takes in large amounts of data and creates a set of rules that connect specific observations to concluded diagnoses. Thus, the algorithm can take in a new patient's data and try to predict the likelihood that they will have a certain condition or disease. Since the algorithms can evaluate a patient's information based on collective data, they can find any outstanding issues to bring to a physician's attention and save time. One study conducted by the Centerstone research institute found that predictive modeling of EHR data has achieved 70–72% accuracy in predicting individualized treatment response. These methods are helpful due to the fact that the amount of online health records doubles every five years. Physicians do not have the bandwidth to process all this data manually, and AI can leverage this data to assist physicians in treating their patients.


=== AlphaFold and drug discovery ===
AlphaFold has the ability to predict protein structures based on the constituent amino acid sequence, expected to have benefits in the life sciences--accelerating drug discovery and enabling better understanding of diseases. Nobel laureate Venki Ramakrishnan called the result "a stunning advance on the protein folding problem", adding that "It has occurred decades before many people in the field would have predicted. It will be exciting to see the many ways in which it will fundamentally change biological research." In 2023, Demis Hassabis and John Jumper won the Breakthrough Prize in Life Sciences as well as the Albert Lasker Award for Basic Medical Research for their management of the AlphaFold project. Hassabis and Jumper proceeded to win the Nobel Prize in Chemistry in 2024 for their work on "protein structure prediction" with David Baker of the University of Washington.


=== Drug interactions ===
Improvements in natural language processing led to the development of algorithms to identify drug-drug interactions in medical literature. Drug-drug interactions pose a threat to those taking multiple medications simultaneously, and the danger increases with the number of medications being taken. To address the difficulty of tracking all known or suspected drug-drug interactions, machine learning algorithms have been created to extract information on interacting drugs and their possible effects from medical literature. Efforts were consolidated in 2013 in the DDIExtraction Challenge, in which a team of researchers at Carlos III University assembled a corpus of literature on drug-drug interactions to form a standardized test for such algorithms. Competitors were tested on their ability to accurately determine, from the text, which drugs were shown to interact and what the characteristics of their interactions were. Researchers continue to use this corpus to standardize the measurement of the effectiveness of their algorithms.
Other algorithms identify drug-drug interactions from patterns in user-generated content, especially electronic health records and/or adverse event reports. Organizations such as the FDA Adverse Event Reporting System (FAERS) and the World Health Organization's VigiBase allow doctors to submit reports of possible negative reactions to medications. Deep learning algorithms have been developed to parse these reports and detect patterns that imply drug-drug interactions.


=== Telemedicine ===

The increase of telemedicine, the treatment of patients remotely, has shown the rise of possible AI applications. AI can assist in caring for patients remotely by monitoring their information through sensors. A wearable device may allow for constant monitoring of a patient and the ability to notice changes that may be less distinguishable by humans. The information can be compared to other data that has already been collected using artificial intelligence algorithms that alert physicians if there are any issues to be aware of.
Another application of artificial intelligence is chat-bot therapy. Some researchers charge that the reliance on chatbots for mental healthcare does not offer the reciprocity and accountability of care that should exist in the relationship between the consumer of mental healthcare and the care provider (be it a chat-bot or psychologist), though. Some examples of these chatbots include Woebot, Earkick and Wysa.
Since the average age has risen due to a longer life expectancy, artificial intelligence could be useful in helping take care of older populations. Tools such as environment and personal sensors can identify a person's regular activities and alert a caretaker if a behavior or a measured vital is abnormal. Although the technology is useful, there are also discussions about limitations of monitoring in order to respect a person's privacy since there are technologies that are designed to map out home layouts and detect human interactions.


=== Workload management ===
AI has the potential to streamline care coordination and reduce the workload. AI algorithms can automate administrative tasks, prioritize patient needs and facilitate seamless communication in a healthcare team. This enables healthcare providers to focus more on direct patient care and ensures the efficient and coordinated delivery of healthcare services.


== Clinical applications ==


=== Cardiovascular ===
Artificial intelligence algorithms have shown promising results in accurately diagnosing and risk stratifying patients with concern for coronary artery disease, showing potential as an initial triage tool. Other algorithms have been used in predicting patient mortality, medication effects, and adverse events following treatment for acute coronary syndrome. Wearables, smartphones, and internet-based technologies have also shown the ability to monitor patients' cardiac data points, expanding the amount of data and the various settings AI models can use and potentially enabling earlier detection of cardiac events occurring outside of the hospital. A research in 2019 found that AI can be used to predict heart attack with up to 90% accuracy. Another growing area of research is the utility of AI in classifying heart sounds and diagnosing valvular disease. Challenges of AI in cardiovascular medicine have included the limited data available to train machine learning models, such as limited data on social determinants of health as they pertain to cardiovascular disease.
A key limitation in early studies evaluating AI were omissions of data comparing algorithmic performance to humans. Examples of studies which assess AI performance relative to physicians includes how AI is non-inferior to humans in interpretation of cardiac echocardiograms and that AI can diagnose heart attack better than human physicians in the emergency setting, reducing both low-value testing and missed diagnoses.
In cardiovascular tissue engineering and organoid studies, AI is increasingly used to analyze microscopy images, and integrate electrophysiological read outs.


=== Dermatology ===
Medical imaging (such as X-ray and photography) is a commonly used tool in dermatology and the development of deep learning has been strongly tied to image processing. 

Han et al. showed keratinocytic skin cancer detection from face photographs. Esteva et al. demonstrated dermatologist-level classification of skin cancer from lesion images. Noyan et al. demonstrated a convolutional neural network that achieved 94% accuracy at identifying skin cells from microscopic Tzanck smear images.  Concerns have been raised, however, regarding the limited diversity of datasets, particularly the underrepresentation of darker skin tones, which may reduce generalizability across populations.
In addition to skin cancer detection and analysis of tissue samples of histological smears, AI has been applied to chronic and aesthetic dermatology. Consumer-facing platforms have extended these methods into digital health, offering remote evaluation and personalized treatment. For example, MDalgorithms has developed mobile applications such as MDacne, which uses a proprietary database of nearly one million acne images to grade acne severity from smartphone selfies and generate customized treatment regimens.
AI has also been applied to inflammatory skin conditions such as rosacea, where an AI-powered diagnostic tool was reported to achieve accuracy rates of approximately 88–90% in identifying the disorder, highlighting the potential for automated systems to support clinical assessment.
Similarly, MDhair applies AI analysis to scalp photographs to personalize hair loss treatments, with clinical trials reporting reductions in shedding, increased density, and improved scalp hydration.
A large study involving over one million individuals, described by Dermatology Times, further emphasized the value of AI-based systems in collecting extensive demographic and clinical data on skin and hair health, enabling the identification of population-level trends that may inform both research and patient care. 
This illustrate the broader applications of AI beyond diagnosis, including treatment personalization, remote monitoring, and enhanced access to dermatologic care.
Nevertheless, independent reviews have emphasized that many studies rely on context-free images rather than full clinical examinations, and performance comparisons often fail to distinguish between trainees and board-certified dermatologists.
According to some researchers, AI algorithms have been shown to be more effective than dermatologists at identifying cancer. However, a 2021 review article found that a majority of papers analyzing the performance of AI algorithms designed for skin cancer classification failed to use external test sets. Only four research studies were found in which the AI algorithms were tested on clinics, regions, or populations distinct from those it was trained on, and in each of those four studies, the performance of dermatologists was found to be on par with that of the algorithm. Moreover, only one study was set in the context of a full clinical examination; others were based on interaction through web-apps or online questionnaires, with most based entirely on context-free images of lesions. In this study, it was found that dermatologists significantly outperformed the algorithms. Many articles claiming superior performance of AI algorithms also fail to distinguish between trainees and board-certified dermatologists in their analyses.
It has also been suggested that AI could be used to automatically evaluate the outcome of maxillo-facial surgery or cleft palate therapy in regard to facial attractiveness or age appearance.


=== Gastroenterology ===
AI can play a role in various facets of the field of gastroenterology. Endoscopic exams such as esophagogastroduodenoscopies (EGD) and colonoscopies rely on rapid detection of abnormal tissue. By enhancing these endoscopic procedures with AI, clinicians can more rapidly identify diseases, determine their severity, and visualize blind spots. Early trials in using AI detection systems of early stomach cancer have shown sensitivity close to expert endoscopists.
AI can assist doctors treating ulcerative colitis in detecting the microscopic activity of the disease in people and predicting when flare-ups will happen. For example, an AI-powered tool was developed to analyse digitised bowel samples (biopsies). The tool was able to distinguish with 80% accuracy between samples that show remission of colitis and those with active disease. It also predicted the risk of a flare-up happening with the same accuracy. These rates of successfully using microscopic disease activity to predict disease flare are similar to the accuracy of pathologists.


=== Infectious diseases ===
AI has shown potential in both the laboratory and clinical spheres of infectious disease medicine. During the COVID-19 pandemic, AI has been used for early detection, tracking virus spread and analysing virus behaviour, among other things. However, there were only a few examples of AI being used directly in clinical practice during the pandemic itself.
Other applications of AI around infectious diseases include support-vector machines identifying antimicrobial resistance, machine learning analysis of blood smears to detect malaria, and improved point-of-care testing of Lyme disease based on antigen detection. Additionally, AI has been investigated for improving diagnosis of meningitis, sepsis, and tuberculosis, as well as predicting treatment complications in hepatitis B and hepatitis C patients.


=== Musculoskeletal ===
AI has been used to identify causes of knee pain that doctors miss, that disproportionately affect Black patients. Underserved populations experience higher levels of pain. These disparities persist even after controlling for the objective severity of diseases like osteoarthritis, as graded by human physicians using medical images, raising the possibility that underserved patients' pain stems from factors external to the knee, such as stress. Researchers have conducted a study using a machine-learning algorithm to show that standard radiographic measures of severity overlook objective but undiagnosed features that disproportionately affect diagnosis and management of underserved populations with knee pain. They proposed that new algorithmic measure ALG-P could potentially enable expanded access to treatments for underserved patients.


=== Neurology ===
The use of AI technologies has been explored for use in the diagnosis and prognosis of Alzheimer's disease (AD). For diagnostic purposes, machine learning models have been developed that rely on structural MRI inputs. The input datasets for these models are drawn from databases such as the Alzheimer's Disease Neuroimaging Initiative. Researchers have developed models that rely on convolutional neural networks with the aim of improving early diagnostic accuracy. Generative adversarial networks are a form of deep learning that have also performed well in diagnosing AD. There have also been efforts to develop machine learning models into forecasting tools that can predict the prognosis of patients with AD. Forecasting patient outcomes through generative models has been proposed by researchers as a means of synthesizing training and validation sets. They suggest that generated patient forecasts could be used to provide future models larger training datasets than current open access databases.


=== Obstetrics and gynaecology ===
Artificial intelligence utilises massive amounts of data to help with predicting illness, prevention, and diagnosis, as well as patient monitoring. In obstetrics, artificial intelligence is utilized in magnetic resonance imaging, ultrasound, and foetal cardiotocography. AI contributes in the resolution of a variety of obstetrical diagnostic issues.


=== Oncology ===
AI has been explored for use in cancer diagnosis, risk stratification, molecular characterization of tumors, and cancer drug discovery. A particular challenge in oncologic care that AI is being developed to address is the ability to accurately predict which treatment protocols will be best suited for each patient based on their individual genetic, molecular, and tumor-based characteristics. AI has been trialed in cancer diagnostics with the reading of imaging studies and pathology slides.
In January 2020, Google DeepMind announced an algorithm capable of surpassing human experts in breast cancer detection in screening scans. A number of researchers, including Trevor Hastie, Joelle Pineau, and Robert Tibshirani among others, published a reply claiming that DeepMind's research publication in Nature lacked key details on methodology and code, "effectively undermin[ing] its scientific value" and making it impossible for the scientific community to confirm the work. In the MIT Technology Review, author Benjamin Haibe-Kains characterized DeepMind's work as "an advertisement" having little to do with science.
In July 2020, it was reported that an AI algorithm developed by the University of Pittsburgh achieves the highest accuracy to date in identifying prostate cancer, with 98% sensitivity and 97% specificity. In 2023 a study reported the use of AI for CT-based radiomics classification at grading the aggressiveness of retroperitoneal sarcoma with 82% accuracy compared with 44% for lab analysis of biopsies.


=== Ophthalmology ===
Artificial intelligence-enhanced technology is being used as an aid in the screening of eye disease and prevention of blindness. In 2018, the U.S. Food and Drug Administration authorized the marketing of the first medical device to diagnose a specific type of eye disease, diabetic retinopathy using an artificial intelligence algorithm. Moreover, AI technology may be used to further improve "diagnosis rates" because of the potential to decrease detection time.


=== Pathology ===

For many diseases, pathological analysis of cells and tissues is considered to be the gold standard of disease diagnosis. Methods of digital pathology allows microscopy slides to be scanned and digitally analyzed. AI-assisted pathology tools have been developed to assist with the diagnosis of a number of diseases, including breast cancer, hepatitis B, gastric cancer, and colorectal cancer. AI has also been used to predict genetic mutations and prognosticate disease outcomes. AI is well-suited for use in low-complexity pathological analysis of large-scale screening samples, such as colorectal or breast cancer screening, thus lessening the burden on pathologists and allowing for faster turnaround of sample analysis. Several deep learning and artificial neural network models have shown accuracy similar to that of human pathologists, and a study of deep learning assistance in diagnosing metastatic breast cancer in lymph nodes showed that the accuracy of humans with the assistance of a deep learning program was higher than either the humans alone or the AI program alone. Additionally, implementation of digital pathology is predicted to save over $12 million for a university center over the course of five years, though savings attributed to AI specifically have not yet been widely researched. The use of augmented and virtual reality could prove to be a stepping stone to wider implementation of AI-assisted pathology, as they can highlight areas of concern on a pathology sample and present them in real-time to a pathologist for more efficient review. AI also has the potential to identify histological findings at levels beyond what the human eye can see, and has shown the ability to use genotypic and phenotypic data to more accurately detect the tumor of origin for metastatic cancer. One of the major current barriers to widespread implementation of AI-assisted pathology tools is the lack of prospective, randomized, multi-center controlled trials in determining the true clinical utility of AI for pathologists and patients, highlighting a current area of need in AI and healthcare research.


=== Pharmacy ===

In pharmacy, AI helps discover, develop and deliver medications, and can enhance patient care through personalized treatment plans.


=== Primary care ===
Primary care has become one key development area for AI technologies. AI in primary care has been used for supporting decision making, predictive modeling, and business analytics. There are only a few examples of AI decision support systems that were prospectively assessed on clinical efficacy when used in practice by physicians. But there are cases where the use of these systems yielded a positive effect on treatment choice by physicians.
As of 2022 in relation to elder care, AI robots had been helpful in guiding older residents living in assisted living with entertainment and company. These bots are allowing staff in the home to have more one-on-one time with each resident, but the bots are also programmed with more ability in what they are able to do; such as knowing different languages and different types of care depending on the patient's conditions. The bot is an AI machine, which means it goes through the same training as any other machine - using algorithms to parse the given data, learn from it and predict the outcome in relation to what situation is at hand.


=== Psychiatry ===
In psychiatry, AI applications are still in a phase of proof-of-concept. Areas where the evidence is widening quickly include predictive modelling of diagnosis and treatment outcomes, chatbots, conversational agents that imitate human behaviour and which have been studied for anxiety and depression.
Challenges include the fact that many applications in the field are developed and proposed by private corporations, such as the screening for suicidal ideation implemented by Facebook in 2017. Such applications outside the healthcare system raise various professional, ethical and regulatory questions. A 2025 study by Sentio University evaluated six major AI applications using scenarios involving suicide risk, self harm, and other high danger situations, and found that all systems produced responses that were at times incomplete, inconsistent, or clinically unsafe. Another issue is often with the validity and interpretability of the models. Small training datasets contain bias that is inherited by the models, and compromises the generalizability and stability of these models. Such models may also have the potential to be discriminatory against minority groups that are underrepresented in samples.
In 2023, US-based National Eating Disorders Association replaced its human helpline staff with a chatbot but had to take it offline after users reported receiving harmful advice from it.
According to a September study in 2025, people have turned to AI chatbots such as ChatGPT for emotional support in the case that traditional therapy with a person is unaffordable or inaccessible. From one instance a woman named Kristen Johansson had lost her therapist after insurance wouldn’t cover the plan, and her out of pocket payment wouldn’t be enough either. Many users say that chatbots provide non-biased, non-judgemental, and constant available help, with this input experts such as Dr. Jodi Halpern stated her concern that AI should support or compliment therapy structures instead of completely taking over in place of it. Concerns included lack of boundary and regulation, risks of unhealthy attachment to the program, and the ai chatbot failing to respond to health communication to professionals. 


=== Radiology ===
AI is being studied within the field of radiology to detect and diagnose diseases through computerized tomography (CT) and magnetic resonance (MR) imaging. It may be particularly useful in settings where demand for human expertise exceeds supply, or where data is too complex to be efficiently interpreted by human readers. Several deep learning models have shown the capability to be roughly as accurate as healthcare professionals in identifying diseases through medical imaging, though few of the studies reporting these findings have been externally validated. AI can also provide non-interpretive benefit to radiologists, such as reducing noise in images, creating high-quality images from lower doses of radiation, enhancing MR image quality, and automatically assessing image quality. Further research investigating the use of AI in nuclear medicine focuses on image reconstruction, anatomical landmarking, and the enablement of lower doses in imaging studies. The analysis of images for supervised AI applications in radiology encompasses two primary techniques at present: (1) convolutional neural network-based analysis; and (2) utilization of radiomics.
AI is also used in breast imaging for analyzing screening mammograms and can participate in improving breast cancer detection rate as well as reducing radiologist's reading workload.
As of 2025, 77% (967 out of 1247) of all FDA-approved AI-enabled medical devices are in radiology.


== Industry ==
The trend of large health companies merging has allowed for greater health data accessibility. Greater health data have laid the groundwork to implement AI algorithms.
A large part of industry focus has been in the clinical decision support systems. As more data is collected, machine learning algorithms adapt and allow for more robust responses and solutions. Numerous companies have been exploring the possibilities of the incorporation of big data in the healthcare industry, many of whom have been investigating market opportunities through "data assessment, storage, management, and analysis technologies".
With the market for AI expanding, large tech companies such as Apple, Google, Amazon, and Baidu all have their own AI research divisions, as well as millions of dollars allocated for acquisition of smaller AI based companies.


=== Large companies ===
The following are examples of large companies that are contributing to AI algorithms for use in healthcare:

The Deep Mind platform, bought by Google in 2014, has been used by the UK National Health Service to detect certain health risks through data collected via a mobile app. A second project with the NHS involves the analysis of medical images collected from NHS patients to develop computer vision algorithms to detect cancerous tissues.
IBM's Watson Oncology is in development at Memorial Sloan Kettering Cancer Center and Cleveland Clinic. IBM is also working with CVS Health on AI applications in chronic disease treatment and with Johnson & Johnson on analysis of scientific papers to find new connections for drug development. In May 2017, IBM and Rensselaer Polytechnic Institute began a joint project entitled Health Empowerment by Analytics, Learning and Semantics (HEALS)], to explore using AI technology to enhance healthcare.
GE Healthcare integrates AI across its imaging and patient monitoring portfolio. It uses deep learning to reconstruct MRI images, enhancing quality and reducing scan times, while embedding AI into core products to streamline workflows and deliver personalized care.
Intel's venture capital arm Intel Capital invested in 2016 in the startup Lumiata, which uses AI to identify at-risk patients and develop care options.
Siemens Healthineers applies AI in imaging and diagnostics, including algorithms to reconstruct CT images and guide ultrasound procedures. It also uses AI to support treatment planning such as radiation therapy for cancer, improve point-of-care diagnostics, and automate lab workflows.
Microsoft's Hanover project, in partnership with Oregon Health & Science University's Knight Cancer Institute, analyzes medical research to predict the most effective cancer drug treatment options for patients. Other projects include medical image analysis of tumor progression and the development of programmable cells.
Philips Healthcare develops AI-powered diagnostic tools that analyze medical images to detect subtle anomalies. Its AI technologies also support precision oncology by assisting pathologists in cancer diagnosis, care management, and patient monitoring.


=== Smaller companies, applications ===
Neuralink has come up with a next-generation neuroprosthetic which intricately interfaces with thousands of neural pathways in the brain. Their process allows a chip, roughly the size of a quarter, to be inserted in the place of a chunk of a skull by a precision surgical robot to avoid accidental injury.
Tencent has been working on several medical systems and services. These include AI Medical Innovation System (AIMIS), an AI-powered diagnostic medical imaging service; WeChat Intelligent Healthcare; and Tencent Doctorwork
Heidi Health develops an AI-powered medical scribe that transcribes clinician–patient conversations in real time and generates structured clinical notes. It has been adopted in multiple health systems, including MaineGeneral Health in the US.
The Indian startup Haptik developed a WhatsApp chatbot in 2021 which answered questions associated with COVID-19 in India. Similarly, a software platform ChatBot in partnership with health technology startup Infermedica launched COVID-19 Risk Assessment ChatBot.


== Expanding care to developing nations ==
Artificial intelligence continues to expand in its abilities to diagnose more people accurately in nations where fewer doctors are accessible to the public.  Many new technology companies such as SpaceX and the Raspberry Pi Foundation have enabled more developing countries to have access to computers and the internet than ever before. With the increasing capabilities of AI over the internet, advanced machine learning algorithms can allow patients to get accurately diagnosed when they would previously have no way of knowing if they had a life-threatening disease or not.
Using AI in developing nations that do not have the resources will diminish the need for outsourcing and can improve patient care. AI can allow for not only diagnosis of patient in areas where healthcare is scarce, but also allow for a good patient experience by resourcing files to find the best treatment for a patient. The ability of AI to adjust course as it goes also allows the patient to have their treatment modified based on what works for them; a level of individualized care that is nearly non-existent in developing countries.


== Regulation ==

Challenges of the clinical use of AI have brought about a potential need for regulations. AI studies need to be completely and transparently reported to have value to inform regulatory approval. Depending on the phase of study, international consensus-based reporting guidelines (TRIPOD+AI, DECIDE-AI, CONSORT-AI) have been developed to provide recommendations on the key details that need to be reported.

While regulations exist pertaining to the collection of patient data such as the Health Insurance Portability and Accountability Act in the US (HIPAA) and the European General Data Protection Regulation (GDPR) pertaining to patients within the EU, health care AI is "severely under-regulated worldwide" as of 2025.
Unclear is whether healthcare AI can be classified merely as software or as medical device.


=== United Nations (WHO/ITU) ===
The ITU-WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) has built a platform known as the ITU-WHO AI for Health Framework for the testing and benchmarking of AI applications in health domain as a joint endeavor of ITU and WHO. As of November 2018, eight use cases were being benchmarked, including assessing breast cancer risk from histopathological imagery, guiding anti-venom selection from snake images, and diagnosing skin lesions.


=== USA ===

In 2015, the Office for Civil Rights (OCR) issued rules and regulations to protect the privacy of individuals' health information, requiring healthcare providers to follow certain privacy rules when using AI, to keep a record of how they use AI and to ensure that their AI systems are secure.
In May 2016, the White House announced its plan to host a series of workshops and formation of the National Science and Technology Council (NSTC) Subcommittee on Machine Learning and Artificial Intelligence. In October 2016, the group published The National Artificial Intelligence Research and Development Strategic Plan, outlining its proposed priorities for Federally-funded AI research and development (within government and academia). The report notes a strategic R&D plan for the subfield of health information technology was in development stages.
In January 2021, the US FDA published a new Action Plan, entitled Artificial Intelligence (AI) /Machine Learning (ML)-Based Software as a Medical Device (SaMD) Action Plan. It layed out the FDA's future plans for regulation of medical devices that would include artificial intelligence in their software with five main actions: 1. Tailored Regulatory Framework for Ai/M:-based SaMD, 2. Good Machine Learning Practice (GMLP), 3. Patient-Centered Approach Incorporating Transparency to Users, 4. Regulatory Science Methods Related to Algorithm Bias & Robustness, and 5. Real-World Performance(RWP). This plan was in direct response to stakeholders' feedback on a 2019 discussion paper also published by the FDA.
Under President Biden the DHSS and the National Institute of Standards and Technology were instructed to develop regulation of healthcare AI.
According to the U.S. Department of Health and Human Services, the OCR issued guidance on the ethical use of AI in healthcare in 2021. It outlined four core ethical principles that must be followed: respect for autonomy, beneficence, non-maleficence, and justice. Respect for autonomy requires that individuals have control over their own data and decisions. Beneficence requires that AI be used to do good, such as improving the quality of care and reducing health disparities. Non-maleficence requires that AI be used to do no harm, such as avoiding discrimination in decisions. Finally, justice requires that AI be used fairly, such as using the same standards for decisions no matter a person's race, gender, or income level. As of March 2021, the OCR had hired a Chief Artificial Intelligence Officer (OCAIO) to pursue the "implementation of the HHS AI strategy".
With the second Trump administration deregulation of health AI began on January 20, 2025 with merely voluntary standards for collecting and sharing data, statutory definitions for algorithmic discrimination, automation bias, and equity being cancelled, cuts to NIST and 19% of FDA workforce eliminated.


=== Europe ===
Other countries have implemented data protection regulations, more specifically with company privacy invasions. In Denmark, the Danish Expert Group on data ethics has adopted recommendations on "Data for the Benefit of the People". These recommendations are intended to encourage the responsible use of data in the business sector, with a focus on data processing. The recommendations include a focus on equality and non-discrimination with regard to bias in AI, as well as human dignity which is to outweigh profit and must be respected in all data processes.
The European Union has implemented the General Data Protection Regulation (GDPR) to protect citizens' personal data, which applies to the use of AI in healthcare. In addition, the European Commission has established guidelines to ensure the ethical development of AI, including the use of algorithms to ensure fairness and transparency. With GDPR, the European Union was the first to regulate AI through data protection legislation. The Union finds privacy as a fundamental human right, it wants to prevent unconsented and secondary uses of data by private or public health facilities. By streamlining access to personal data for health research and findings, they are able to instate the right and importance of patient privacy. 
In March 2024, the European Union approved the pivotal Artificial Intelligence Act (AI Act). The regulation applies to European companies and organizations, and foreign providers of AI systems in the EU market. The EU AI Act has a risk-based structure, where AI enabled medical devices are in the "high-risk" category, the highest risk category of permitted uses for AI.
In the United States, the Health Insurance Portability and Accountability Act (HIPAA) requires organizations to protect the privacy and security of patient information. The Centers for Medicare and Medicaid Services have also released guidelines for the development of AI-based medical applications.
In 2025, Europe was leading the USA on AI regulation, while lagging in innovation and at least one California-based biotech company was "engaging the European Medicines Agency earlier in development than previously anticipated to mitigate concerns about the FDA's ability to meet development timelines."


== Ethical concerns ==
While research on the use of AI in healthcare aims to validate its efficacy in improving patient outcomes before its broader adoption, its use may introduce several new types of risk to patients and healthcare providers, such as algorithmic bias, Do not resuscitate implications, and other machine morality issues. AI may also compromise the protection of patients' rights, such as the right to informed consent and the right to medical data protection.


=== Privacy and data collection ===
In order to effectively train machine learning systems and use them in healthcare, massive amounts of data must be gathered. Acquiring this data, however, comes at the cost of patient privacy, which can be controversial. For example, a survey conducted in the UK estimated that 63% of the population is uncomfortable with sharing their personal data in order to improve AI technology. The scarcity of real, accessible patient data is a hindrance that deters the progress of developing and deploying more AI in healthcare.
The lack of regulations surrounding AI in the United States has generated concerns about mismanagement of patient data, such as with corporations utilizing patient data for financial gain. For example, as of 2020, the Swiss healthcare company Roche reportedly purchased healthcare data for approximately 2 million cancer patients at an estimated total cost of $1.9 billion. This generated ethical concerns about whether it was fair to sell patients' data, even considering the benefits. Ultimately, the current potential of AI in healthcare is additionally hindered by concerns about mismanagement of data collected, especially in the United States.
The use of large language models for healthcare consultations introduces particular privacy risks, such as increased exposure of sensitive health information during consultations that may be collected for model retraining. A 2024 study of 846 Chinese users found that while 77.3% expressed willingness to use LLM-based healthcare services, privacy awareness varied significantly by demographics and cultural context. The research revealed a "privacy paradox" where users who claimed greater privacy knowledge and concern actually showed higher acceptance of information sharing, potentially due to better understanding of legitimate uses such as academic research and service improvement.
Privacy expectations for LLMs vary significantly across cultural contexts. Research in China has shown that users may have different privacy norms compared to Western populations, with factors such as age, education level, and medical background influencing acceptance of data sharing. Younger and more educated users tend to be more privacy-conscious, while those with medical backgrounds show greater acceptance of health data sharing for legitimate medical purposes.


=== Technological unemployment ===

A systematic review and thematic analysis in 2023 showed that most stakeholders including health professionals, patients, and the general public doubted that care involving AI could be empathetic, or fulfill beneficence.
According to a 2019 study, AI can replace up to 35% of jobs in the UK within the next 10 to 20 years. However, of these jobs, it was concluded that AI has not eliminated any healthcare jobs so far. Though if AI were to automate healthcare-related jobs, the jobs most susceptible to automation would be those dealing with digital information, radiology, and pathology, as opposed to those dealing with doctor-to-patient interaction.
Outputs can be incorrect or incomplete and diagnosis and recommendations harm people.


=== Bias and discrimination ===
Since AI makes decisions solely on the data it receives as input, it is important that this data represents accurate patient demographics. In a hospital setting, patients do not have full knowledge of how predictive algorithms are created or calibrated. Therefore, these medical establishments can unfairly code their algorithms to discriminate against minorities and prioritize profits rather than providing optimal care, i.e. violating the ethical principle of social justice or non-maleficence. A recent scoping review identified 18 equity challenges along with 15 strategies that can be implemented to help address them when AI applications are developed using many-to-many mapping.
There can be unintended bias in algorithms that can exacerbate social and healthcare inequities. Since AI's decisions are a direct reflection of its input data, the data it receives must have accurate representation of patient demographics. For instance, if populations are less represented in healthcare data it is likely to create bias in AI tools that lead to incorrect assumptions of a demographic and impact the ability to provide appropriate care. White males are overly represented in medical data sets. Therefore, having minimal patient data on minorities can lead to AI making more accurate predictions for majority populations, leading to unintended worse medical outcomes for minority populations. Collecting data from minority communities can also lead to medical discrimination. For instance, HIV is a prevalent virus among minority communities and HIV status can be used to discriminate against patients. In addition to biases that may arise from sample selection, different clinical systems used to collect data may also impact AI functionality. For example, radiographic systems and their outcomes (e.g., resolution) vary by provider. Moreover, clinician work practices, such as the positioning of the patient for radiography, can also greatly influence the data and make comparability difficult. However, these biases are able to be eliminated through careful implementation and a methodical collection of representative data.
A final source of algorithmic bias, which has been called "label choice bias", arises when proxy measures are used to train algorithms, that build in bias against certain groups. For example, a widely used algorithm predicted health care costs as a proxy for health care needs, and used predictions to allocate resources to help patients with complex health needs. This introduced bias because Black patients have lower costs, even when they are just as unhealthy as White patients. Solutions to the "label choice bias" aim to match the actual target (what the algorithm is predicting) more closely to the ideal target (what researchers want the algorithm to predict), so for the prior example, instead of predicting cost, researchers would focus on the variable of healthcare needs which is rather more significant. Adjusting the target led to almost double the number of Black patients being selected for the program.


== History ==
Research in the 1960s and 1970s produced the first problem-solving program, or expert system, known as Dendral. While it was designed for applications in organic chemistry, it provided the basis for a subsequent system MYCIN, considered one of the most significant early uses of artificial intelligence in medicine. MYCIN and other systems such as INTERNIST-1 and CASNET did not achieve routine use by practitioners, however.
The 1980s and 1990s brought the proliferation of the microcomputer and new levels of network connectivity. During this time, there was a recognition by researchers and developers that AI systems in healthcare must be designed to accommodate the absence of perfect data and build on the expertise of physicians. Approaches involving fuzzy set theory, Bayesian networks, and artificial neural networks, have been applied to intelligent computing systems in healthcare.
Medical and technological advancements occurring over this half-century period that have enabled the growth of healthcare-related applications of AI to include: 

Improvements in computing power resulting in faster data collection and data processing
Growth of genomic sequencing databases
Widespread implementation of electronic health record systems
Improvements in natural language processing and computer vision, enabling machines to replicate human perceptual processes
Enhanced the precision of robot-assisted surgery
Increased tree-based machine learning models that allow flexibility in establishing health predictors
Improvements in deep learning techniques and data logs for rare diseases


== See also ==


== References ==


== Further reading ==


== External links ==
Artificial Intelligence in healthcare on europa.eu
Artificial Intelligence-Enabled Medical Devices on fda.gov