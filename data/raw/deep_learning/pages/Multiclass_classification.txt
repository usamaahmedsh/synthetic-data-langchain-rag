In machine learning and statistical classification, multiclass classification or multinomial classification is the problem of classifying instances into one of three or more classes (classifying instances into one of two classes is called binary classification). For example, deciding on whether an image is showing a banana, peach, orange, or an apple is a multiclass classification problem, with four possible classes (banana, peach, orange, apple), while deciding on whether an image contains an apple or not is a binary classification problem (with the two possible classes being: apple, no apple). 
While many classification algorithms (notably multinomial logistic regression) naturally permit the use of more than two classes, some are by nature binary algorithms; these can, however, be turned into multinomial classifiers by a variety of strategies.
Multiclass classification should not be confused with multi-label classification, where multiple labels are to be predicted for each instance (e.g., predicting that an image contains both an apple and an orange, in the previous example).


== Better-than-random multiclass models ==
From the confusion matrix of a multiclass model, we can determine whether a model does better than chance. Let 
  
    
      
        K
        ≥
        3
      
    
    {\displaystyle K\geq 3}
  
 be the number of classes, 
  
    
      
        
          
            O
          
        
      
    
    {\displaystyle {\mathcal {O}}}
  
 a set of observations, 
  
    
      
        
          
            
              y
              ^
            
          
        
        :
        
          
            O
          
        
        →
        {
        1
        ,
        .
        .
        .
        ,
        K
        }
      
    
    {\displaystyle {\hat {y}}:{\mathcal {O}}\to \{1,...,K\}}
  
 a model of the target variable 
  
    
      
        y
        :
        
          
            O
          
        
        →
        {
        1
        ,
        .
        .
        .
        ,
        K
        }
      
    
    {\displaystyle y:{\mathcal {O}}\to \{1,...,K\}}
  
 and 
  
    
      
        
          n
          
            i
            ,
            j
          
        
      
    
    {\displaystyle n_{i,j}}
  
 be the number of observations in the set 
  
    
      
        {
        y
        =
        i
        }
        ∩
        {
        
          
            
              y
              ^
            
          
        
        =
        j
        }
      
    
    {\displaystyle \{y=i\}\cap \{{\hat {y}}=j\}}
  
.
We note 
  
    
      
        
          n
          
            i
            .
          
        
        =
        
          ∑
          
            j
          
        
        
          n
          
            i
            ,
            j
          
        
      
    
    {\displaystyle n_{i.}=\sum _{j}n_{i,j}}
  
, 
  
    
      
        
          n
          
            .
            j
          
        
        =
        
          ∑
          
            i
          
        
        
          n
          
            i
            ,
            j
          
        
      
    
    {\displaystyle n_{.j}=\sum _{i}n_{i,j}}
  
, 
  
    
      
        n
        =
        
          ∑
          
            j
          
        
        
          n
          
            .
            j
          
        
        =
        
          ∑
          
            i
          
        
        
          n
          
            i
            .
          
        
      
    
    {\displaystyle n=\sum _{j}n_{.j}=\sum _{i}n_{i.}}
  
, 
  
    
      
        
          λ
          
            i
          
        
        =
        
          
            
              n
              
                i
                .
              
            
            n
          
        
      
    
    {\displaystyle \lambda _{i}={\frac {n_{i.}}{n}}}
  
 and  
  
    
      
        
          μ
          
            j
          
        
        =
        
          
            
              n
              
                .
                j
              
            
            n
          
        
      
    
    {\displaystyle \mu _{j}={\frac {n_{.j}}{n}}}
  
. It is assumed that the confusion matrix 
  
    
      
        (
        
          n
          
            i
            ,
            j
          
        
        
          )
          
            i
            ,
            j
          
        
      
    
    {\displaystyle (n_{i,j})_{i,j}}
  
 contains at least one non-zero entry in each row, that is 
  
    
      
        
          λ
          
            i
          
        
        >
        0
      
    
    {\displaystyle \lambda _{i}>0}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
. Finally we call "normalized confusion matrix" the matrix of conditional probabilities 
  
    
      
        (
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        i
        )
        
          )
          
            i
            ,
            j
          
        
        =
        
          
            (
            
              
                
                  n
                  
                    i
                    ,
                    j
                  
                
                
                  n
                  
                    i
                    .
                  
                
              
            
            )
          
          
            i
            ,
            j
          
        
      
    
    {\displaystyle (\mathbb {P} ({\hat {y}}=j\mid y=i))_{i,j}=\left({\frac {n_{i,j}}{n_{i.}}}\right)_{i,j}}
  
.


=== Intuitive explanation ===
The lift is a way of measuring the deviation from independence of two events 
  
    
      
        A
      
    
    {\displaystyle A}
  
 and 
  
    
      
        B
      
    
    {\displaystyle B}
  
 : 

  
    
      
        
          L
          i
          f
          t
        
        (
        A
        ,
        B
        )
        =
        
          
            
              
                P
              
              (
              A
              ∩
              B
              )
            
            
              
                P
              
              (
              A
              )
              
                P
              
              (
              B
              )
            
          
        
        =
        
          
            
              
                P
              
              (
              A
              ∣
              B
              )
            
            
              
                P
              
              (
              A
              )
            
          
        
        =
        
          
            
              
                P
              
              (
              B
              ∣
              A
              )
            
            
              
                P
              
              (
              B
              )
            
          
        
      
    
    {\displaystyle \mathrm {Lift} (A,B)={\frac {\mathbb {P} (A\cap B)}{\mathbb {P} (A)\mathbb {P} (B)}}={\frac {\mathbb {P} (A\mid B)}{\mathbb {P} (A)}}={\frac {\mathbb {P} (B\mid A)}{\mathbb {P} (B)}}}
  

We have 
  
    
      
        
          L
          i
          f
          t
        
        (
        A
        ,
        B
        )
        >
        1
      
    
    {\displaystyle \mathrm {Lift} (A,B)>1}
  
 if and only if events 
  
    
      
        A
      
    
    {\displaystyle A}
  
 and 
  
    
      
        B
      
    
    {\displaystyle B}
  
 occur simultaneously with a greater probability than if they were independent. In other words, if one of the two events occurs, the probability of observing the other event increases.
A first condition to satisfy is to have 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        i
        ,
        
          
            
              y
              ^
            
          
        
        =
        i
        )
        ≥
        1
      
    
    {\displaystyle \mathrm {Lift} (y=i,{\hat {y}}=i)\geq 1}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
. And the quality of a model (better or worse than chance) does not change if we over- or undersample the dataset, that is if we multiply each row 
  
    
      
        
          R
          
            i
          
        
      
    
    {\displaystyle R_{i}}
  
 of the confusion matrix by a constant 
  
    
      
        
          c
          
            i
          
        
      
    
    {\displaystyle c_{i}}
  
. Thus the second condition is that the necessary and sufficient conditions for doing better than chance need only depend on the normalized confusion matrix.
The condition on lifts can be reformulated with One versus Rest binary models : for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
, we define the binary target variable 
  
    
      
        
          y
          
            i
          
        
      
    
    {\displaystyle y_{i}}
  
 which is the indicator of event 
  
    
      
        {
        y
        =
        i
        }
      
    
    {\displaystyle \{y=i\}}
  
, and the binary model 
  
    
      
        
          
            
              
                y
                ^
              
            
          
          
            i
          
        
      
    
    {\displaystyle {\hat {y}}_{i}}
  
 of 
  
    
      
        
          y
          
            i
          
        
      
    
    {\displaystyle y_{i}}
  
 which is the indicator of event 
  
    
      
        {
        
          
            
              y
              ^
            
          
        
        =
        i
        }
      
    
    {\displaystyle \{{\hat {y}}=i\}}
  
. Each of the 
  
    
      
        
          
            
              
                y
                ^
              
            
          
          
            i
          
        
      
    
    {\displaystyle {\hat {y}}_{i}}
  
 models is a "One versus Rest" model. 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        i
        ,
        
          
            
              y
              ^
            
          
        
        =
        i
        )
      
    
    {\displaystyle \mathrm {Lift} (y=i,{\hat {y}}=i)}
  
 only depends on the events 
  
    
      
        {
        y
        =
        i
        }
      
    
    {\displaystyle \{y=i\}}
  
 and 
  
    
      
        {
        
          
            
              y
              ^
            
          
        
        =
        i
        }
      
    
    {\displaystyle \{{\hat {y}}=i\}}
  
, so merging or not merging the other classes doesn't change its value. We therefore have 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        i
        ,
        
          
            
              y
              ^
            
          
        
        =
        i
        )
        =
        
          L
          i
          f
          t
        
        (
        
          y
          
            i
          
        
        =
        1
        ,
        
          
            
              
                y
                ^
              
            
          
          
            i
          
        
        =
        1
        )
      
    
    {\displaystyle \mathrm {Lift} (y=i,{\hat {y}}=i)=\mathrm {Lift} (y_{i}=1,{\hat {y}}_{i}=1)}
  
 and the first condition is that all binary One versus Rest models are better than chance.


==== Example ====
If 
  
    
      
        K
        =
        2
      
    
    {\displaystyle K=2}
  
 and 2 is the class of interest , the normalized confusion matrix is 
  
    
      
        
          
            (
            
              
                
                  
                    s
                    p
                    e
                    c
                    i
                    f
                    i
                    c
                    i
                    t
                    y
                  
                
                
                  1
                  −
                  
                    s
                    p
                    e
                    c
                    i
                    f
                    i
                    c
                    i
                    t
                    y
                  
                
              
              
                
                  1
                  −
                  
                    s
                    e
                    n
                    s
                    i
                    t
                    i
                    v
                    i
                    t
                    y
                  
                
                
                  
                    s
                    e
                    n
                    s
                    i
                    t
                    i
                    v
                    i
                    t
                    y
                  
                
              
            
            )
          
        
      
    
    {\displaystyle {\begin{pmatrix}\mathrm {specificity} &1-\mathrm {specificity} \\1-\mathrm {sensitivity} &\mathrm {sensitivity} \end{pmatrix}}}
  
  and we have 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        1
        ,
        
          
            
              y
              ^
            
          
        
        =
        1
        )
        −
        1
        =
        
          
            
              
                P
              
              (
              y
              =
              
                
                  
                    y
                    ^
                  
                
              
              =
              1
              )
            
            
              
                λ
                
                  1
                
              
              
                μ
                
                  1
                
              
            
          
        
        −
        1
        =
        
          
            
              
                n
                
                  1
                  ,
                  1
                
              
              n
            
            
              
                n
                
                  1.
                
              
              
                n
                
                  .1
                
              
            
          
        
        −
        1
      
    
    {\displaystyle \mathrm {Lift} (y=1,{\hat {y}}=1)-1={\frac {\mathbb {P} (y={\hat {y}}=1)}{\lambda _{1}\mu _{1}}}-1={\frac {n_{1,1}n}{n_{1.}n_{.1}}}-1}
  
 
  
    
      
        =
        
          
            
              
                n
                
                  1
                  ,
                  1
                
              
              (
              
                n
                
                  1
                  ,
                  1
                
              
              +
              
                n
                
                  1
                  ,
                  2
                
              
              +
              
                n
                
                  2
                  ,
                  1
                
              
              +
              
                n
                
                  2
                  ,
                  2
                
              
              )
              −
              (
              
                n
                
                  1
                  ,
                  1
                
              
              +
              
                n
                
                  1
                  ,
                  2
                
              
              )
              (
              
                n
                
                  1
                  ,
                  1
                
              
              +
              
                n
                
                  2
                  ,
                  1
                
              
              )
            
            
              
                n
                
                  1.
                
              
              
                n
                
                  .1
                
              
            
          
        
        =
        
          
            
              
                n
                
                  1
                  ,
                  1
                
              
              
                n
                
                  2
                  ,
                  2
                
              
              −
              
                n
                
                  1
                  ,
                  2
                
              
              
                n
                
                  2
                  ,
                  1
                
              
            
            
              
                n
                
                  1.
                
              
              
                n
                
                  .1
                
              
            
          
        
      
    
    {\displaystyle ={\frac {n_{1,1}(n_{1,1}+n_{1,2}+n_{2,1}+n_{2,2})-(n_{1,1}+n_{1,2})(n_{1,1}+n_{2,1})}{n_{1.}n_{.1}}}={\frac {n_{1,1}n_{2,2}-n_{1,2}n_{2,1}}{n_{1.}n_{.1}}}}
  
. Thus 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        1
        ,
        
          
            
              y
              ^
            
          
        
        =
        1
        )
        ≥
        1
        
        ⟺
        
        
          n
          
            1
            ,
            1
          
        
        
          n
          
            2
            ,
            2
          
        
        −
        
          n
          
            1
            ,
            2
          
        
        
          n
          
            2
            ,
            1
          
        
        ≥
        0
      
    
    {\displaystyle \mathrm {Lift} (y=1,{\hat {y}}=1)\geq 1\iff n_{1,1}n_{2,2}-n_{1,2}n_{2,1}\geq 0}
  
. Similarly, by swapping the roles of 1 and 2, we find that 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        2
        ,
        
          
            
              y
              ^
            
          
        
        =
        2
        )
        ≥
        1
        
        ⟺
        
        
          n
          
            1
            ,
            1
          
        
        
          n
          
            2
            ,
            2
          
        
        −
        
          n
          
            1
            ,
            2
          
        
        
          n
          
            2
            ,
            1
          
        
        ≥
        0
      
    
    {\displaystyle \mathrm {Lift} (y=2,{\hat {y}}=2)\geq 1\iff n_{1,1}n_{2,2}-n_{1,2}n_{2,1}\geq 0}
  
. Dividing by 
  
    
      
        
          n
          
            1.
          
        
        
          n
          
            2.
          
        
      
    
    {\displaystyle n_{1.}n_{2.}}
  
 we find that the necessary and sufficient condition on the normalized confusion matrix is 
  
    
      
        
          s
          e
          n
          s
          i
          t
          i
          v
          i
          t
          y
        
         
        
          s
          p
          e
          c
          i
          f
          i
          c
          i
          t
          y
        
        −
        (
        1
        −
        
          s
          e
          n
          s
          i
          t
          i
          v
          i
          t
          y
        
        )
        (
        1
        −
        
          s
          p
          e
          c
          i
          f
          i
          c
          i
          t
          y
        
        )
        ≥
        0
        
        ⟺
        
        
          s
          e
          n
          s
          i
          t
          i
          v
          i
          t
          y
        
        +
        
          s
          p
          e
          c
          i
          f
          i
          c
          i
          t
          y
        
        −
        1
        ≥
        0
        
        ⟺
        
        J
        ≥
        0
      
    
    {\displaystyle \mathrm {sensitivity} \ \mathrm {specificity} -(1-\mathrm {sensitivity} )(1-\mathrm {specificity} )\geq 0\iff \mathrm {sensitivity} +\mathrm {specificity} -1\geq 0\iff J\geq 0}
  
. This brings us back to the classical binary condition: Youden's J must be positive (or zero for random models).


=== Random models ===
A random model is a model that is independent of the target variable. This property is easily reformulated with the confusion matrix.

This proposition shows that the model 
  
    
      
        
          
            
              y
              ^
            
          
        
      
    
    {\displaystyle {\hat {y}}}
  
 of 
  
    
      
        y
      
    
    {\displaystyle y}
  
 is uninformative if and only if there are two families of numbers 
  
    
      
        (
        
          α
          
            i
          
        
        
          )
          
            i
          
        
      
    
    {\displaystyle (\alpha _{i})_{i}}
  
 and 
  
    
      
        (
        
          β
          
            j
          
        
        
          )
          
            j
          
        
      
    
    {\displaystyle (\beta _{j})_{j}}
  
 such that 
  
    
      
        
          P
        
        (
        {
        y
        =
        i
        }
        ∩
        {
        
          
            
              y
              ^
            
          
        
        =
        j
        }
        )
        =
        
          α
          
            i
          
        
        
          β
          
            j
          
        
      
    
    {\displaystyle \mathbb {P} (\{y=i\}\cap \{{\hat {y}}=j\})=\alpha _{i}\beta _{j}}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        j
      
    
    {\displaystyle j}
  
.  


=== Multiclass likelihood ratios and diagnostic odds ratios ===
We define generalized likelihood ratios calculated from the normalized confusion matrix: for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        j
        ≠
        i
      
    
    {\displaystyle j\not =i}
  
, let

  
    
      
        
          
            L
            R
          
          
            i
            ,
            j
          
        
        =
        
          
            
              
                P
              
              (
              
                
                  
                    y
                    ^
                  
                
              
              =
              j
              ∣
              y
              =
              j
              )
            
            
              
                P
              
              (
              
                
                  
                    y
                    ^
                  
                
              
              =
              j
              ∣
              y
              =
              i
              )
            
          
        
      
    
    {\displaystyle \mathrm {LR} _{i,j}={\frac {\mathbb {P} ({\hat {y}}=j\mid y=j)}{\mathbb {P} ({\hat {y}}=j\mid y=i)}}}
  
. When 
  
    
      
        K
        =
        2
      
    
    {\displaystyle K=2}
  
, if 2 is the class of interest,, we find the classical likelihood ratios 
  
    
      
        
          
            L
            R
          
          
            1
            ,
            2
          
        
        =
        
          
            L
            R
          
          
            +
          
        
      
    
    {\displaystyle \mathrm {LR} _{1,2}=\mathrm {LR} _{+}}
  
 and 
  
    
      
        
          
            L
            R
          
          
            2
            ,
            1
          
        
        =
        
          
            1
            
              
                L
                R
              
              
                −
              
            
          
        
      
    
    {\displaystyle \mathrm {LR} _{2,1}={\frac {1}{\mathrm {LR} _{-}}}}
  
. Multiclass diagnostic odds ratios can also be defined using the formula  

  
    
      
        
          
            D
            O
            R
          
          
            i
            ,
            j
          
        
        =
        
          
            D
            O
            R
          
          
            j
            ,
            i
          
        
        =
        
          
            L
            R
          
          
            i
            ,
            j
          
        
        
          
            L
            R
          
          
            j
            ,
            i
          
        
        =
        
          
            
              
                n
                
                  i
                  ,
                  i
                
              
              
                n
                
                  j
                  ,
                  j
                
              
            
            
              
                n
                
                  i
                  ,
                  j
                
              
              
                n
                
                  j
                  ,
                  i
                
              
            
          
        
        =
        
          
            
              
                P
              
              (
              
                
                  
                    y
                    ^
                  
                
              
              =
              j
              ∣
              y
              =
              j
              )
              
                /
              
              
                P
              
              (
              
                
                  
                    y
                    ^
                  
                
              
              =
              i
              ∣
              y
              =
              j
              )
            
            
              
                P
              
              (
              
                
                  
                    y
                    ^
                  
                
              
              =
              j
              ∣
              y
              =
              i
              )
              
                /
              
              
                P
              
              (
              
                
                  
                    y
                    ^
                  
                
              
              =
              i
              ∣
              y
              =
              i
              )
            
          
        
      
    
    {\displaystyle \mathrm {DOR} _{i,j}=\mathrm {DOR} _{j,i}=\mathrm {LR} _{i,j}\mathrm {LR} _{j,i}={\frac {n_{i,i}n_{j,j}}{n_{i,j}n_{j,i}}}={\frac {\mathbb {P} ({\hat {y}}=j\mid y=j)/\mathbb {P} ({\hat {y}}=i\mid y=j)}{\mathbb {P} ({\hat {y}}=j\mid y=i)/\mathbb {P} ({\hat {y}}=i\mid y=i)}}}
  

We saw above that a better-than-chance model (or a random model) must verify 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        i
        ,
        
          
            
              y
              ^
            
          
        
        =
        i
        )
        ≥
        1
      
    
    {\displaystyle \mathrm {Lift} (y=i,{\hat {y}}=i)\geq 1}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        
          λ
          
            i
          
        
      
    
    {\displaystyle \lambda _{i}}
  
. According to the previous corollary, likelihood ratios are thus greater than or equal to 1. Conversely, if the likelihood ratios are greater than or equal to 1, the theorem shows that we have 
  
    
      
        
          L
          i
          f
          t
        
        (
        y
        =
        i
        ,
        
          
            
              y
              ^
            
          
        
        =
        i
        )
        ≥
        1
      
    
    {\displaystyle \mathrm {Lift} (y=i,{\hat {y}}=i)\geq 1}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        
          λ
          
            i
          
        
      
    
    {\displaystyle \lambda _{i}}
  
.


=== Definition of better-than-chance multiclass models ===
A model 
  
    
      
        
          
            
              y
              ^
            
          
        
      
    
    {\displaystyle {\hat {y}}}
  
 of 
  
    
      
        y
      
    
    {\displaystyle y}
  
 outperforms chance if the following conditions are met:

For any 
  
    
      
        j
      
    
    {\displaystyle j}
  
, we have 
  
    
      
        
          max
          
            i
          
        
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        i
        )
        =
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        j
        )
      
    
    {\displaystyle \max _{i}\mathbb {P} ({\hat {y}}=j\mid y=i)=\mathbb {P} ({\hat {y}}=j\mid y=j)}
  
.
There are i and j distinct such that 
  
    
      
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        i
        )
        <
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        j
        )
      
    
    {\displaystyle \mathbb {P} ({\hat {y}}=j\mid y=i)<\mathbb {P} ({\hat {y}}=j\mid y=j)}
  
.
If all the entries of the confusion matrix are non-zero, this means that all the likelihood ratios are greater than or equal to 1, and at least one of these inegalities is strict. A model that satisfies the first condition but not the second is random, since we then have 
  
    
      
        
          P
        
        (
        {
        
          
            
              y
              ^
            
          
        
        =
        j
        }
        ∩
        {
        y
        =
        i
        }
        )
        =
        
          P
        
        (
        y
        =
        i
        )
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        i
        )
        =
        
          P
        
        (
        y
        =
        i
        )
        
          P
        
        (
        
          
            
              y
              ^
            
          
        
        =
        j
        ∣
        y
        =
        j
        )
        =
        
          α
          
            i
          
        
        
          β
          
            j
          
        
      
    
    {\displaystyle \mathbb {P} (\{{\hat {y}}=j\}\cap \{y=i\})=\mathbb {P} (y=i)\mathbb {P} ({\hat {y}}=j\mid y=i)=\mathbb {P} (y=i)\mathbb {P} ({\hat {y}}=j\mid y=j)=\alpha _{i}\beta _{j}}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
 and 
  
    
      
        j
      
    
    {\displaystyle j}
  
.
We can rewrite the first condition in a more familiar way, noting 
  
    
      
        x
      
    
    {\displaystyle x}
  
 the observed value of 
  
    
      
        
          
            
              y
              ^
            
          
        
      
    
    {\displaystyle {\hat {y}}}
  
, 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 the value to be estimated of 
  
    
      
        y
      
    
    {\displaystyle y}
  
 and 
  
    
      
        
          
            
              θ
              ^
            
          
        
        (
        x
        )
      
    
    {\displaystyle {\hat {\theta }}(x)}
  
 the set 
  
    
      
        a
        r
        g
        m
        a
        
          x
          
            θ
          
        
        
          P
        
        (
        x
        ∣
        θ
        )
      
    
    {\displaystyle argmax_{\theta }\mathbb {P} (x\mid \theta )}
  
: for any 
  
    
      
        x
      
    
    {\displaystyle x}
  
 we have 
  
    
      
        x
        ∈
        
          
            
              θ
              ^
            
          
        
        (
        x
        )
      
    
    {\displaystyle x\in {\hat {\theta }}(x)}
  
. We deduce that a model is better-than-random or random if and only if it is a maximum likelihood estimator of the target variable.


=== Applications ===


==== Multiclass balanced accuracy ====
The performance of a better-than-chance model can be estimated using multiclass versions of metrics such as balanced accuracy or Youden's 
  
    
      
        J
      
    
    {\displaystyle J}
  
.

If 
  
    
      
        
          b
          a
          l
          a
          n
          c
          e
          d
           
          a
          c
          c
          u
          r
          a
          c
          y
        
        =
        1
      
    
    {\displaystyle \mathrm {balanced\ accuracy} =1}
  
, in other words 
  
    
      
        J
        =
        1
      
    
    {\displaystyle J=1}
  
, the model is perfect. And for any random model, we have 
  
    
      
        
          b
          a
          l
          a
          n
          c
          e
          d
           
          a
          c
          c
          u
          r
          a
          c
          y
        
        =
        
          
            1
            K
          
        
      
    
    {\displaystyle \mathrm {balanced\ accuracy} ={\frac {1}{K}}}
  
 (if, for example, we draw a uniform random number from the 
  
    
      
        K
      
    
    {\displaystyle K}
  
 labels, we have exactly one chance in 
  
    
      
        K
      
    
    {\displaystyle K}
  
 of predicting the correct value of the target variable).
On a balanced data set (
  
    
      
        
          λ
          
            i
          
        
        =
        
          
            1
            K
          
        
      
    
    {\displaystyle \lambda _{i}={\frac {1}{K}}}
  
 for any 
  
    
      
        i
      
    
    {\displaystyle i}
  
), balanced accuracy is equal to the rate of well-classified observations. On any data set, if a model does better than chance, we have 
  
    
      
        J
        ≥
        0
      
    
    {\displaystyle J\geq 0}
  
 and 
  
    
      
        
          b
          a
          l
          a
          n
          c
          e
          d
           
          a
          c
          c
          u
          r
          a
          c
          y
        
        ≥
        
          
            1
            K
          
        
      
    
    {\displaystyle \mathrm {balanced\ accuracy} \geq {\frac {1}{K}}}
  
. But the converse is not true when 
  
    
      
        K
        >
        2
      
    
    {\displaystyle K>2}
  
, as we can see from this example: the confusion matrix 
  
    
      
        
          
            (
            
              
                
                  0
                
                
                  3
                
                
                  0
                
              
              
                
                  1
                
                
                  2
                
                
                  0
                
              
              
                
                  0
                
                
                  0
                
                
                  3
                
              
            
            )
          
        
      
    
    {\displaystyle {\begin{pmatrix}0&3&0\\1&2&0\\0&0&3\end{pmatrix}}}
  
 is that of a bad model (=worse than chance) since 
  
    
      
        
          
            L
            R
          
          
            2
            ,
            1
          
        
        =
        0
      
    
    {\displaystyle \mathrm {LR} _{2,1}=0}
  
.  However, 5 of the 9 observations are correctly classified. This also shows that poor model performance on one of the modalities is not compensated for by good performance on the other modalities.


==== ROC space ====
The set of normalized confusion matrices is called the ROC space, a subspace of 
  
    
      
        
          
            [
          
        
        0
        ,
        1
        
          
            
              ]
            
          
          
            
              m
              
                2
              
            
          
        
      
    
    {\displaystyle {\mathopen {[}}0,1{\mathclose {]}}^{m^{2}}}
  
. If 
  
    
      
        E
      
    
    {\displaystyle E}
  
 denotes the subset of the ROC space made up of random models or models that do better than chance, one can show that the topological boundary of 
  
    
      
        E
      
    
    {\displaystyle E}
  
 is the set of elements of 
  
    
      
        E
      
    
    {\displaystyle E}
  
 for which at least one of the likelihood ratios is equal to 1. And random models are those models whose likelihood ratios are all equal to 1. When 
  
    
      
        K
        =
        2
      
    
    {\displaystyle K=2}
  
, the boundary between models that do better than chance and bad models is equal to the set of random models (see article on the roc curve for more details), but it is strictly larger as soon as 
  
    
      
        K
        >
        2
      
    
    {\displaystyle K>2}
  
. And if 
  
    
      
        K
        =
        3
      
    
    {\displaystyle K=3}
  
, we can calculate the volume occupied by bad models in the ROC space: they occupy 90% of this space, whereas it's only 50% when 
  
    
      
        K
        =
        2
      
    
    {\displaystyle K=2}
  
.


== General algorithmic strategies ==

The existing multi-class classification techniques can be categorised into

transformation to binary
extension from binary
hierarchical classification.


=== Transformation to binary ===
This section discusses strategies for reducing the problem of multiclass classification to multiple binary classification problems. It can be categorized into one vs rest and one vs one. The techniques developed based on reducing the multi-class problem into multiple binary problems can also be called problem transformation techniques.


==== One-vs.-rest ====
One-vs.-rest (OvR or one-vs.-all, OvA or one-against-all, OAA) strategy involves training a single classifier per class, with the samples of that class as positive samples and all other samples as negatives. This strategy requires the base classifiers to produce a real-valued score for its decision (see also scoring rule), rather than just a class label; discrete class labels alone can lead to ambiguities, where multiple classes are predicted for a single sample.
In pseudocode, the training algorithm for an OvR learner constructed from a binary classification learner L is as follows:

Inputs:
L, a learner (training algorithm for binary classifiers)
samples X
labels y where yi ∈ {1, … K} is the label for the sample Xi
Output:
a list of classifiers fk for k ∈ {1, …, K}
Procedure:
For each k in {1, …, K}
Construct a new label vector z where zi  = yi  if yi = k and  zi = 0 otherwise
Apply L to X, z to obtain fk
Making decisions means applying all classifiers to an unseen sample x and predicting the label k for which the corresponding classifier reports the highest confidence score:

  
    
      
        
          
            
              y
              ^
            
          
        
        =
        
          
            
              arg
              
              max
            
            
              k
              ∈
              {
              1
              …
              K
              }
            
          
        
        
        
          f
          
            k
          
        
        (
        x
        )
      
    
    {\displaystyle {\hat {y}}={\underset {k\in \{1\ldots K\}}{\arg \!\max }}\;f_{k}(x)}
  

Although this strategy is popular, it is a heuristic that suffers from several problems. Firstly, the scale of the confidence values may differ between the binary classifiers. Second, even if the class distribution is balanced in the training set, the binary classification learners see unbalanced distributions because typically the set of negatives they see is much larger than the set of positives.


==== One-vs.-one ====
In the one-vs.-one (OvO) reduction, one trains K (K − 1) / 2 binary classifiers for a K-way multiclass problem; each receives the samples of a pair of classes from the original training set, and must learn to distinguish these two classes. At prediction time, a voting scheme is applied: all K (K − 1) / 2 classifiers are applied to an unseen sample and the class that got the highest number of "+1" predictions gets predicted by the combined classifier.
Like OvR, OvO suffers from ambiguities in that some regions of its input space may receive the same number of votes.


=== Extension from binary ===
This section discusses strategies of extending the existing binary classifiers to solve multi-class classification problems. Several algorithms have been developed based on neural networks, decision trees, k-nearest neighbors, naive Bayes, support vector machines and extreme learning machines to address multi-class classification problems. These types of techniques can also be called algorithm adaptation techniques.


==== Neural networks ====
Multiclass perceptrons provide a natural extension to the multi-class problem. Instead of just having one neuron in the output layer, with binary output, one could have N binary neurons leading to multi-class classification. In practice, the last layer of a neural network is usually a softmax function layer, which is the algebraic simplification of N logistic classifiers, normalized per class by the sum of the N-1 other logistic classifiers. Neural Network-based classification has brought significant improvements and scopes for thinking from different perspectives.


===== Extreme learning machines =====
Extreme learning machines (ELM) is a special case of single hidden layer feed-forward neural networks (SLFNs) wherein the input weights and the hidden node biases can be chosen at random. Many variants and developments are made to the ELM for multiclass classification.


==== k-nearest neighbours ====
k-nearest neighbors kNN is considered among the oldest non-parametric classification algorithms. To classify an unknown example, the distance from that example to every other training example is measured. The k smallest distances are identified, and the most represented class by these k nearest neighbours is considered the output class label.


==== Naive Bayes ====
Naive Bayes is a successful classifier based upon the principle of maximum a posteriori (MAP). This approach is naturally extensible to the case of having more than two classes, and was shown to perform well in spite of the underlying simplifying assumption of conditional independence.


==== Decision trees ====
Decision tree learning is a powerful classification technique. The tree tries to infer a split of the training data based on the values of the available features to produce a good generalization.  The algorithm can naturally handle binary or multiclass classification problems. The leaf nodes can refer to any of the K classes concerned.


==== Support vector machines ====
Support vector machines are based upon the idea of maximizing the margin i.e. maximizing the minimum distance from the separating hyperplane to the nearest example. The basic SVM supports only binary classification, but extensions have been proposed to handle the multiclass classification case as well. In these extensions, additional parameters and constraints are added to the optimization problem to handle the separation of the different classes.


==== Multi expression programming ====
Multi expression programming (MEP) is an evolutionary algorithm for generating computer programs (that can be used for classification tasks too). MEP has a unique feature: it encodes multiple programs into a single chromosome. Each of these programs can be used to generate the output for a class, thus making MEP naturally suitable for solving multi-class classification problems.


=== Hierarchical classification ===
Hierarchical classification tackles the multi-class classification problem by dividing the output space into a tree. Each parent node is divided into multiple child nodes and the process is continued until each child node represents only one class. Several methods have been proposed based on hierarchical classification.


== Learning paradigms ==
Based on learning paradigms, the existing multi-class classification techniques can be classified into batch learning and online learning. Batch learning algorithms require all the data samples to be available beforehand. It trains the model using the entire training data and then predicts the test sample using the found relationship. The online learning algorithms, on the other hand, incrementally build their models in sequential iterations. In iteration t, an online algorithm receives a sample, xt and predicts its label ŷt using the current model; the algorithm then receives yt, the true label of xt and updates its model based on the sample-label pair: (xt, yt). Recently, a new learning paradigm called progressive learning technique has been developed. The progressive learning technique is capable of not only learning from new samples but also capable of learning new classes of data and yet retain the knowledge learnt thus far.


== Evaluation ==
The performance of a multi-class classification system is often assessed by comparing the predictions of the system against reference labels with an evaluation metric. Common evaluation metrics are Accuracy or macro F1.


== See also ==
Binary classification
One-class classification
Multi-label classification
Multiclass perceptron
Multi-task learning


== Notes ==


== References ==