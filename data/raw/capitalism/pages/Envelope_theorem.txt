In mathematics and economics, the envelope theorem is a major result about the differentiability properties of the value function of a parameterized optimization problem. As we change parameters of the objective, the envelope theorem shows that, in a certain sense, changes in the optimizer of the objective do not contribute to the change in the objective function. The envelope theorem is an important tool for comparative statics of optimization models.
The term envelope derives from describing the graph of the value function as the "upper envelope" of the graphs of the parameterized family of functions 
  
    
      
        
          
            {
            
              f
              
                (
                
                  x
                  ,
                  ⋅
                
                )
              
            
            }
          
          
            x
            ∈
            X
          
        
      
    
    {\displaystyle \left\{f\left(x,\cdot \right)\right\}_{x\in X}}
  
  that are optimized.


== Statement ==
Let 
  
    
      
        f
        (
        x
        ,
        α
        )
      
    
    {\displaystyle f(x,\alpha )}
  
 and 
  
    
      
        
          g
          
            j
          
        
        (
        x
        ,
        α
        )
        ,
        j
        =
        1
        ,
        2
        ,
        …
        ,
        m
      
    
    {\displaystyle g_{j}(x,\alpha ),j=1,2,\ldots ,m}
  
 be real-valued continuously differentiable functions on 
  
    
      
        
          
            R
          
          
            n
            +
            l
          
        
      
    
    {\displaystyle \mathbb {R} ^{n+l}}
  
, where 
  
    
      
        x
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle x\in \mathbb {R} ^{n}}
  
 are choice variables and 
  
    
      
        α
        ∈
        
          
            R
          
          
            l
          
        
      
    
    {\displaystyle \alpha \in \mathbb {R} ^{l}}
  
 are parameters, and consider the problem of choosing 
  
    
      
        x
      
    
    {\displaystyle x}
  
, for a given 
  
    
      
        α
      
    
    {\displaystyle \alpha }
  
, so as to:

  
    
      
        
          max
          
            x
          
        
        f
        (
        x
        ,
        α
        )
      
    
    {\displaystyle \max _{x}f(x,\alpha )}
  
 subject to 
  
    
      
        
          g
          
            j
          
        
        (
        x
        ,
        α
        )
        ≥
        0
        ,
        j
        =
        1
        ,
        2
        ,
        …
        ,
        m
      
    
    {\displaystyle g_{j}(x,\alpha )\geq 0,j=1,2,\ldots ,m}
  
 and 
  
    
      
        x
        ≥
        0
      
    
    {\displaystyle x\geq 0}
  
.
The Lagrangian expression of this problem is given by

  
    
      
        
          
            L
          
        
        (
        x
        ,
        λ
        ,
        α
        )
        =
        f
        (
        x
        ,
        α
        )
        +
        λ
        ⋅
        g
        (
        x
        ,
        α
        )
      
    
    {\displaystyle {\mathcal {L}}(x,\lambda ,\alpha )=f(x,\alpha )+\lambda \cdot g(x,\alpha )}
  

where 
  
    
      
        λ
        ∈
        
          
            R
          
          
            m
          
        
      
    
    {\displaystyle \lambda \in \mathbb {R} ^{m}}
  
 are the Lagrange multipliers. Now let 
  
    
      
        
          x
          
            ∗
          
        
        (
        α
        )
      
    
    {\displaystyle x^{\ast }(\alpha )}
  
 and 
  
    
      
        
          λ
          
            ∗
          
        
        (
        α
        )
      
    
    {\displaystyle \lambda ^{\ast }(\alpha )}
  
 together be the solution that maximizes the objective function f subject to the constraints (and hence are saddle points of the Lagrangian),

  
    
      
        
          
            
              L
            
          
          
            ∗
          
        
        (
        α
        )
        ≡
        f
        (
        
          x
          
            ∗
          
        
        (
        α
        )
        ,
        α
        )
        +
        
          λ
          
            ∗
          
        
        (
        α
        )
        ⋅
        g
        (
        
          x
          
            ∗
          
        
        (
        α
        )
        ,
        α
        )
        ,
      
    
    {\displaystyle {\mathcal {L}}^{\ast }(\alpha )\equiv f(x^{\ast }(\alpha ),\alpha )+\lambda ^{\ast }(\alpha )\cdot g(x^{\ast }(\alpha ),\alpha ),}
  

and define the value function

  
    
      
        V
        (
        α
        )
        ≡
        f
        (
        
          x
          
            ∗
          
        
        (
        α
        )
        ,
        α
        )
        .
      
    
    {\displaystyle V(\alpha )\equiv f(x^{\ast }(\alpha ),\alpha ).}
  

Then we have the following theorem.
Theorem: Assume that 
  
    
      
        V
      
    
    {\displaystyle V}
  
 and 
  
    
      
        
          
            L
          
        
      
    
    {\displaystyle {\mathcal {L}}}
  
 are continuously differentiable. Then

  
    
      
        
          
            
              ∂
              V
              (
              α
              )
            
            
              ∂
              
                α
                
                  k
                
              
            
          
        
        =
        
          
            
              ∂
              
                
                  
                    L
                  
                
                
                  ∗
                
              
              (
              α
              )
            
            
              ∂
              
                α
                
                  k
                
              
            
          
        
        =
        
          
            
              ∂
              
                
                  L
                
              
              (
              
                x
                
                  ∗
                
              
              (
              α
              )
              ,
              
                λ
                
                  ∗
                
              
              (
              α
              )
              ,
              α
              )
            
            
              ∂
              
                α
                
                  k
                
              
            
          
        
        ,
        k
        =
        1
        ,
        2
        ,
        …
        ,
        l
      
    
    {\displaystyle {\frac {\partial V(\alpha )}{\partial \alpha _{k}}}={\frac {\partial {\mathcal {L}}^{\ast }(\alpha )}{\partial \alpha _{k}}}={\frac {\partial {\mathcal {L}}(x^{\ast }(\alpha ),\lambda ^{\ast }(\alpha ),\alpha )}{\partial \alpha _{k}}},k=1,2,\ldots ,l}
  

where 
  
    
      
        ∂
        
          
            L
          
        
        
          /
        
        ∂
        
          α
          
            k
          
        
        =
        ∂
        f
        
          /
        
        ∂
        
          α
          
            k
          
        
        +
        λ
        ⋅
        ∂
        g
        
          /
        
        ∂
        
          α
          
            k
          
        
      
    
    {\displaystyle \partial {\mathcal {L}}/\partial \alpha _{k}=\partial f/\partial \alpha _{k}+\lambda \cdot \partial g/\partial \alpha _{k}}
  
.


== For arbitrary choice sets ==
Let 
  
    
      
        X
      
    
    {\displaystyle X}
  
 denote the choice set and let the relevant parameter be 
  
    
      
        t
        ∈
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle t\in \lbrack 0,1]}
  
. Letting 
  
    
      
        f
        :
        X
        ×
        [
        0
        ,
        1
        ]
        →
        R
      
    
    {\displaystyle f:X\times \lbrack 0,1]\rightarrow R}
  
 denote the parameterized objective function, the value function 
  
    
      
        V
      
    
    {\displaystyle V}
  
 and the optimal choice correspondence (set-valued function) 
  
    
      
        
          X
          
            ∗
          
        
      
    
    {\displaystyle X^{\ast }}
  
 are given by:

"Envelope theorems" describe sufficient conditions for the value function 
  
    
      
        V
      
    
    {\displaystyle V}
  
 to be differentiable in the parameter 
  
    
      
        t
      
    
    {\displaystyle t}
  
 and describe its derivative as

where 
  
    
      
        
          f
          
            t
          
        
      
    
    {\displaystyle f_{t}}
  
 denotes the partial derivative of 
  
    
      
        f
      
    
    {\displaystyle f}
  
 with respect to 
  
    
      
        t
      
    
    {\displaystyle t}
  
. Namely, the derivative of the value function with respect to the parameter equals the partial derivative of the objective function with respect to 
  
    
      
        t
      
    
    {\displaystyle t}
  
 holding the maximizer fixed at its optimal level. 
Traditional envelope theorem derivations use the first-order condition for (1), which requires that the choice set 
  
    
      
        X
      
    
    {\displaystyle X}
  
 have the convex and topological structure, and the objective function 
  
    
      
        f
      
    
    {\displaystyle f}
  
 be differentiable in the variable 
  
    
      
        x
      
    
    {\displaystyle x}
  
. (The argument is that changes in the maximizer have only a "second-order effect" at the optimum and so can be ignored.) However, in many applications such as the analysis of incentive constraints in contract theory and game theory, nonconvex production problems, and "monotone" or "robust" comparative statics, the choice sets and objective functions generally lack the topological and convexity properties required by the traditional envelope theorems.
Paul Milgrom and Ilya Segal (2002) observe that the traditional envelope formula holds for optimization problems with arbitrary choice sets at any differentiability point of the value function, provided that the objective function is differentiable in the parameter:
Theorem 1: Let 
  
    
      
        t
        ∈
        
          (
          
            0
            ,
            1
          
          )
        
      
    
    {\displaystyle t\in \left(0,1\right)}
  
 and 
  
    
      
        x
        ∈
        
          X
          
            ∗
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle x\in X^{\ast }\left(t\right)}
  
. If both 
  
    
      
        
          V
          
            ′
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle V^{\prime }\left(t\right)}
  
 and 
  
    
      
        
          f
          
            t
          
        
        
          (
          
            x
            ,
            t
          
          )
        
      
    
    {\displaystyle f_{t}\left(x,t\right)}
  
 exist, the envelope formula (3) holds.
Proof: Equation (1) implies that for 
  
    
      
        x
        ∈
        
          X
          
            ∗
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle x\in X^{\ast }\left(t\right)}
  
,

  
    
      
        
          max
          
            s
            ∈
            
              [
              
                0
                ,
                1
              
              ]
            
          
        
        
          [
          
            f
            
              (
              
                x
                ,
                s
              
              )
            
            −
            V
            
              (
              s
              )
            
          
          ]
        
        =
        f
        
          (
          
            x
            ,
            t
          
          )
        
        −
        V
        
          (
          t
          )
        
        =
        0.
      
    
    {\displaystyle \max _{s\in \left[0,1\right]}\left[f\left(x,s\right)-V\left(s\right)\right]=f\left(x,t\right)-V\left(t\right)=0.}
  

Under the assumptions, the objective function of the displayed maximization problem is differentiable at 
  
    
      
        s
        =
        t
      
    
    {\displaystyle s=t}
  
, and the first-order condition for this maximization is exactly  equation (3). Q.E.D.
While differentiability of the value function in general requires strong assumptions, in many applications weaker conditions such as absolute continuity, differentiability almost everywhere, or left- and right-differentiability, suffice. In particular, Milgrom and Segal's (2002) Theorem 2 offers a sufficient condition for 
  
    
      
        V
      
    
    {\displaystyle V}
  
 to be absolutely continuous, which means that it is differentiable almost everywhere and can be represented as an integral of its derivative:
Theorem 2: Suppose that 
  
    
      
        f
        (
        x
        ,
        ⋅
        )
      
    
    {\displaystyle f(x,\cdot )}
  
 is absolutely continuous for all 
  
    
      
        x
        ∈
        X
      
    
    {\displaystyle x\in X}
  
. Suppose also that there exists an integrable function 
  
    
      
        b
        :
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle b:[0,1]}
  
 
  
    
      
        →
      
    
    {\displaystyle \rightarrow }
  
 
  
    
      
        
          
            R
          
          
            +
          
        
      
    
    {\displaystyle \mathbb {R} _{+}}
  
 such that 
  
    
      
        
          |
        
        
          f
          
            t
          
        
        (
        x
        ,
        t
        )
        
          |
        
        ≤
        b
        (
        t
        )
      
    
    {\displaystyle |f_{t}(x,t)|\leq b(t)}
  
 for all 
  
    
      
        x
        ∈
        X
      
    
    {\displaystyle x\in X}
  
 and almost all 
  
    
      
        t
        ∈
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle t\in \lbrack 0,1]}
  
. Then 
  
    
      
        V
      
    
    {\displaystyle V}
  
 is absolutely continuous. Suppose, in addition, that 
  
    
      
        f
        (
        x
        ,
        ⋅
        )
      
    
    {\displaystyle f(x,\cdot )}
  
 is differentiable for all 
  
    
      
        x
        ∈
        X
      
    
    {\displaystyle x\in X}
  
, and that 
  
    
      
        
          X
          
            ∗
          
        
        (
        t
        )
        ≠
        ∅
      
    
    {\displaystyle X^{\ast }(t)\neq \varnothing }
  
 almost everywhere on 
  
    
      
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle [0,1]}
  
. Then for any selection 
  
    
      
        
          x
          
            ∗
          
        
        (
        t
        )
        ∈
        
          X
          
            ∗
          
        
        (
        t
        )
      
    
    {\displaystyle x^{\ast }(t)\in X^{\ast }(t)}
  
,

Proof: Using  (1)(1), observe that for any 
  
    
      
        
          t
          
            ′
          
        
        ,
        
          t
          
            ′
            ′
          
        
        ∈
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle t^{\prime },t^{\prime \prime }\in \lbrack 0,1]}
  
 with 
  
    
      
        
          t
          
            ′
          
        
        <
        
          t
          
            ′
            ′
          
        
      
    
    {\displaystyle t^{\prime }<t^{\prime \prime }}
  
,

  
    
      
        
          |
        
        V
        (
        
          t
          
            ′
            ′
          
        
        )
        −
        V
        (
        
          t
          
            ′
          
        
        )
        
          |
        
        ≤
        
          sup
          
            x
            ∈
            X
          
        
        
          |
        
        f
        (
        x
        ,
        
          t
          
            ′
            ′
          
        
        )
        −
        f
        (
        x
        ,
        
          t
          
            ′
          
        
        )
        
          |
        
        =
        
          sup
          
            x
            ∈
            X
          
        
        
          |
          
            
              ∫
              
                
                  t
                  
                    ′
                  
                
              
              
                
                  t
                  
                    ′
                    ′
                  
                
              
            
            
              f
              
                t
              
            
            (
            x
            ,
            t
            )
            d
            t
          
          |
        
        ≤
        
          ∫
          
            
              t
              
                ′
              
            
          
          
            
              t
              
                ′
                ′
              
            
          
        
        
          sup
          
            x
            ∈
            X
          
        
        
          |
        
        
          f
          
            t
          
        
        (
        x
        ,
        t
        )
        
          |
        
        d
        t
        ≤
        
          ∫
          
            
              t
              
                ′
              
            
          
          
            
              t
              
                ′
                ′
              
            
          
        
        b
        (
        t
        )
        d
        t
        .
      
    
    {\displaystyle |V(t^{\prime \prime })-V(t^{\prime })|\leq \sup _{x\in X}|f(x,t^{\prime \prime })-f(x,t^{\prime })|=\sup _{x\in X}\left\vert \int _{t^{\prime }}^{t^{\prime \prime }}f_{t}(x,t)dt\right\vert \leq \int _{t^{\prime }}^{t^{\prime \prime }}\sup _{x\in X}|f_{t}(x,t)|dt\leq \int _{t^{\prime }}^{t^{\prime \prime }}b(t)dt.}
  

This implies that 
  
    
      
        V
      
    
    {\displaystyle V}
  
 is absolutely continuous. Therefore, 
  
    
      
        V
      
    
    {\displaystyle V}
  
 is differentiable almost everywhere, and using  (3) yields (4). Q.E.D.
This result dispels the common misconception that nice behavior of the value function requires correspondingly nice behavior of the maximizer. Theorem 2 ensures the absolute continuity of the value function even though the maximizer may be discontinuous. In a similar vein, Milgrom and Segal's (2002) Theorem 3 implies that the value function must be differentiable at 
  
    
      
        t
        =
        
          t
          
            0
          
        
      
    
    {\displaystyle t=t_{0}}
  
 and hence satisfy the envelope formula (3) when the family 
  
    
      
        
          
            {
            
              f
              
                (
                
                  x
                  ,
                  ⋅
                
                )
              
            
            }
          
          
            x
            ∈
            X
          
        
      
    
    {\displaystyle \left\{f\left(x,\cdot \right)\right\}_{x\in X}}
  
 is equi-differentiable at 
  
    
      
        
          t
          
            0
          
        
        ∈
        
          (
          
            0
            ,
            1
          
          )
        
      
    
    {\displaystyle t_{0}\in \left(0,1\right)}
  
 and 
  
    
      
        
          f
          
            t
          
        
        
          (
          
            
              X
              
                ∗
              
            
            
              (
              t
              )
            
            ,
            
              t
              
                0
              
            
          
          )
        
      
    
    {\displaystyle f_{t}\left(X^{\ast }\left(t\right),t_{0}\right)}
  
 is single-valued and continuous at 
  
    
      
        t
        =
        
          t
          
            0
          
        
      
    
    {\displaystyle t=t_{0}}
  
, even if the maximizer is not differentiable at 
  
    
      
        
          t
          
            0
          
        
      
    
    {\displaystyle t_{0}}
  
 (e.g., if 
  
    
      
        X
      
    
    {\displaystyle X}
  
 is described by a set of inequality constraints and the set of binding constraints changes at 
  
    
      
        
          t
          
            0
          
        
      
    
    {\displaystyle t_{0}}
  
).


== Applications ==


=== Applications to producer theory ===
Theorem 1 implies Hotelling's lemma at any differentiability point of the profit function, and Theorem 2 implies the producer surplus formula. Formally, let 
  
    
      
        π
        
          (
          p
          )
        
      
    
    {\displaystyle \pi \left(p\right)}
  
 denote the indirect profit function of a price-taking firm with production set 
  
    
      
        X
        ⊆
        
          
            R
          
          
            L
          
        
      
    
    {\displaystyle X\subseteq \mathbb {R} ^{L}}
  
 facing prices 
  
    
      
        p
        ∈
        
          
            R
          
          
            L
          
        
      
    
    {\displaystyle p\in \mathbb {R} ^{L}}
  
, and let 
  
    
      
        
          x
          
            ∗
          
        
        
          (
          p
          )
        
      
    
    {\displaystyle x^{\ast }\left(p\right)}
  
 denote the firm's supply function, i.e.,

  
    
      
        π
        (
        p
        )
        =
        
          max
          
            x
            ∈
            X
          
        
        p
        ⋅
        x
        =
        p
        ⋅
        
          x
          
            ∗
          
        
        
          (
          p
          )
        
        
          .
        
      
    
    {\displaystyle \pi (p)=\max _{x\in X}p\cdot x=p\cdot x^{\ast }\left(p\right){\text{.}}}
  

Let 
  
    
      
        t
        =
        
          p
          
            i
          
        
      
    
    {\displaystyle t=p_{i}}
  
 (the price of good 
  
    
      
        i
      
    
    {\displaystyle i}
  
) and fix the other goods' prices at 
  
    
      
        
          p
          
            −
            i
          
        
        ∈
        
          
            R
          
          
            L
            −
            1
          
        
      
    
    {\displaystyle p_{-i}\in \mathbb {R} ^{L-1}}
  
. Applying Theorem 1 to 
  
    
      
        f
        (
        x
        ,
        t
        )
        =
        t
        
          x
          
            i
          
        
        +
        
          p
          
            −
            i
          
        
        ⋅
        
          x
          
            −
            i
          
        
      
    
    {\displaystyle f(x,t)=tx_{i}+p_{-i}\cdot x_{-i}}
  
 yields 
  
    
      
        
          
            
              ∂
              π
              (
              p
              )
            
            
              ∂
              
                p
                
                  i
                
              
            
          
        
        =
        
          x
          
            i
          
          
            ∗
          
        
        (
        p
        )
      
    
    {\displaystyle {\frac {\partial \pi (p)}{\partial p_{i}}}=x_{i}^{\ast }(p)}
  
 (the firm's optimal supply of good 
  
    
      
        i
      
    
    {\displaystyle i}
  
). Applying Theorem 2 (whose assumptions are verified when 
  
    
      
        
          p
          
            i
          
        
      
    
    {\displaystyle p_{i}}
  
 is restricted to a bounded interval) yields

  
    
      
        π
        (
        t
        ,
        
          p
          
            −
            i
          
        
        )
        −
        π
        (
        0
        ,
        
          p
          
            −
            i
          
        
        )
        =
        
          ∫
          
            0
          
          
            
              p
              
                i
              
            
          
        
        
          x
          
            i
          
          
            ∗
          
        
        (
        s
        ,
        
          p
          
            −
            i
          
        
        )
        d
        s
        ,
      
    
    {\displaystyle \pi (t,p_{-i})-\pi (0,p_{-i})=\int _{0}^{p_{i}}x_{i}^{\ast }(s,p_{-i})ds,}
  

i.e. the producer surplus 
  
    
      
        π
        (
        t
        ,
        
          p
          
            −
            i
          
        
        )
        −
        π
        (
        0
        ,
        
          p
          
            −
            i
          
        
        )
      
    
    {\displaystyle \pi (t,p_{-i})-\pi (0,p_{-i})}
  
 can be obtained by integrating under the firm's supply curve for good 
  
    
      
        i
      
    
    {\displaystyle i}
  
.


=== Applications to mechanism design and auction theory ===
Consider an agent whose utility function 
  
    
      
        f
        (
        x
        ,
        t
        )
      
    
    {\displaystyle f(x,t)}
  
 over outcomes 
  
    
      
        x
        ∈
        
          
            
              X
              ¯
            
          
        
      
    
    {\displaystyle x\in {\bar {X}}}
  
 depends on his type 
  
    
      
        t
        ∈
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle t\in \lbrack 0,1]}
  
. Let 
  
    
      
        X
        ⊆
        
          
            
              X
              ¯
            
          
        
      
    
    {\displaystyle X\subseteq {\bar {X}}}
  
 represent the "menu" of possible outcomes the agent could obtain in the mechanism by sending different messages. The agent's equilibrium utility 
  
    
      
        V
        (
        t
        )
      
    
    {\displaystyle V(t)}
  
 in the mechanism is then given by (1), and the set 
  
    
      
        
          X
          
            ∗
          
        
        (
        t
        )
      
    
    {\displaystyle X^{\ast }(t)}
  
 of the mechanism's equilibrium outcomes is given by (2). Any selection 
  
    
      
        
          x
          
            ∗
          
        
        (
        t
        )
        ∈
        
          X
          
            ∗
          
        
        (
        t
        )
      
    
    {\displaystyle x^{\ast }(t)\in X^{\ast }(t)}
  
 is a choice rule implemented by the mechanism. Suppose that the agent's utility function 
  
    
      
        f
        (
        x
        ,
        t
        )
      
    
    {\displaystyle f(x,t)}
  
 is differentiable and absolutely continuous in 
  
    
      
        t
      
    
    {\displaystyle t}
  
 for all 
  
    
      
        x
        ∈
        Y
      
    
    {\displaystyle x\in Y}
  
, and that 
  
    
      
        
          sup
          
            x
            ∈
            
              
                
                  X
                  ¯
                
              
            
          
        
        
          |
        
        
          f
          
            t
          
        
        (
        x
        ,
        t
        )
        
          |
        
      
    
    {\displaystyle \sup _{x\in {\bar {X}}}|f_{t}(x,t)|}
  
 is integrable on 
  
    
      
        [
        0
        ,
        1
        ]
      
    
    {\displaystyle [0,1]}
  
. Then Theorem 2 implies that the agent's equilibrium utility 
  
    
      
        V
      
    
    {\displaystyle V}
  
 in any mechanism implementing a given choice rule 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{\ast }}
  
 must satisfy the integral condition (4).
The integral condition (4) is a key step in the analysis of mechanism design problems with continuous type spaces. In particular, in Myerson's (1981) analysis of single-item auctions, the outcome from the viewpoint of one bidder can be described as 
  
    
      
        x
        =
        
          (
          
            y
            ,
            z
          
          )
        
      
    
    {\displaystyle x=\left(y,z\right)}
  
, where 
  
    
      
        y
      
    
    {\displaystyle y}
  
 is the bidder's probability of receiving the object and 
  
    
      
        z
      
    
    {\displaystyle z}
  
 is his expected payment, and the bidder's expected utility takes the form 
  
    
      
        f
        
          (
          
            
              (
              
                y
                ,
                z
              
              )
            
            ,
            t
          
          )
        
        =
        t
        y
        −
        z
      
    
    {\displaystyle f\left(\left(y,z\right),t\right)=ty-z}
  
. In this case, letting 
  
    
      
        
          
            t
            _
          
        
      
    
    {\displaystyle {\underline {t}}}
  
 denote the bidder's lowest possible type, the integral condition (4) for the bidder's equilibrium expected utility 
  
    
      
        V
      
    
    {\displaystyle V}
  
 takes the form

  
    
      
        V
        (
        t
        )
        −
        V
        (
        
          
            t
            _
          
        
        )
        =
        
          ∫
          
            0
          
          
            t
          
        
        
          y
          
            ∗
          
        
        (
        s
        )
        d
        s
        .
      
    
    {\displaystyle V(t)-V({\underline {t}})=\int _{0}^{t}y^{\ast }(s)ds.}
  

(This equation can be interpreted as the producer surplus formula for the firm whose production technology for converting numeraire 
  
    
      
        z
      
    
    {\displaystyle z}
  
 into probability 
  
    
      
        y
      
    
    {\displaystyle y}
  
 of winning the object is defined by the auction and which resells the object at a fixed price 
  
    
      
        t
      
    
    {\displaystyle t}
  
). This condition in turn yields Myerson's (1981) celebrated revenue equivalence theorem: the expected revenue generated in an auction in which bidders have independent private values is fully determined by the bidders' probabilities 
  
    
      
        
          y
          
            ∗
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle y^{\ast }\left(t\right)}
  
 of getting the object for all types 
  
    
      
        t
      
    
    {\displaystyle t}
  
 as well as by the expected payoffs 
  
    
      
        V
        (
        
          
            t
            _
          
        
        )
      
    
    {\displaystyle V({\underline {t}})}
  
 of the bidders' lowest types. Finally, this condition is a key step in Myerson's (1981) of optimal auctions.
For other applications of the envelope theorem to mechanism design see Mirrlees (1971), Holmstrom (1979), Laffont and Maskin (1980), Riley and Samuelson (1981), Fudenberg and Tirole (1991), and Williams (1999). While these authors derived and exploited the envelope theorem by restricting attention to (piecewise) continuously differentiable choice rules or even narrower classes, it may sometimes be optimal to implement a choice rule that is not piecewise continuously differentiable. (One example is the class of trading problems with linear utility described in chapter 6.5 of Myerson (1991).) Note that the integral condition (3) still holds in this setting and implies such important results as Holmstrom's lemma (Holmstrom, 1979), Myerson's lemma (Myerson, 1981), the revenue equivalence theorem (for auctions), the Green–Laffont–Holmstrom theorem (Green and Laffont, 1979; Holmstrom, 1979), the Myerson–Satterthwaite inefficiency theorem (Myerson and Satterthwaite, 1983), the Jehiel–Moldovanu impossibility theorems (Jehiel and Moldovanu, 2001), the McAfee–McMillan weak-cartels theorem (McAfee and McMillan, 1992), and Weber's martingale theorem (Weber, 1983), etc. The details of these applications are provided in Chapter 3 of Milgrom (2004), who offers an elegant and unifying framework in auction and mechanism design analysis mainly based on the envelope theorem and other familiar techniques and concepts in demand theory.


=== Applications to multidimensional parameter spaces ===
For a multidimensional parameter space 
  
    
      
        T
        ⊆
        
          
            R
          
          
            K
          
        
      
    
    {\displaystyle T\subseteq \mathbb {R} ^{K}}
  
, Theorem
1 can be applied to partial and directional derivatives of the value
function. If both the objective function 
  
    
      
        f
      
    
    {\displaystyle f}
  
 and the value function 
  
    
      
        V
      
    
    {\displaystyle V}
  
 are (totally) differentiable in 
  
    
      
        t
      
    
    {\displaystyle t}
  
, Theorem 1 implies the envelope formula for their gradients: 
  
    
      
        ∇
        V
        
          (
          t
          )
        
        =
        
          ∇
          
            t
          
        
        f
        
          (
          
            x
            ,
            t
          
          )
        
      
    
    {\displaystyle \nabla V\left(t\right)=\nabla _{t}f\left(x,t\right)}
  
 for each 
  
    
      
        x
        ∈
        
          X
          
            ∗
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle x\in X^{\ast }\left(t\right)}
  
. While total differentiability of the value function may not be easy to ensure, Theorem 2 can be still applied along any smooth path connecting two parameter values 
  
    
      
        
          t
          
            0
          
        
      
    
    {\displaystyle t_{0}}
  
 and 
  
    
      
        t
      
    
    {\displaystyle t}
  
. Namely, suppose that functions 
  
    
      
        f
        (
        x
        ,
        ⋅
        )
      
    
    {\displaystyle f(x,\cdot )}
  
 are differentiable for all 
  
    
      
        x
        ∈
        X
      
    
    {\displaystyle x\in X}
  
 with 
  
    
      
        
          |
        
        
          ∇
          
            t
          
        
        f
        (
        x
        ,
        t
        )
        
          |
        
        ≤
        B
      
    
    {\displaystyle |\nabla _{t}f(x,t)|\leq B}
  
 for all 
  
    
      
        x
        ∈
        X
        ,
      
    
    {\displaystyle x\in X,}
  
 
  
    
      
        t
        ∈
        T
      
    
    {\displaystyle t\in T}
  
. A smooth path from 
  
    
      
        
          t
          
            0
          
        
      
    
    {\displaystyle t_{0}}
  
 to 
  
    
      
        t
      
    
    {\displaystyle t}
  
 is described by a differentiable mapping 
  
    
      
        γ
        :
        
          [
          
            0
            ,
            1
          
          ]
        
        →
        T
      
    
    {\displaystyle \gamma :\left[0,1\right]\rightarrow T}
  
 with a bounded derivative, such that 
  
    
      
        γ
        
          (
          0
          )
        
        =
        
          t
          
            0
          
        
      
    
    {\displaystyle \gamma \left(0\right)=t_{0}}
  
 and 
  
    
      
        γ
        
          (
          1
          )
        
        =
        t
      
    
    {\displaystyle \gamma \left(1\right)=t}
  
. Theorem 2 implies that for any such smooth path, the change of the value function can be expressed as the path integral of the partial gradient 
  
    
      
        
          ∇
          
            t
          
        
        f
        (
        
          x
          
            ∗
          
        
        (
        t
        )
        ,
        t
        )
      
    
    {\displaystyle \nabla _{t}f(x^{\ast }(t),t)}
  
 of the objective function along the path:

  
    
      
        V
        (
        t
        )
        −
        V
        (
        
          t
          
            0
          
        
        )
        =
        
          ∫
          
            γ
          
        
        
          ∇
          
            t
          
        
        f
        (
        
          x
          
            ∗
          
        
        (
        s
        )
        ,
        s
        )
        ⋅
        d
        s
        .
      
    
    {\displaystyle V(t)-V(t_{0})=\int _{\gamma }\nabla _{t}f(x^{\ast }(s),s)\cdot ds.}
  

In particular, for 
  
    
      
        t
        =
        
          t
          
            0
          
        
      
    
    {\displaystyle t=t_{0}}
  
, this establishes that cyclic path integrals along any smooth path 
  
    
      
        γ
      
    
    {\displaystyle \gamma }
  
 must be zero:

  
    
      
        ∫
        
          ∇
          
            t
          
        
        f
        (
        
          x
          
            ∗
          
        
        (
        s
        )
        ,
        s
        )
        ⋅
        d
        s
        =
        0.
      
    
    {\displaystyle \int \nabla _{t}f(x^{\ast }(s),s)\cdot ds=0.}
  

This "integrability condition" plays an important role in mechanism design with multidimensional types, constraining what kind of choice rules 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{\ast }}
  
 can be sustained by mechanism-induced menus 
  
    
      
        X
        ⊆
        
          
            
              X
              ¯
            
          
        
      
    
    {\displaystyle X\subseteq {\bar {X}}}
  
. In application to producer theory, with 
  
    
      
        x
        ∈
        X
        ⊆
        
          
            R
          
          
            L
          
        
      
    
    {\displaystyle x\in X\subseteq \mathbb {R} ^{L}}
  
 being the firm's production vector and 
  
    
      
        t
        ∈
        
          
            R
          
          
            L
          
        
      
    
    {\displaystyle t\in \mathbb {R} ^{L}}
  
 being the price vector, 
  
    
      
        f
        
          (
          
            x
            ,
            t
          
          )
        
        =
        t
        ⋅
        x
      
    
    {\displaystyle f\left(x,t\right)=t\cdot x}
  
, and the integrability condition says that any rationalizable supply function 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{\ast }}
  
 must satisfy

  
    
      
        ∫
        
          x
          
            ∗
          
        
        (
        s
        )
        ⋅
        d
        s
        =
        0.
      
    
    {\displaystyle \int x^{\ast }(s)\cdot ds=0.}
  

When 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{\ast }}
  
 is continuously differentiable, this integrability condition is equivalent to the symmetry of the substitution matrix 
  
    
      
        
          
            (
            
              ∂
              
                x
                
                  i
                
                
                  ∗
                
              
              
                (
                t
                )
              
              
                /
              
              ∂
              
                t
                
                  j
                
              
            
            )
          
          
            i
            ,
            j
            =
            1
          
          
            L
          
        
      
    
    {\displaystyle \left(\partial x_{i}^{\ast }\left(t\right)/\partial t_{j}\right)_{i,j=1}^{L}}
  
. (In consumer theory, the same argument applied to the expenditure minimization problem yields symmetry of the Slutsky matrix.)


=== Applications to parameterized constraints ===
Suppose now that the feasible set 
  
    
      
        X
        
          (
          t
          )
        
      
    
    {\displaystyle X\left(t\right)}
  
 depends on the parameter, i.e.,

  
    
      
        V
        (
        t
        )
        =
        
          sup
          
            x
            ∈
            X
            
              (
              t
              )
            
          
        
        f
        (
        x
        ,
        t
        )
      
    
    {\displaystyle V(t)=\sup _{x\in X\left(t\right)}f(x,t)}
  

  
    
      
        
          X
          
            ∗
          
        
        (
        t
        )
        =
        {
        x
        ∈
        X
        
          (
          t
          )
        
        :
        f
        (
        x
        ,
        t
        )
        =
        V
        (
        t
        )
        }
        
          , 
        
      
    
    {\displaystyle X^{\ast }(t)=\{x\in X\left(t\right):f(x,t)=V(t)\}{\text{, }}}
  

where 
  
    
      
        X
        
          (
          t
          )
        
        =
        
          {
          
            x
            ∈
            X
            :
            g
            
              (
              
                x
                ,
                t
              
              )
            
            ≥
            0
          
          }
        
      
    
    {\displaystyle X\left(t\right)=\left\{x\in X:g\left(x,t\right)\geq 0\right\}}
  
 for some 
  
    
      
        g
        :
        X
        ×
        
          [
          
            0
            ,
            1
          
          ]
        
        →
        
          
            R
          
          
            K
          
        
        .
      
    
    {\displaystyle g:X\times \left[0,1\right]\rightarrow \mathbb {R} ^{K}.}
  

Suppose that 
  
    
      
        X
      
    
    {\displaystyle X}
  
 is a convex set, 
  
    
      
        f
      
    
    {\displaystyle f}
  
 and 
  
    
      
        g
      
    
    {\displaystyle g}
  
 are concave in 
  
    
      
        x
      
    
    {\displaystyle x}
  
, and there exists 
  
    
      
        
          
            
              x
              ^
            
          
        
        ∈
        X
      
    
    {\displaystyle {\hat {x}}\in X}
  
 such that 
  
    
      
        g
        
          (
          
            
              
                
                  x
                  ^
                
              
            
            ,
            t
          
          )
        
        >
        0
      
    
    {\displaystyle g\left({\hat {x}},t\right)>0}
  
 for all 
  
    
      
        t
        ∈
        
          [
          
            0
            ,
            1
          
          ]
        
      
    
    {\displaystyle t\in \left[0,1\right]}
  
. Under these assumptions, it is well known that the above constrained optimization program can be represented as a saddle-point problem for the Lagrangian 
  
    
      
        L
        
          (
          
            x
            ,
            λ
            ,
            t
          
          )
        
        =
        f
        (
        x
        ,
        t
        )
        +
        λ
        ⋅
        g
        
          (
          
            x
            ,
            t
          
          )
        
      
    
    {\displaystyle L\left(x,\lambda ,t\right)=f(x,t)+\lambda \cdot g\left(x,t\right)}
  
, where 
  
    
      
        λ
        ∈
        
          
            R
          
          
            +
          
          
            K
          
        
      
    
    {\displaystyle \lambda \in \mathbb {R} _{+}^{K}}
  
 is the vector of Lagrange multipliers chosen by the adversary to minimize the Lagrangian. This allows the application of Milgrom and Segal's (2002, Theorem 4) envelope theorem for saddle-point problems, under the additional assumptions that 
  
    
      
        X
      
    
    {\displaystyle X}
  
 is a compact set in a normed linear space, 
  
    
      
        f
      
    
    {\displaystyle f}
  
 and 
  
    
      
        g
      
    
    {\displaystyle g}
  
 are continuous in 
  
    
      
        x
      
    
    {\displaystyle x}
  
, and 
  
    
      
        
          f
          
            t
          
        
      
    
    {\displaystyle f_{t}}
  
 and 
  
    
      
        
          g
          
            t
          
        
      
    
    {\displaystyle g_{t}}
  
 are continuous in 
  
    
      
        
          (
          
            x
            ,
            t
          
          )
        
      
    
    {\displaystyle \left(x,t\right)}
  
. In particular, letting 
  
    
      
        
          (
          
            
              x
              
                ∗
              
            
            (
            t
            )
            ,
            
              λ
              
                ∗
              
            
            
              (
              t
              )
            
          
          )
        
      
    
    {\displaystyle \left(x^{\ast }(t),\lambda ^{\ast }\left(t\right)\right)}
  
 denote the Lagrangian's saddle point for parameter value 
  
    
      
        t
      
    
    {\displaystyle t}
  
, the theorem implies that 
  
    
      
        V
      
    
    {\displaystyle V}
  
 is absolutely continuous and satisfies

  
    
      
        V
        (
        t
        )
        =
        V
        (
        0
        )
        +
        
          ∫
          
            0
          
          
            t
          
        
        
          L
          
            t
          
        
        (
        
          x
          
            ∗
          
        
        (
        s
        )
        ,
        
          λ
          
            ∗
          
        
        
          (
          s
          )
        
        ,
        s
        )
        d
        s
        .
      
    
    {\displaystyle V(t)=V(0)+\int _{0}^{t}L_{t}(x^{\ast }(s),\lambda ^{\ast }\left(s\right),s)ds.}
  

For the special case in which 
  
    
      
        f
        
          (
          
            x
            ,
            t
          
          )
        
      
    
    {\displaystyle f\left(x,t\right)}
  
 is independent of 
  
    
      
        t
      
    
    {\displaystyle t}
  
, 
  
    
      
        K
        =
        1
      
    
    {\displaystyle K=1}
  
, and 
  
    
      
        g
        
          (
          
            x
            ,
            t
          
          )
        
        =
        h
        
          (
          x
          )
        
        +
        t
      
    
    {\displaystyle g\left(x,t\right)=h\left(x\right)+t}
  
, the formula implies that 
  
    
      
        
          V
          
            ′
          
        
        (
        t
        )
        =
        
          L
          
            t
          
        
        (
        
          x
          
            ∗
          
        
        (
        t
        )
        ,
        
          λ
          
            ∗
          
        
        
          (
          t
          )
        
        ,
        t
        )
        =
        
          λ
          
            ∗
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle V^{\prime }(t)=L_{t}(x^{\ast }(t),\lambda ^{\ast }\left(t\right),t)=\lambda ^{\ast }\left(t\right)}
  
 for a.e. 
  
    
      
        t
      
    
    {\displaystyle t}
  
. That is, the Lagrange multiplier 
  
    
      
        
          λ
          
            ∗
          
        
        
          (
          t
          )
        
      
    
    {\displaystyle \lambda ^{\ast }\left(t\right)}
  
 on the constraint is its "shadow price" in the optimization program.


=== Other applications ===
Milgrom and Segal (2002) demonstrate that the generalized version of the envelope theorems can also be applied to convex programming, continuous optimization problems, saddle-point problems, and optimal stopping problems.


== See also ==


== References ==