In mathematics, the linear span (also called the linear hull or just span) of a set 
  
    
      
        S
      
    
    {\displaystyle S}
  
 of elements of a vector space 
  
    
      
        V
      
    
    {\displaystyle V}
  
 is the smallest linear subspace of 
  
    
      
        V
      
    
    {\displaystyle V}
  
 that contains 
  
    
      
        S
        .
      
    
    {\displaystyle S.}
  
 It is the set of all finite linear combinations of the elements of S, and the intersection of all linear subspaces that contain 
  
    
      
        S
        .
      
    
    {\displaystyle S.}
  
 It is often denoted span(S) or 
  
    
      
        ⟨
        S
        ⟩
        .
      
    
    {\displaystyle \langle S\rangle .}
  
 
For example, in geometry, two linearly independent vectors span a plane.
To express that a vector space V is a linear span of a subset S, one commonly uses one of the following phrases: S spans V; S is a spanning set of V; V is spanned or generated by S;  S is a generator set or a generating set of V.
Spans can be generalized to many mathematical structures, in which case, the smallest substructure containing 
  
    
      
        S
      
    
    {\displaystyle S}
  
 is generally called the substructure generated by 
  
    
      
        S
        .
      
    
    {\displaystyle S.}
  


== Definition ==
Given a vector space V over a field K, the span of a set S of vectors (not necessarily finite) is defined to be the intersection W of all subspaces of V that contain S. It is thus the smallest (for set inclusion) subspace containing  S. It is referred to as the subspace spanned by S, or by the vectors in S. Conversely, S is called a spanning set of W, and we say that S spans W.
It follows from this definition that the span of S is the set of all finite linear combinations of elements (vectors) of S, and can be defined as such. That is, 
  
    
      
        span
        ⁡
        (
        S
        )
        =
        
          
            {
          
        
        
          λ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        
          λ
          
            2
          
        
        
          
            v
          
          
            2
          
        
        +
        ⋯
        +
        
          λ
          
            n
          
        
        
          
            v
          
          
            n
          
        
        ∣
        n
        ∈
        
          N
        
        ,
        
        
          
            v
          
          
            1
          
        
        ,
        .
        .
        .
        
          
            v
          
          
            n
          
        
        ∈
        S
        ,
        
        
          λ
          
            1
          
        
        ,
        .
        .
        .
        
          λ
          
            n
          
        
        ∈
        K
        
          
            }
          
        
      
    
    {\displaystyle \operatorname {span} (S)={\biggl \{}\lambda _{1}\mathbf {v} _{1}+\lambda _{2}\mathbf {v} _{2}+\cdots +\lambda _{n}\mathbf {v} _{n}\mid n\in \mathbb {N} ,\;\mathbf {v} _{1},...\mathbf {v} _{n}\in S,\;\lambda _{1},...\lambda _{n}\in K{\biggr \}}}
  
 
When S is empty, the only possibility is n = 0, and the previous expression for 
  
    
      
        span
        ⁡
        (
        S
        )
      
    
    {\displaystyle \operatorname {span} (S)}
  
 reduces to the empty sum. The standard convention for the empty sum implies thus 
  
    
      
        
          span
        
        (
        ∅
        )
        =
        {
        
          0
        
        }
        ,
      
    
    {\displaystyle {\text{span}}(\emptyset )=\{\mathbf {0} \},}
  
 a property that is immediate with the other definitions. However, many introductory textbooks simply include this fact as part of the definition.
When 
  
    
      
        S
        =
        {
        
          
            v
          
          
            1
          
        
        ,
        …
        ,
        
          
            v
          
          
            n
          
        
        }
      
    
    {\displaystyle S=\{\mathbf {v} _{1},\ldots ,\mathbf {v} _{n}\}}
  
 is finite, one has

  
    
      
        span
        ⁡
        (
        S
        )
        =
        {
        
          λ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        
          λ
          
            2
          
        
        
          
            v
          
          
            2
          
        
        +
        ⋯
        +
        
          λ
          
            n
          
        
        
          
            v
          
          
            n
          
        
        ∣
        
          λ
          
            1
          
        
        ,
        .
        .
        .
        
          λ
          
            n
          
        
        ∈
        K
        }
      
    
    {\displaystyle \operatorname {span} (S)=\{\lambda _{1}\mathbf {v} _{1}+\lambda _{2}\mathbf {v} _{2}+\cdots +\lambda _{n}\mathbf {v} _{n}\mid \lambda _{1},...\lambda _{n}\in K\}}
  


== Examples ==
The real vector space 
  
    
      
        
          
            R
          
          
            3
          
        
      
    
    {\displaystyle \mathbb {R} ^{3}}
  
 has {(−1, 0, 0), (0, 1, 0), (0, 0, 1)} as a spanning set. This particular spanning set is also a basis. If (−1, 0, 0) were replaced by (1, 0, 0), it would also form the canonical basis of 
  
    
      
        
          
            R
          
          
            3
          
        
      
    
    {\displaystyle \mathbb {R} ^{3}}
  
.
Another spanning set for the same space is given by {(1, 2, 3), (0, 1, 2), (−1, 1⁄2, 3), (1, 1, 1)}, but this set is not a basis, because it is linearly dependent.
The set {(1, 0, 0), (0, 1, 0), (1, 1, 0)} is not a spanning set of 
  
    
      
        
          
            R
          
          
            3
          
        
      
    
    {\displaystyle \mathbb {R} ^{3}}
  
, since its span is the space of all vectors in 
  
    
      
        
          
            R
          
          
            3
          
        
      
    
    {\displaystyle \mathbb {R} ^{3}}
  
 whose last component is zero. That space is also spanned by the set {(1, 0, 0), (0, 1, 0)}, as (1, 1, 0) is a linear combination of (1, 0, 0) and (0, 1, 0). Thus, the spanned space is not 
  
    
      
        
          
            R
          
          
            3
          
        
        .
      
    
    {\displaystyle \mathbb {R} ^{3}.}
  
 It can be identified with 
  
    
      
        
          
            R
          
          
            2
          
        
      
    
    {\displaystyle \mathbb {R} ^{2}}
  
 by removing the third components equal to zero.
The empty set is a spanning set of {(0, 0, 0)}, since the empty set is a subset of all possible vector spaces in 
  
    
      
        
          
            R
          
          
            3
          
        
      
    
    {\displaystyle \mathbb {R} ^{3}}
  
, and {(0, 0, 0)} is the intersection of all of these vector spaces.
The set of monomials xn, where n is a non-negative integer, spans the space of polynomials.


== Theorems ==


=== Equivalence of definitions ===
The set of all linear combinations of a subset S of V, a vector space over K, is the smallest linear subspace of V containing S.

Proof. We first prove that span S is a subspace of V. Since S is a subset of V, we only need to prove the existence of a zero vector 0 in span S, that span S is closed under addition, and that span S is closed under scalar multiplication. Letting 
  
    
      
        S
        =
        {
        
          
            v
          
          
            1
          
        
        ,
        
          
            v
          
          
            2
          
        
        ,
        …
        ,
        
          
            v
          
          
            n
          
        
        }
      
    
    {\displaystyle S=\{\mathbf {v} _{1},\mathbf {v} _{2},\ldots ,\mathbf {v} _{n}\}}
  
, it is trivial that the zero vector of V exists in span S, since 
  
    
      
        
          0
        
        =
        0
        
          
            v
          
          
            1
          
        
        +
        0
        
          
            v
          
          
            2
          
        
        +
        ⋯
        +
        0
        
          
            v
          
          
            n
          
        
      
    
    {\displaystyle \mathbf {0} =0\mathbf {v} _{1}+0\mathbf {v} _{2}+\cdots +0\mathbf {v} _{n}}
  
. Adding together two linear combinations of S also produces a linear combination of S: 
  
    
      
        (
        
          λ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        ⋯
        +
        
          λ
          
            n
          
        
        
          
            v
          
          
            n
          
        
        )
        +
        (
        
          μ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        ⋯
        +
        
          μ
          
            n
          
        
        
          
            v
          
          
            n
          
        
        )
        =
        (
        
          λ
          
            1
          
        
        +
        
          μ
          
            1
          
        
        )
        
          
            v
          
          
            1
          
        
        +
        ⋯
        +
        (
        
          λ
          
            n
          
        
        +
        
          μ
          
            n
          
        
        )
        
          
            v
          
          
            n
          
        
      
    
    {\displaystyle (\lambda _{1}\mathbf {v} _{1}+\cdots +\lambda _{n}\mathbf {v} _{n})+(\mu _{1}\mathbf {v} _{1}+\cdots +\mu _{n}\mathbf {v} _{n})=(\lambda _{1}+\mu _{1})\mathbf {v} _{1}+\cdots +(\lambda _{n}+\mu _{n})\mathbf {v} _{n}}
  
, where all 
  
    
      
        
          λ
          
            i
          
        
        ,
        
          μ
          
            i
          
        
        ∈
        K
      
    
    {\displaystyle \lambda _{i},\mu _{i}\in K}
  
, and multiplying a linear combination of S by a scalar 
  
    
      
        c
        ∈
        K
      
    
    {\displaystyle c\in K}
  
 will produce another linear combination of S: 
  
    
      
        c
        (
        
          λ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        ⋯
        +
        
          λ
          
            n
          
        
        
          
            v
          
          
            n
          
        
        )
        =
        c
        
          λ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        ⋯
        +
        c
        
          λ
          
            n
          
        
        
          
            v
          
          
            n
          
        
      
    
    {\displaystyle c(\lambda _{1}\mathbf {v} _{1}+\cdots +\lambda _{n}\mathbf {v} _{n})=c\lambda _{1}\mathbf {v} _{1}+\cdots +c\lambda _{n}\mathbf {v} _{n}}
  
. Thus span S is a subspace of V.
It follows that 
  
    
      
        S
        ⊆
        span
        ⁡
        S
      
    
    {\displaystyle S\subseteq \operatorname {span} S}
  
, since every vi is a linear combination of S (trivially). Suppose that W is a linear subspace of V containing S. Since W is closed under addition and scalar multiplication, then every linear combination 
  
    
      
        
          λ
          
            1
          
        
        
          
            v
          
          
            1
          
        
        +
        ⋯
        +
        
          λ
          
            n
          
        
        
          
            v
          
          
            n
          
        
      
    
    {\displaystyle \lambda _{1}\mathbf {v} _{1}+\cdots +\lambda _{n}\mathbf {v} _{n}}
  
 must be contained in W. Thus, span S is contained in every subspace of V containing S, and the intersection of all such subspaces, or the smallest such subspace, is equal to the set of all linear combinations of S.


=== Size of spanning set is at least size of linearly independent set ===
Every spanning set S of a vector space V must contain at least as many elements as any linearly independent set of vectors from V.

Proof. Let 
  
    
      
        S
        =
        {
        
          
            v
          
          
            1
          
        
        ,
        …
        ,
        
          
            v
          
          
            m
          
        
        }
      
    
    {\displaystyle S=\{\mathbf {v} _{1},\ldots ,\mathbf {v} _{m}\}}
  
 be a spanning set and 
  
    
      
        W
        =
        {
        
          
            w
          
          
            1
          
        
        ,
        …
        ,
        
          
            w
          
          
            n
          
        
        }
      
    
    {\displaystyle W=\{\mathbf {w} _{1},\ldots ,\mathbf {w} _{n}\}}
  
 be a linearly independent set of vectors from V. We want to show that 
  
    
      
        m
        ≥
        n
      
    
    {\displaystyle m\geq n}
  
.
Since S spans V, then 
  
    
      
        S
        ∪
        {
        
          
            w
          
          
            1
          
        
        }
      
    
    {\displaystyle S\cup \{\mathbf {w} _{1}\}}
  
 must also span V, and 
  
    
      
        
          
            w
          
          
            1
          
        
      
    
    {\displaystyle \mathbf {w} _{1}}
  
 must be a linear combination of S. Thus 
  
    
      
        S
        ∪
        {
        
          
            w
          
          
            1
          
        
        }
      
    
    {\displaystyle S\cup \{\mathbf {w} _{1}\}}
  
 is linearly dependent, and we can remove one vector from S that is a linear combination of the other elements. This vector cannot be any of the wi, since W is linearly independent. The resulting set is 
  
    
      
        {
        
          
            w
          
          
            1
          
        
        ,
        
          
            v
          
          
            1
          
        
        ,
        …
        ,
        
          
            v
          
          
            i
            −
            1
          
        
        ,
        
          
            v
          
          
            i
            +
            1
          
        
        ,
        …
        ,
        
          
            v
          
          
            m
          
        
        }
      
    
    {\displaystyle \{\mathbf {w} _{1},\mathbf {v} _{1},\ldots ,\mathbf {v} _{i-1},\mathbf {v} _{i+1},\ldots ,\mathbf {v} _{m}\}}
  
, which is a spanning set of V. We repeat this step n times, where the resulting set after the pth step is the union of 
  
    
      
        {
        
          
            w
          
          
            1
          
        
        ,
        …
        ,
        
          
            w
          
          
            p
          
        
        }
      
    
    {\displaystyle \{\mathbf {w} _{1},\ldots ,\mathbf {w} _{p}\}}
  
 and m - p vectors of S.
It is ensured until the nth step that there will always be some vi to remove out of S for every adjoint of v, and thus there are at least as many vi's as there are wi's—i.e. 
  
    
      
        m
        ≥
        n
      
    
    {\displaystyle m\geq n}
  
. To verify this, we assume by way of contradiction that 
  
    
      
        m
        <
        n
      
    
    {\displaystyle m<n}
  
. Then, at the mth step, we have the set 
  
    
      
        {
        
          
            w
          
          
            1
          
        
        ,
        …
        ,
        
          
            w
          
          
            m
          
        
        }
      
    
    {\displaystyle \{\mathbf {w} _{1},\ldots ,\mathbf {w} _{m}\}}
  
 and we can adjoin another vector 
  
    
      
        
          
            w
          
          
            m
            +
            1
          
        
      
    
    {\displaystyle \mathbf {w} _{m+1}}
  
. But, since 
  
    
      
        {
        
          
            w
          
          
            1
          
        
        ,
        …
        ,
        
          
            w
          
          
            m
          
        
        }
      
    
    {\displaystyle \{\mathbf {w} _{1},\ldots ,\mathbf {w} _{m}\}}
  
 is a spanning set of V, 
  
    
      
        
          
            w
          
          
            m
            +
            1
          
        
      
    
    {\displaystyle \mathbf {w} _{m+1}}
  
 is a linear combination of 
  
    
      
        {
        
          
            w
          
          
            1
          
        
        ,
        …
        ,
        
          
            w
          
          
            m
          
        
        }
      
    
    {\displaystyle \{\mathbf {w} _{1},\ldots ,\mathbf {w} _{m}\}}
  
. This is a contradiction, since W is linearly independent.


=== Spanning set can be reduced to a basis ===
Let V be a finite-dimensional vector space. Any set of vectors that spans V can be reduced to a basis for V, by discarding vectors if necessary (i.e. if there are linearly dependent vectors in the set). If the axiom of choice holds, this is true without the assumption that V has finite dimension. This also indicates that a basis is a minimal spanning set when V is finite-dimensional.


== Generalizations ==
Generalizing the definition of the span of points in space, a subset X of the ground set of a matroid is called a spanning set if the rank of X equals the rank of the entire ground set
The vector space definition can also be generalized to modules. Given an R-module A and a collection of elements a1, ..., an of A, the submodule of A spanned by a1, ..., an is the sum of cyclic modules

  
    
      
        R
        
          a
          
            1
          
        
        +
        ⋯
        +
        R
        
          a
          
            n
          
        
        =
        
          {
          
            
              ∑
              
                k
                =
                1
              
              
                n
              
            
            
              r
              
                k
              
            
            
              a
              
                k
              
            
            
              
                |
              
            
            
              r
              
                k
              
            
            ∈
            R
          
          }
        
      
    
    {\displaystyle Ra_{1}+\cdots +Ra_{n}=\left\{\sum _{k=1}^{n}r_{k}a_{k}{\bigg |}r_{k}\in R\right\}}
  

consisting of all R-linear combinations of the elements ai. As with the case of vector spaces, the submodule of A spanned by any subset of A is the intersection of all submodules containing that subset.


== Closed linear span (functional analysis) ==
In functional analysis, a closed linear span of a set of vectors is the minimal closed set which contains the linear span of that set.
Suppose that X is a normed vector space and let E be any non-empty subset of X. The closed linear span of E, denoted by 
  
    
      
        
          
            Sp
            ¯
          
        
        (
        E
        )
      
    
    {\displaystyle {\overline {\operatorname {Sp} }}(E)}
  
 or 
  
    
      
        
          
            Span
            ¯
          
        
        (
        E
        )
      
    
    {\displaystyle {\overline {\operatorname {Span} }}(E)}
  
, is the intersection of all the closed linear subspaces of X which contain E.
One mathematical formulation of this is

  
    
      
        
          
            Sp
            ¯
          
        
        (
        E
        )
        =
        {
        u
        ∈
        X
        
          |
        
        ∀
        ε
        >
        0
        
        ∃
        x
        ∈
        Sp
        ⁡
        (
        E
        )
        :
        ‖
        x
        −
        u
        ‖
        <
        ε
        }
        .
      
    
    {\displaystyle {\overline {\operatorname {Sp} }}(E)=\{u\in X|\forall \varepsilon >0\,\exists x\in \operatorname {Sp} (E):\|x-u\|<\varepsilon \}.}
  

The closed linear span of the set of functions xn on the interval [0, 1], where n is a non-negative integer, depends on the norm used. If the L2 norm is used, then the closed linear span is the Hilbert space of square-integrable functions on the interval. But if the maximum norm is used, the closed linear span will be the space of continuous functions on the interval. In either case, the closed linear span contains functions that are not polynomials, and so are not in the linear span itself. However, the cardinality of the set of functions in the closed linear span is the cardinality of the continuum, which is the same cardinality as for the set of polynomials.


=== Notes ===
The linear span of a set is dense in the closed linear span. Moreover, as stated in the lemma below, the closed linear span is indeed the closure of the linear span.
Closed linear spans are important when dealing with closed linear subspaces (which are themselves highly important, see Riesz's lemma).


=== A useful lemma ===
Let X be a normed space and let E be any non-empty subset of X. Then

(So the usual way to find the closed linear span is to find the linear span first, and then the closure of that linear span.)


== See also ==
Affine hull
Conical combination
Convex hull


== Footnotes ==


== Citations ==


== Sources ==


=== Textbooks ===
Axler, Sheldon Jay (2015). Linear Algebra Done Right (PDF) (3rd ed.).  Springer. ISBN 978-3-319-11079-0.
Hefferon, Jim (2020). Linear Algebra (PDF) (4th ed.). Orthogonal Publishing. ISBN 978-1-944325-11-4.
Mac Lane, Saunders; Birkhoff, Garrett (1999) [1988]. Algebra (3rd ed.). AMS Chelsea Publishing. ISBN 978-0821816462.
Oxley, James G. (2011). Matroid Theory. Oxford Graduate Texts in Mathematics. Vol. 3 (2nd ed.). Oxford University Press. ISBN 9780199202508.
Roman, Steven (2005). Advanced Linear Algebra (PDF) (2nd ed.). Springer. ISBN 0-387-24766-1.
Rynne, Brian P.; Youngson, Martin A. (2008). Linear Functional Analysis. Springer. ISBN 978-1848000049.
Lay, David C. (2021) Linear Algebra and Its Applications (6th Edition). Pearson.


=== Web ===
Lankham, Isaiah; Nachtergaele, Bruno; Schilling, Anne (13 February 2010). "Linear Algebra - As an Introduction to Abstract Mathematics" (PDF). University of California, Davis. Retrieved 27 September 2011.
Weisstein, Eric Wolfgang. "Vector Space Span". MathWorld. Retrieved 16 Feb 2021.
"Linear hull". Encyclopedia of Mathematics. 5 April 2020. Retrieved 16 Feb 2021.


== External links ==
Linear Combinations and Span: Understanding linear combinations and spans of vectors, khanacademy.org.
Sanderson, Grant (August 6, 2016). "Linear combinations, span, and basis vectors". Essence of Linear Algebra. Archived from the original on 2021-12-11 – via YouTube.