The Ho–Kashyap algorithm is an iterative method in machine learning for finding a linear decision boundary that separates two linearly separable classes. It was developed by Yu-Chi Ho and Rangasami L. Kashyap in 1965, and usually presented as a problem in linear programming.


== Setup ==
Given a training set consisting of samples from two classes, the Ho–Kashyap algorithm seeks to find a weight vector 
  
    
      
        
          w
        
      
    
    {\displaystyle \mathbf {w} }
  
 and a margin vector 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
 such that:

  
    
      
        
          Y
          w
        
        =
        
          b
        
      
    
    {\displaystyle \mathbf {Yw} =\mathbf {b} }
  

where 
  
    
      
        
          Y
        
      
    
    {\displaystyle \mathbf {Y} }
  
 is the augmented data matrix with samples from both classes (with appropriate sign conventions, e.g., samples from class 2 are negated), 
  
    
      
        
          w
        
      
    
    {\displaystyle \mathbf {w} }
  
 is the weight vector to be determined, and 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
 is a positive margin vector.
The algorithm minimizes the criterion function:

  
    
      
        J
        (
        
          w
        
        ,
        
          b
        
        )
        =
        
          |
        
        
          |
        
        
          Y
          w
        
        −
        
          b
        
        
          |
        
        
          
            |
          
          
            2
          
        
      
    
    {\displaystyle J(\mathbf {w} ,\mathbf {b} )=||\mathbf {Yw} -\mathbf {b} ||^{2}}
  
subject to the constraint that 
  
    
      
        
          b
        
        >
        
          0
        
      
    
    {\displaystyle \mathbf {b} >\mathbf {0} }
  
 (element-wise).
Given a problem of linearly separating two classes, we consider a dataset of elements 
  
    
      
        {
        (
        
          
            x
            
              i
            
          
        
        ,
        
          y
          
            i
          
        
        )
        
          }
          
            i
            ∈
            1
            :
            N
          
        
      
    
    {\displaystyle \{(\mathbf {x_{i}} ,y_{i})\}_{i\in 1:N}}
  
 where 
  
    
      
        
          y
          
            i
          
        
        ∈
        {
        −
        1
        ,
        +
        1
        }
      
    
    {\displaystyle y_{i}\in \{-1,+1\}}
  
. Linearly separating them by a perceptron is equivalent to finding weight and bias 
  
    
      
        
          w
        
        ,
        b
      
    
    {\displaystyle \mathbf {w} ,b}
  
 for a perceptron, such that:
  
    
      
        
          
            [
            
              
                
                  
                    y
                    
                      1
                    
                  
                  
                    
                      x
                    
                    
                      1
                    
                  
                
                
                  1
                
              
              
                
                  ⋮
                
                
                  ⋮
                
              
              
                
                  
                    y
                    
                      N
                    
                  
                  
                    
                      x
                    
                    
                      N
                    
                  
                
                
                  1
                
              
            
            ]
          
        
        
          
            [
            
              
                
                  
                    w
                  
                
              
              
                
                  b
                
              
            
            ]
          
        
        >
        0
      
    
    {\displaystyle {\begin{bmatrix}y_{1}\mathbf {x} _{1}&1\\\vdots &\vdots \\y_{N}\mathbf {x} _{N}&1\\\end{bmatrix}}{\begin{bmatrix}\mathbf {w} \\b\end{bmatrix}}>0}
  


== Algorithm ==
The idea of the Ho–Kashyap rule is as follows:

Given any 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
, the corresponding 
  
    
      
        
          w
        
      
    
    {\displaystyle \mathbf {w} }
  
 is known: It is simply 
  
    
      
        
          w
        
        =
        
          
            Y
          
          
            +
          
        
        
          b
        
      
    
    {\displaystyle \mathbf {w} =\mathbf {Y} ^{+}\mathbf {b} }
  
, where 
  
    
      
        
          
            Y
          
          
            +
          
        
      
    
    {\displaystyle \mathbf {Y} ^{+}}
  
 denotes the Moore–Penrose pseudoinverse of 
  
    
      
        
          Y
        
      
    
    {\displaystyle \mathbf {Y} }
  
.
Therefore, it only remains to find 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
 by gradient descent.
However, the gradient descent may sometimes decrease some of the coordinates of 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
, which may cause some coordinates of 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
  to become negative, which is undesirable. Therefore, whenever some coordinates of 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
 would have decreased, those coordinates are unchanged instead. As for the coordinates of 
  
    
      
        
          b
        
      
    
    {\displaystyle \mathbf {b} }
  
 that would increase, those would increase without issue.
Formally, the algorithm is as follows:

Initialization: Set 
  
    
      
        
          b
        
        (
        0
        )
      
    
    {\displaystyle \mathbf {b} (0)}
  
 to an arbitrary positive vector, typically 
  
    
      
        
          b
        
        (
        0
        )
        =
        
          1
        
      
    
    {\displaystyle \mathbf {b} (0)=\mathbf {1} }
  
 (a vector of ones). Set the iteration counter 
  
    
      
        k
        =
        0
      
    
    {\displaystyle k=0}
  
. Set 
  
    
      
        
          w
        
        (
        0
        )
        =
        
          
            Y
          
          
            +
          
        
        
          b
        
        (
        0
        )
      
    
    {\displaystyle \mathbf {w} (0)=\mathbf {Y} ^{+}\mathbf {b} (0)}
  

Loop until convergence, or until iteration counter exceeds some 
  
    
      
        
          k
          
            m
            a
            x
          
        
      
    
    {\displaystyle k_{max}}
  
.
Error calculation: Compute the error vector: 
  
    
      
        
          e
        
        (
        k
        )
        =
        
          Y
          w
        
        (
        k
        )
        −
        
          b
        
        (
        k
        )
      
    
    {\displaystyle \mathbf {e} (k)=\mathbf {Yw} (k)-\mathbf {b} (k)}
  
.
Margin update: Update the margin vector: 
  
    
      
        
          b
        
        (
        k
        +
        1
        )
        =
        
          b
        
        (
        k
        )
        +
        2
        
          η
          
            k
          
        
        (
        
          e
        
        (
        k
        )
        +
        
          |
        
        
          e
        
        (
        k
        )
        
          |
        
        )
      
    
    {\displaystyle \mathbf {b} (k+1)=\mathbf {b} (k)+2\eta _{k}(\mathbf {e} (k)+|\mathbf {e} (k)|)}
  
 where 
  
    
      
        
          η
          
            k
          
        
      
    
    {\displaystyle \eta _{k}}
  
 is a positive learning rate parameter, and 
  
    
      
        
          |
        
        
          e
        
        (
        k
        )
        
          |
        
      
    
    {\displaystyle |\mathbf {e} (k)|}
  
 denotes the element-wise absolute value.
Weight calculation: Compute the weight vector using the pseudoinverse: 
  
    
      
        
          w
        
        (
        k
        +
        1
        )
        =
        
          
            Y
          
          
            +
          
        
        
          b
        
        (
        k
        +
        1
        )
      
    
    {\displaystyle \mathbf {w} (k+1)=\mathbf {Y} ^{+}\mathbf {b} (k+1)}
  
.
Convergence check: If 
  
    
      
        
          |
        
        
          |
        
        
          e
        
        (
        k
        )
        
          |
        
        
          |
        
        ≤
        θ
      
    
    {\displaystyle ||\mathbf {e} (k)||\leq \theta }
  
 for some predetermined threshold 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 (close to zero), then return 
  
    
      
        
          b
        
        (
        k
        +
        1
        )
        ,
        
          w
        
        (
        k
        +
        1
        )
      
    
    {\displaystyle \mathbf {b} (k+1),\mathbf {w} (k+1)}
  
.
if 
  
    
      
        
          e
        
        (
        k
        )
        ≤
        
          0
        
      
    
    {\displaystyle \mathbf {e} (k)\leq \mathbf {0} }
  
 (all components non-positive), return "Samples not separable.".
Return "Algorithm failed to converge in time.".


== Properties ==
If the training data is linearly separable, the algorithm converges to a solution (where 
  
    
      
        
          e
        
        (
        k
        )
        =
        
          0
        
      
    
    {\displaystyle \mathbf {e} (k)=\mathbf {0} }
  
) in a finite number of iterations.
If the data is not linearly separable, the algorithm may or may not ever reach the point where 
  
    
      
        
          e
        
        (
        k
        )
        =
        
          0
        
      
    
    {\displaystyle \mathbf {e} (k)=\mathbf {0} }
  
. However, if it does happen that 
  
    
      
        
          e
        
        (
        k
        )
        ≤
        
          0
        
      
    
    {\displaystyle \mathbf {e} (k)\leq \mathbf {0} }
  
 at some iteration, this proves non-separability.
The convergence rate depends on the choice of the learning rate parameter 
  
    
      
        ρ
      
    
    {\displaystyle \rho }
  
 and the degree of linear separability of the data.


== Relationship to other algorithms ==
Perceptron algorithm: Both seek linear separators. The perceptron updates weights incrementally based on individual misclassified samples, while Ho–Kashyap is a batch method that processes all samples to compute the pseudoinverse and updates based on an overall error vector.
Linear discriminant analysis (LDA): LDA assumes underlying Gaussian distributions with equal covariances for the classes and derives the decision boundary from these statistical assumptions. Ho–Kashyap makes no explicit distributional assumptions and instead tries to solve a system of linear inequalities directly.
Support vector machines (SVM): For linearly separable data, SVMs aim to find the maximum-margin hyperplane. The Ho–Kashyap algorithm finds a separating hyperplane but not necessarily the one with the maximum margin. If the data is not separable, soft-margin SVMs allow for some misclassifications by optimizing a trade-off between margin size and misclassification penalty, while Ho–Kashyap provides a least-squares solution.


== Variants ==
Modified Ho–Kashyap algorithm changes weight calculation step 
  
    
      
        
          w
        
        (
        k
        +
        1
        )
        =
        
          
            Y
          
          
            +
          
        
        
          b
        
        (
        k
        +
        1
        )
      
    
    {\displaystyle \mathbf {w} (k+1)=\mathbf {Y} ^{+}\mathbf {b} (k+1)}
  
 to 
  
    
      
        
          w
        
        (
        k
        +
        1
        )
        =
        
          w
        
        (
        k
        )
        +
        
          η
          
            k
          
        
        
          
            Y
          
          
            +
          
        
        
          |
        
        
          e
        
        (
        k
        )
        
          |
        
      
    
    {\displaystyle \mathbf {w} (k+1)=\mathbf {w} (k)+\eta _{k}\mathbf {Y} ^{+}|\mathbf {e} (k)|}
  
.
Kernel Ho–Kashyap algorithm: Applies kernel methods (the "kernel trick") to the Ho–Kashyap framework to enable non-linear classification by implicitly mapping data to a higher-dimensional feature space.


== See also ==
Linear classifier
Perceptron
Pattern recognition
Machine learning
Support vector machine
Moore–Penrose pseudoinverse


== References ==

Duda, R. O.; Hart, P. E.; Stork, D. G. (2001). "5.9. The Ho–Kashyap Procedures". Pattern Classification (2nd ed.). Wiley-Interscience. ISBN 978-0-471-05669-0.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer. ISBN 978-0-387-31073-2.
Theodoridis, S.; Koutroumbas, K. (2008). Pattern Recognition (4th ed.). Academic Press. ISBN 978-1-59749-272-0.