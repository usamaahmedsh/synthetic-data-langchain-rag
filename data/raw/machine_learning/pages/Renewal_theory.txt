Renewal theory is the branch of probability theory that generalizes the Poisson process for arbitrary holding times. Instead of exponentially distributed holding times, a renewal process may have any independent and identically distributed (IID) holding times that have finite expectation. A renewal-reward process additionally has a random sequence of rewards incurred at each holding time, which are IID but need not be independent of the holding times.
A renewal process has asymptotic properties analogous to the strong law of large numbers and central limit theorem. The renewal function 
  
    
      
        m
        (
        t
        )
      
    
    {\displaystyle m(t)}
  
 (expected number of arrivals) and reward function 
  
    
      
        g
        (
        t
        )
      
    
    {\displaystyle g(t)}
  
 (expected reward value) are of key importance in renewal theory. The renewal function satisfies a recursive integral equation, the renewal equation. The key renewal equation gives the limiting value of the convolution of 
  
    
      
        
          m
          ′
        
        (
        t
        )
      
    
    {\displaystyle m'(t)}
  
 with a suitable non-negative function. The superposition of renewal processes can be studied as a special case of Markov renewal processes.
Applications include calculating the best strategy for replacing worn-out machinery in a factory; comparing the long-term benefits of different insurance policies; and modelling the transmission of infectious disease, where "One of the most widely adopted means of inference of the reproduction number is via the renewal equation". The inspection paradox relates to the fact that observing a renewal interval at time t gives an interval with average value larger than that of an average renewal interval.


== Renewal processes ==


=== Introduction ===
The renewal process is a generalization of the Poisson process. In essence, the Poisson process is a continuous-time Markov process on the positive integers (usually starting at zero) which has independent exponentially distributed holding times at each integer 
  
    
      
        i
      
    
    {\displaystyle i}
  
 before advancing to the next integer, 
  
    
      
        i
        +
        1
      
    
    {\displaystyle i+1}
  
. In a renewal process, the holding times need not have an exponential distribution; rather, the holding times may have any distribution on the positive numbers, so long as the holding times are independent and identically distributed (IID) and have finite mean.


=== Formal definition ===

Let 
  
    
      
        (
        
          S
          
            i
          
        
        
          )
          
            i
            ≥
            1
          
        
      
    
    {\displaystyle (S_{i})_{i\geq 1}}
  
 be a sequence of positive independent identically distributed random variables with finite expected value

  
    
      
        0
        <
        E
        ⁡
        [
        
          S
          
            i
          
        
        ]
        <
        ∞
        .
      
    
    {\displaystyle 0<\operatorname {E} [S_{i}]<\infty .}
  

We refer to the random variable 
  
    
      
        
          S
          
            i
          
        
      
    
    {\displaystyle S_{i}}
  
 as the "
  
    
      
        i
      
    
    {\displaystyle i}
  
-th holding time".
Define for each n > 0 :

  
    
      
        
          J
          
            n
          
        
        =
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        
          S
          
            i
          
        
        ,
      
    
    {\displaystyle J_{n}=\sum _{i=1}^{n}S_{i},}
  

each 
  
    
      
        
          J
          
            n
          
        
      
    
    {\displaystyle J_{n}}
  
 is referred to as the "
  
    
      
        n
      
    
    {\displaystyle n}
  
-th jump time" and the intervals 
  
    
      
        [
        
          J
          
            n
          
        
        ,
        
          J
          
            n
            +
            1
          
        
        ]
      
    
    {\displaystyle [J_{n},J_{n+1}]}
  
 are called "renewal intervals".
Then 
  
    
      
        (
        
          X
          
            t
          
        
        
          )
          
            t
            ≥
            0
          
        
      
    
    {\displaystyle (X_{t})_{t\geq 0}}
  
 is given by random variable

  
    
      
        
          X
          
            t
          
        
        =
        
          ∑
          
            n
            =
            1
          
          
            ∞
          
        
        
          
            
              I
            
          
          
            {
            
              J
              
                n
              
            
            ≤
            t
            }
          
        
        =
        sup
        
          {
          
            
            n
            :
            
              J
              
                n
              
            
            ≤
            t
            
          
          }
        
      
    
    {\displaystyle X_{t}=\sum _{n=1}^{\infty }\operatorname {\mathbb {I} } _{\{J_{n}\leq t\}}=\sup \left\{\,n:J_{n}\leq t\,\right\}}
  

where 
  
    
      
        
          
            
              I
            
          
          
            {
            
              J
              
                n
              
            
            ≤
            t
            }
          
        
      
    
    {\displaystyle \operatorname {\mathbb {I} } _{\{J_{n}\leq t\}}}
  
 is the indicator function

  
    
      
        
          
            
              I
            
          
          
            {
            
              J
              
                n
              
            
            ≤
            t
            }
          
        
        =
        
          
            {
            
              
                
                  1
                  ,
                
                
                  
                    if 
                  
                  
                    J
                    
                      n
                    
                  
                  ≤
                  t
                
              
              
                
                  0
                  ,
                
                
                  
                    otherwise
                  
                
              
            
            
          
        
      
    
    {\displaystyle \operatorname {\mathbb {I} } _{\{J_{n}\leq t\}}={\begin{cases}1,&{\text{if }}J_{n}\leq t\\0,&{\text{otherwise}}\end{cases}}}
  

  
    
      
        (
        
          X
          
            t
          
        
        
          )
          
            t
            ≥
            0
          
        
      
    
    {\displaystyle (X_{t})_{t\geq 0}}
  
 represents the number of jumps that have occurred by time t, and is called a renewal process.


=== Interpretation ===
If one considers events occurring at random times, one may choose to think of the holding times 
  
    
      
        {
        
          S
          
            i
          
        
        :
        i
        ≥
        1
        }
      
    
    {\displaystyle \{S_{i}:i\geq 1\}}
  
 as the random time elapsed between two consecutive events. For example, if the renewal process is modelling the numbers of breakdown of different machines, then the holding time represents the time between one machine breaking down before another one does.
The Poisson process is the unique renewal process with the Markov property, as the exponential distribution is the unique continuous random variable with the property of memorylessness.


== Renewal-reward processes ==

Let 
  
    
      
        
          W
          
            1
          
        
        ,
        
          W
          
            2
          
        
        ,
        …
      
    
    {\displaystyle W_{1},W_{2},\ldots }
  
 be a sequence of IID random variables (rewards) satisfying

  
    
      
        E
        ⁡
        
          |
        
        
          W
          
            i
          
        
        
          |
        
        <
        ∞
        .
        
      
    
    {\displaystyle \operatorname {E} |W_{i}|<\infty .\,}
  

Then the random variable

  
    
      
        
          Y
          
            t
          
        
        =
        
          ∑
          
            i
            =
            1
          
          
            
              X
              
                t
              
            
          
        
        
          W
          
            i
          
        
      
    
    {\displaystyle Y_{t}=\sum _{i=1}^{X_{t}}W_{i}}
  

is called a renewal-reward process. Note that unlike the 
  
    
      
        
          S
          
            i
          
        
      
    
    {\displaystyle S_{i}}
  
, each 
  
    
      
        
          W
          
            i
          
        
      
    
    {\displaystyle W_{i}}
  
 may take negative values as well as positive values.
The random variable 
  
    
      
        
          Y
          
            t
          
        
      
    
    {\displaystyle Y_{t}}
  
 depends on two sequences: the holding times 
  
    
      
        
          S
          
            1
          
        
        ,
        
          S
          
            2
          
        
        ,
        …
      
    
    {\displaystyle S_{1},S_{2},\ldots }
  
 and the rewards

  
    
      
        
          W
          
            1
          
        
        ,
        
          W
          
            2
          
        
        ,
        …
      
    
    {\displaystyle W_{1},W_{2},\ldots }
  
 These two sequences need not be independent. In particular, 
  
    
      
        
          W
          
            i
          
        
      
    
    {\displaystyle W_{i}}
  
 may be a function
of 
  
    
      
        
          S
          
            i
          
        
      
    
    {\displaystyle S_{i}}
  
.


=== Interpretation ===
In the context of the above interpretation of the holding times as the time between successive malfunctions of a machine, the "rewards" 
  
    
      
        
          W
          
            1
          
        
        ,
        
          W
          
            2
          
        
        ,
        …
      
    
    {\displaystyle W_{1},W_{2},\ldots }
  
 (which in this case happen to be negative) may be viewed as the successive repair costs incurred as a result of the successive malfunctions.
An alternative analogy is that we have a magic goose which lays eggs at intervals (holding times) distributed as 
  
    
      
        
          S
          
            i
          
        
      
    
    {\displaystyle S_{i}}
  
. Sometimes it lays golden eggs of random weight, and sometimes it lays toxic eggs (also of random weight) which require responsible (and costly) disposal. The "rewards" 
  
    
      
        
          W
          
            i
          
        
      
    
    {\displaystyle W_{i}}
  
 are the successive (random) financial losses/gains resulting from successive eggs (i = 1,2,3,...) and 
  
    
      
        
          Y
          
            t
          
        
      
    
    {\displaystyle Y_{t}}
  
 records the total financial "reward" at time t.


== Renewal function ==
We define the renewal function as the expected value of the number of jumps observed up to some time 
  
    
      
        t
      
    
    {\displaystyle t}
  
:

  
    
      
        m
        (
        t
        )
        =
        E
        ⁡
        [
        
          X
          
            t
          
        
        ]
        .
        
      
    
    {\displaystyle m(t)=\operatorname {E} [X_{t}].\,}
  


=== Elementary renewal theorem ===
The renewal function satisfies

  
    
      
        
          lim
          
            t
            →
            ∞
          
        
        
          
            1
            t
          
        
        m
        (
        t
        )
        =
        
          
            1
            
              E
              ⁡
              [
              
                S
                
                  1
                
              
              ]
            
          
        
        .
      
    
    {\displaystyle \lim _{t\to \infty }{\frac {1}{t}}m(t)={\frac {1}{\operatorname {E} [S_{1}]}}.}
  


=== Elementary renewal theorem for renewal reward processes ===
We define the reward function:

  
    
      
        g
        (
        t
        )
        =
        E
        ⁡
        [
        
          Y
          
            t
          
        
        ]
        .
        
      
    
    {\displaystyle g(t)=\operatorname {E} [Y_{t}].\,}
  

The reward function satisfies

  
    
      
        
          lim
          
            t
            →
            ∞
          
        
        
          
            1
            t
          
        
        g
        (
        t
        )
        =
        
          
            
              E
              ⁡
              [
              
                W
                
                  1
                
              
              ]
            
            
              E
              ⁡
              [
              
                S
                
                  1
                
              
              ]
            
          
        
        .
      
    
    {\displaystyle \lim _{t\to \infty }{\frac {1}{t}}g(t)={\frac {\operatorname {E} [W_{1}]}{\operatorname {E} [S_{1}]}}.}
  


=== Renewal equation ===
The renewal function satisfies

  
    
      
        m
        (
        t
        )
        =
        
          F
          
            S
          
        
        (
        t
        )
        +
        
          ∫
          
            0
          
          
            t
          
        
        m
        (
        t
        −
        s
        )
        
          f
          
            S
          
        
        (
        s
        )
        
        d
        s
      
    
    {\displaystyle m(t)=F_{S}(t)+\int _{0}^{t}m(t-s)f_{S}(s)\,ds}
  

where 
  
    
      
        
          F
          
            S
          
        
      
    
    {\displaystyle F_{S}}
  
 is the cumulative distribution function of 
  
    
      
        
          S
          
            1
          
        
      
    
    {\displaystyle S_{1}}
  
 and 
  
    
      
        
          f
          
            S
          
        
      
    
    {\displaystyle f_{S}}
  
 is the corresponding probability density function.


== Key renewal theorem ==
Let X be a renewal process with renewal function 
  
    
      
        m
        (
        t
        )
      
    
    {\displaystyle m(t)}
  
 and interrenewal mean 
  
    
      
        μ
      
    
    {\displaystyle \mu }
  
. Let 
  
    
      
        g
        :
        [
        0
        ,
        ∞
        )
        →
        [
        0
        ,
        ∞
        )
      
    
    {\displaystyle g:[0,\infty )\rightarrow [0,\infty )}
  
 be a function satisfying:

  
    
      
        
          ∫
          
            0
          
          
            ∞
          
        
        g
        (
        t
        )
        
        d
        t
        <
        ∞
      
    
    {\displaystyle \int _{0}^{\infty }g(t)\,dt<\infty }
  

g is monotone and non-increasing
The key renewal theorem states that, as 
  
    
      
        t
        →
        ∞
      
    
    {\displaystyle t\rightarrow \infty }
  
:

  
    
      
        
          ∫
          
            0
          
          
            t
          
        
        g
        (
        t
        −
        x
        )
        
          m
          ′
        
        (
        x
        )
        
        d
        x
        →
        
          
            1
            μ
          
        
        
          ∫
          
            0
          
          
            ∞
          
        
        g
        (
        x
        )
        
        d
        x
      
    
    {\displaystyle \int _{0}^{t}g(t-x)m'(x)\,dx\rightarrow {\frac {1}{\mu }}\int _{0}^{\infty }g(x)\,dx}
  


=== Renewal theorem ===
Considering 
  
    
      
        g
        (
        x
        )
        =
        
          
            I
          
          
            [
            0
            ,
            h
            ]
          
        
        (
        x
        )
      
    
    {\displaystyle g(x)=\mathbb {I} _{[0,h]}(x)}
  
 for any 
  
    
      
        h
        >
        0
      
    
    {\displaystyle h>0}
  
 gives as a special case the renewal theorem:

  
    
      
        m
        (
        t
        +
        h
        )
        −
        m
        (
        t
        )
        →
        
          
            h
            μ
          
        
      
    
    {\displaystyle m(t+h)-m(t)\rightarrow {\frac {h}{\mu }}}
  
 as 
  
    
      
        t
        →
        ∞
      
    
    {\displaystyle t\rightarrow \infty }
  

The result can be proved using integral equations or by a coupling argument. Though a special case of the key renewal theorem, it can be used to deduce the full theorem, by considering step functions and then increasing sequences of step functions.


== Asymptotic properties ==
Renewal processes and renewal-reward processes have properties analogous to the strong law of large numbers, which can be derived from the same theorem. If 
  
    
      
        (
        
          X
          
            t
          
        
        
          )
          
            t
            ≥
            0
          
        
      
    
    {\displaystyle (X_{t})_{t\geq 0}}
  
 is a renewal process and 
  
    
      
        (
        
          Y
          
            t
          
        
        
          )
          
            t
            ≥
            0
          
        
      
    
    {\displaystyle (Y_{t})_{t\geq 0}}
  
 is a renewal-reward process then:

  
    
      
        
          lim
          
            t
            →
            ∞
          
        
        
          
            1
            t
          
        
        
          X
          
            t
          
        
        =
        
          
            1
            
              E
              ⁡
              [
              
                S
                
                  1
                
              
              ]
            
          
        
      
    
    {\displaystyle \lim _{t\to \infty }{\frac {1}{t}}X_{t}={\frac {1}{\operatorname {E} [S_{1}]}}}
  

  
    
      
        
          lim
          
            t
            →
            ∞
          
        
        
          
            1
            t
          
        
        
          Y
          
            t
          
        
        =
        
          
            1
            
              E
              ⁡
              [
              
                S
                
                  1
                
              
              ]
            
          
        
        E
        ⁡
        [
        
          W
          
            1
          
        
        ]
      
    
    {\displaystyle \lim _{t\to \infty }{\frac {1}{t}}Y_{t}={\frac {1}{\operatorname {E} [S_{1}]}}\operatorname {E} [W_{1}]}
  

almost surely.

Renewal processes additionally have a property analogous to the central limit theorem:

  
    
      
        
          
            
              
                X
                
                  t
                
              
              −
              t
              
                /
              
              μ
            
            
              t
              
                σ
                
                  2
                
              
              
                /
              
              
                μ
                
                  3
                
              
            
          
        
        →
        
          
            N
          
        
        (
        0
        ,
        1
        )
      
    
    {\displaystyle {\frac {X_{t}-t/\mu }{\sqrt {t\sigma ^{2}/\mu ^{3}}}}\to {\mathcal {N}}(0,1)}
  


== Inspection paradox ==

A curious feature of renewal processes is that if we wait some predetermined time t and then observe how large the renewal interval containing t is, we should expect it to be typically larger than a renewal interval of average size.
Mathematically the inspection paradox states: for any t > 0 the renewal interval containing t is stochastically larger than the first renewal interval. That is, for all x > 0 and for all t > 0:

  
    
      
        P
        ⁡
        (
        
          S
          
            
              X
              
                t
              
            
            +
            1
          
        
        >
        x
        )
        ≥
        P
        ⁡
        (
        
          S
          
            1
          
        
        >
        x
        )
        =
        1
        −
        
          F
          
            S
          
        
        (
        x
        )
      
    
    {\displaystyle \operatorname {P} (S_{X_{t}+1}>x)\geq \operatorname {P} (S_{1}>x)=1-F_{S}(x)}
  

where FS is the cumulative distribution function of the IID holding times Si. A vivid example is the bus waiting time paradox: For a given random distribution of bus arrivals, the average rider at a bus stop observes more delays than the average operator of the buses.
The resolution of the paradox is that our sampled distribution at time t is size-biased (see sampling bias), in that the likelihood an interval is chosen is proportional to its size. However, a renewal interval of average size is not size-biased.


== Superposition ==
Unless the renewal process is a Poisson process, the superposition (sum) of two independent renewal processes is not a renewal process. However, such processes can be described within a larger class of processes called the Markov-renewal processes. However, the cumulative distribution function of the first inter-event time in the superposition process is given by

  
    
      
        R
        (
        t
        )
        =
        1
        −
        
          ∑
          
            k
            =
            1
          
          
            K
          
        
        
          
            
              α
              
                k
              
            
            
              
                ∑
                
                  l
                  =
                  1
                
                
                  K
                
              
              
                α
                
                  l
                
              
            
          
        
        (
        1
        −
        
          R
          
            k
          
        
        (
        t
        )
        )
        
          ∏
          
            j
            =
            1
            ,
            j
            ≠
            k
          
          
            K
          
        
        
          α
          
            j
          
        
        
          ∫
          
            t
          
          
            ∞
          
        
        (
        1
        −
        
          R
          
            j
          
        
        (
        u
        )
        )
        
        
          d
        
        u
      
    
    {\displaystyle R(t)=1-\sum _{k=1}^{K}{\frac {\alpha _{k}}{\sum _{l=1}^{K}\alpha _{l}}}(1-R_{k}(t))\prod _{j=1,j\neq k}^{K}\alpha _{j}\int _{t}^{\infty }(1-R_{j}(u))\,{\text{d}}u}
  

where Rk(t) and αk > 0 are the CDF of the inter-event times and the arrival rate of process k.


== Example application ==
Eric the entrepreneur has n machines, each having an operational lifetime uniformly distributed between zero and two years. Eric may let each machine run until it fails with replacement cost €2600; alternatively he may replace a machine at any time while it is still functional at a cost of €200.
What is his optimal replacement policy?


== See also ==


== Notes ==


== References ==
Cox, David (1970). Renewal Theory. London: Methuen & Co. p. 142. ISBN 0-412-20570-X.
Doob, J. L. (1948). "Renewal Theory From the Point of View of the Theory of Probability" (PDF). Transactions of the American Mathematical Society. 63 (3): 422–438. doi:10.2307/1990567. JSTOR 1990567.
Feller, William (1971). An introduction to probability theory and its applications. Vol. 2 (second ed.). Wiley.
Grimmett, G. R.; Stirzaker, D. R. (1992). Probability and Random Processes (second ed.). Oxford University Press. ISBN 0-19-857222-0.
Smith, Walter L. (1958). "Renewal Theory and Its Ramifications". Journal of the Royal Statistical Society, Series B. 20 (2): 243–302. doi:10.1111/j.2517-6161.1958.tb00294.x. JSTOR 2983891.
Wanli Wang, Johannes H. P. Schulz, Weihua Deng, and Eli Barkai (2018). "Renewal theory with fat-tailed distributed sojourn times: Typical versus rare". Phys. Rev. E. 98 (4) 042139. arXiv:1809.05856. Bibcode:2018PhRvE..98d2139W. doi:10.1103/PhysRevE.98.042139. S2CID 54727926.{{cite journal}}:  CS1 maint: multiple names: authors list (link)