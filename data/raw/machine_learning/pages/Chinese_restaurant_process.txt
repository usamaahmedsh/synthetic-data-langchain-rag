In probability theory, the Chinese restaurant process is a discrete-time stochastic process, analogous to seating customers at tables in a restaurant.
Imagine a restaurant with an infinite number of circular tables, each with infinite capacity. Customer 1 sits at the first table. The next customer either sits at the same table as customer 1, or the next table. This continues, with each customer choosing to either sit at an occupied table with a probability proportional to the number of customers already there (i.e., they are more likely to sit at a table with many customers than few), or an unoccupied table. At time n, the n customers have been partitioned among m ≤ n tables (or blocks of the partition). The results of this process are exchangeable, meaning the order in which the customers sit does not affect the probability of the final distribution. This property greatly simplifies a number of problems in population genetics, linguistic analysis, and image recognition.
The restaurant analogy first appeared in a 1985 write-up by David Aldous, where it was attributed to Jim Pitman (who additionally credits Lester Dubins).
An equivalent partition process was published a year earlier by Fred Hoppe, using an "urn scheme" akin to Pólya's urn. In comparison with Hoppe's urn model, the Chinese restaurant process has the advantage that it naturally lends itself to describing random permutations via their cycle structure, in addition to describing random partitions.


== Formal definition ==
For any positive integer 
  
    
      
        n
      
    
    {\displaystyle n}
  
, let 
  
    
      
        
          
            
              P
            
          
          
            n
          
        
      
    
    {\displaystyle {\mathcal {P}}_{n}}
  
 denote the set of all partitions of the set 
  
    
      
        {
        1
        ,
        2
        ,
        3
        ,
        .
        .
        .
        ,
        n
        }
        ≜
        [
        n
        ]
      
    
    {\displaystyle \{1,2,3,...,n\}\triangleq [n]}
  
. The Chinese restaurant process takes values in the infinite Cartesian product 
  
    
      
        
          ∏
          
            n
            ≥
            1
          
        
        
          
            
              P
            
          
          
            n
          
        
      
    
    {\displaystyle \prod _{n\geq 1}{\mathcal {P}}_{n}}
  
.
The value of the process at time 
  
    
      
        n
      
    
    {\displaystyle n}
  
 is a partition 
  
    
      
        
          B
          
            n
          
        
      
    
    {\displaystyle B_{n}}
  
 of the set 
  
    
      
        [
        n
        ]
      
    
    {\displaystyle [n]}
  
, whose probability distribution is determined as follows.  At time 
  
    
      
        n
        =
        1
      
    
    {\displaystyle n=1}
  
, the trivial partition 
  
    
      
        
          B
          
            1
          
        
        =
        {
        {
        1
        }
        }
      
    
    {\displaystyle B_{1}=\{\{1\}\}}
  
 is obtained (with probability one). At time 
  
    
      
        n
        +
        1
      
    
    {\displaystyle n+1}
  
 the element "
  
    
      
        n
        +
        1
      
    
    {\displaystyle n+1}
  
" is either:

added to one of the blocks of the partition 
  
    
      
        
          B
          
            n
          
        
      
    
    {\displaystyle B_{n}}
  
, where each block is chosen with probability 
  
    
      
        
          |
        
        b
        
          |
        
        
          /
        
        (
        n
        +
        1
        )
      
    
    {\displaystyle |b|/(n+1)}
  
 where 
  
    
      
        
          |
        
        b
        
          |
        
      
    
    {\displaystyle |b|}
  
 is the size of the block (i.e. number of elements), or
added to the partition 
  
    
      
        
          B
          
            n
          
        
      
    
    {\displaystyle B_{n}}
  
 as a new singleton block, with probability 
  
    
      
        1
        
          /
        
        (
        n
        +
        1
        )
      
    
    {\displaystyle 1/(n+1)}
  
.
The random partition so generated has some special properties. It is exchangeable in the sense that relabeling 
  
    
      
        {
        1
        ,
        .
        .
        .
        ,
        n
        }
      
    
    {\displaystyle \{1,...,n\}}
  
 does not change the distribution of the partition, and it is consistent in the sense that the law of the partition of 
  
    
      
        [
        n
        −
        1
        ]
      
    
    {\displaystyle [n-1]}
  
 obtained by removing the element 
  
    
      
        n
      
    
    {\displaystyle n}
  
 from the random partition 
  
    
      
        
          B
          
            n
          
        
      
    
    {\displaystyle B_{n}}
  
 is the same as the law of the random partition 
  
    
      
        
          B
          
            n
            −
            1
          
        
      
    
    {\displaystyle B_{n-1}}
  
.
The probability assigned to any particular partition (ignoring the order in which customers sit around any particular table) is

  
    
      
        Pr
        (
        
          B
          
            n
          
        
        =
        B
        )
        =
        
          
            
              
                ∏
                
                  b
                  ∈
                  B
                
              
              (
              
                |
              
              b
              
                |
              
              −
              1
              )
              !
            
            
              n
              !
            
          
        
        ,
        
        B
        ∈
        
          
            
              P
            
          
          
            n
          
        
      
    
    {\displaystyle \Pr(B_{n}=B)={\frac {\prod _{b\in B}(|b|-1)!}{n!}},\qquad B\in {\mathcal {P}}_{n}}
  

where 
  
    
      
        b
      
    
    {\displaystyle b}
  
 is a block in the partition 
  
    
      
        B
      
    
    {\displaystyle B}
  
 and 
  
    
      
        
          |
        
        b
        
          |
        
      
    
    {\displaystyle |b|}
  
 is the size of 
  
    
      
        b
      
    
    {\displaystyle b}
  
.
The definition can be generalized by introducing a parameter 
  
    
      
        θ
        >
        0
      
    
    {\displaystyle \theta >0}
  
 which modifies the probability of the new customer sitting at a new table to 
  
    
      
        
          
            θ
            
              n
              +
              θ
            
          
        
      
    
    {\displaystyle {\frac {\theta }{n+\theta }}}
  
 and correspondingly modifies the probability of them sitting at a table of size 
  
    
      
        
          |
        
        b
        
          |
        
      
    
    {\displaystyle |b|}
  
 to 
  
    
      
        
          
            
              
                |
              
              b
              
                |
              
            
            
              n
              +
              θ
            
          
        
      
    
    {\displaystyle {\frac {|b|}{n+\theta }}}
  
. The vanilla process introduced above can be recovered by setting 
  
    
      
        θ
        =
        1
      
    
    {\displaystyle \theta =1}
  
. Intuitively, 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 can be interpreted as the effective number of customers sitting at the first empty table.


=== Alternative definition ===
An equivalent, but subtly different way to define the Chinese restaurant process, is to let new customers choose companions rather than tables. Customer 
  
    
      
        n
        +
        1
      
    
    {\displaystyle n+1}
  
 chooses to sit at the same table as any one of the 
  
    
      
        n
      
    
    {\displaystyle n}
  
 seated customers with probability 
  
    
      
        
          
            1
            
              n
              +
              θ
            
          
        
      
    
    {\displaystyle {\frac {1}{n+\theta }}}
  
, or chooses to sit at a new, unoccupied table with probability 
  
    
      
        
          
            θ
            
              n
              +
              θ
            
          
        
      
    
    {\displaystyle {\frac {\theta }{n+\theta }}}
  
. Notice that in this formulation, the customer chooses a table without having to count table occupancies---we don't need 
  
    
      
        
          |
        
        b
        
          |
        
      
    
    {\displaystyle |b|}
  
.


== Distribution of the number of tables ==

The Chinese restaurant table distribution (CRT) is the probability distribution on the number of tables in the Chinese restaurant process. It can be understood as the sum of 
  
    
      
        n
      
    
    {\displaystyle n}
  
 independent Bernoulli random variables, each with a different parameter:

  
    
      
        
          
            
              
                K
              
              
                
                =
                
                  ∑
                  
                    i
                    =
                    1
                  
                  
                    n
                  
                
                
                  b
                  
                    i
                  
                
              
            
            
              
                
                  b
                  
                    i
                  
                
              
              
                
                ∼
                Bernoulli
                ⁡
                
                  (
                  
                    
                      θ
                      
                        i
                        −
                        1
                        +
                        θ
                      
                    
                  
                  )
                
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}K&=\sum _{i=1}^{n}b_{i}\\[4pt]b_{i}&\sim \operatorname {Bernoulli} \left({\frac {\theta }{i-1+\theta }}\right)\end{aligned}}}
  

The probability mass function of 
  
    
      
        K
      
    
    {\displaystyle K}
  
 is given by 

  
    
      
        f
        (
        k
        )
        =
        
          
            
              Γ
              (
              θ
              )
            
            
              Γ
              (
              n
              +
              θ
              )
            
          
        
        
          |
        
        s
        (
        n
        ,
        k
        )
        
          |
        
        
          θ
          
            k
          
        
        ,
        
        k
        =
        1
        ,
        …
        ,
        n
        ,
      
    
    {\displaystyle f(k)={\frac {\Gamma (\theta )}{\Gamma (n+\theta )}}|s(n,k)|\theta ^{k},\quad k=1,\dots ,n,}
  

where 
  
    
      
        s
      
    
    {\displaystyle s}
  
 denotes Stirling numbers of the first kind.


== Two-parameter generalization ==
This construction can be generalized to a model with two parameters, 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 & 
  
    
      
        α
      
    
    {\displaystyle \alpha }
  
, commonly called the strength (or concentration) and discount parameters respectively.  At time 
  
    
      
        n
        +
        1
      
    
    {\displaystyle n+1}
  
, the next customer to arrive finds 
  
    
      
        
          |
        
        B
        
          |
        
      
    
    {\displaystyle |B|}
  
 occupied tables and decides to sit at an empty table with probability

  
    
      
        
          
            
              θ
              +
              
                |
              
              B
              
                |
              
              α
            
            
              n
              +
              θ
            
          
        
        ,
      
    
    {\displaystyle {\frac {\theta +|B|\alpha }{n+\theta }},}
  

or at an occupied table 
  
    
      
        b
      
    
    {\displaystyle b}
  
 of size 
  
    
      
        
          |
        
        b
        
          |
        
      
    
    {\displaystyle |b|}
  
 with probability

  
    
      
        
          
            
              
                |
              
              b
              
                |
              
              −
              α
            
            
              n
              +
              θ
            
          
        
        .
      
    
    {\displaystyle {\frac {|b|-\alpha }{n+\theta }}.}
  

In order for the construction to define a valid probability measure it is necessary to suppose that either 
  
    
      
        α
        <
        0
      
    
    {\displaystyle \alpha <0}
  
 and 
  
    
      
        θ
        =
        −
        L
        α
      
    
    {\displaystyle \theta =-L\alpha }
  
 for some 
  
    
      
        L
        ∈
        {
        1
        ,
        2
        ,
        ,
        .
        .
        .
        }
      
    
    {\displaystyle L\in \{1,2,,...\}}
  
; or that 
  
    
      
        0
        ≤
        α
        <
        1
      
    
    {\displaystyle 0\leq \alpha <1}
  
 and 
  
    
      
        θ
        >
        −
        α
      
    
    {\displaystyle \theta >-\alpha }
  
.
Under this model the probability assigned to any particular partition 
  
    
      
        B
      
    
    {\displaystyle B}
  
 of 
  
    
      
        [
        n
        ]
      
    
    {\displaystyle [n]}
  
, can be expressed in the general case (for any values of 
  
    
      
        θ
        ,
        α
      
    
    {\displaystyle \theta ,\alpha }
  
 that satisfy the above-mentioned constraints) in terms of the Pochhammer k-symbol, as

  
    
      
        Pr
        (
        
          B
          
            n
          
        
        =
        B
        ∣
        θ
        ,
        α
        )
        =
        
          
            
              (
              θ
              +
              α
              
                )
                
                  
                    |
                  
                  B
                  
                    |
                  
                  −
                  1
                  ,
                  α
                
              
            
            
              (
              θ
              +
              1
              
                )
                
                  n
                  −
                  1
                  ,
                  1
                
              
            
          
        
        
          ∏
          
            b
            ∈
            B
          
        
        (
        1
        −
        α
        
          )
          
            
              |
            
            b
            
              |
            
            −
            1
            ,
            1
          
        
      
    
    {\displaystyle \Pr(B_{n}=B\mid \theta ,\alpha )={\frac {(\theta +\alpha )_{|B|-1,\alpha }}{(\theta +1)_{n-1,1}}}\prod _{b\in B}(1-\alpha )_{|b|-1,1}}
  

where, the Pochhammer k-symbol is defined as follows: by convention, 
  
    
      
        (
        a
        
          )
          
            0
            ,
            k
          
        
        =
        1
      
    
    {\displaystyle (a)_{0,k}=1}
  
, and for 
  
    
      
        m
        >
        0
      
    
    {\displaystyle m>0}
  

  
    
      
        (
        a
        
          )
          
            m
            ,
            k
          
        
        =
        
          ∏
          
            i
            =
            0
          
          
            m
            −
            1
          
        
        (
        a
        +
        i
        k
        )
        =
        
          
            {
            
              
                
                  
                    a
                    
                      m
                    
                  
                
                
                  
                    if 
                  
                  k
                  =
                  0
                  ,
                
              
              
                
              
              
                
                  
                    k
                    
                      m
                    
                  
                  
                  (
                  
                    
                      a
                      k
                    
                  
                  
                    )
                    
                      
                        m
                        ¯
                      
                    
                  
                
                
                  
                    if 
                  
                  k
                  >
                  0
                  ,
                
              
              
                
              
              
                
                  
                    
                      |
                      k
                      |
                    
                    
                      m
                    
                  
                  
                  (
                  
                    
                      a
                      
                        |
                        k
                        |
                      
                    
                  
                  
                    )
                    
                      
                        m
                        _
                      
                    
                  
                
                
                  
                    if 
                  
                  k
                  <
                  0
                
              
            
            
          
        
      
    
    {\displaystyle (a)_{m,k}=\prod _{i=0}^{m-1}(a+ik)={\begin{cases}a^{m}&{\text{if }}k=0,\\\\k^{m}\,({\frac {a}{k}})^{\overline {m}}&{\text{if }}k>0,\\\\\left|k\right|^{m}\,({\frac {a}{\left|k\right|}})^{\underline {m}}&{\text{if }}k<0\end{cases}}}
  

where 
  
    
      
        
          x
          
            
              m
              ¯
            
          
        
        =
        
          ∏
          
            i
            =
            0
          
          
            m
            −
            1
          
        
        (
        x
        +
        i
        )
      
    
    {\displaystyle x^{\overline {m}}=\prod _{i=0}^{m-1}(x+i)}
  
 is the rising factorial and 
  
    
      
        
          x
          
            
              m
              _
            
          
        
        =
        
          ∏
          
            i
            =
            0
          
          
            m
            −
            1
          
        
        (
        x
        −
        i
        )
      
    
    {\displaystyle x^{\underline {m}}=\prod _{i=0}^{m-1}(x-i)}
  
 is the falling factorial. It is worth noting that for the parameter setting where 
  
    
      
        α
        <
        0
      
    
    {\displaystyle \alpha <0}
  
 and 
  
    
      
        θ
        =
        −
        L
        α
      
    
    {\displaystyle \theta =-L\alpha }
  
, then 
  
    
      
        (
        θ
        +
        α
        
          )
          
            
              |
            
            B
            
              |
            
            −
            1
            ,
            α
          
        
        =
        (
        
          |
        
        α
        
          |
        
        (
        L
        −
        1
        )
        
          )
          
            
              |
            
            B
            
              |
            
            −
            1
            ,
            α
          
        
      
    
    {\displaystyle (\theta +\alpha )_{|B|-1,\alpha }=(|\alpha |(L-1))_{|B|-1,\alpha }}
  
, which evaluates to zero whenever 
  
    
      
        
          |
        
        B
        
          |
        
        >
        L
      
    
    {\displaystyle |B|>L}
  
, so that 
  
    
      
        L
      
    
    {\displaystyle L}
  
 is an upper bound on the number of blocks in the partition; see the subsection on the Dirichlet-categorical model below for more details.
For the case when 
  
    
      
        θ
        >
        0
      
    
    {\displaystyle \theta >0}
  
 and 
  
    
      
        0
        <
        α
        <
        1
      
    
    {\displaystyle 0<\alpha <1}
  
, the partition probability can be rewritten in terms of the Gamma function as

  
    
      
        Pr
        (
        
          B
          
            n
          
        
        =
        B
        ∣
        θ
        ,
        α
        )
        =
        
          
            
              Γ
              (
              θ
              )
            
            
              Γ
              (
              θ
              +
              n
              )
            
          
        
        
          
            
              
                
                  α
                  
                    
                      |
                    
                    B
                    
                      |
                    
                  
                
                
                Γ
                (
                θ
                
                  /
                
                α
                +
                
                  |
                
                B
                
                  |
                
                )
              
              
                Γ
                (
                θ
                
                  /
                
                α
                )
              
            
          
        
        
          ∏
          
            b
            ∈
            B
          
        
        
          
            
              
                Γ
                (
                
                  |
                
                b
                
                  |
                
                −
                α
                )
              
              
                Γ
                (
                1
                −
                α
                )
              
            
          
        
        .
      
    
    {\displaystyle \Pr(B_{n}=B\mid \theta ,\alpha )={\frac {\Gamma (\theta )}{\Gamma (\theta +n)}}{\dfrac {\alpha ^{|B|}\,\Gamma (\theta /\alpha +|B|)}{\Gamma (\theta /\alpha )}}\prod _{b\in B}{\dfrac {\Gamma (|b|-\alpha )}{\Gamma (1-\alpha )}}.}
  

In the one-parameter case, where 
  
    
      
        α
      
    
    {\displaystyle \alpha }
  
 is zero, and 
  
    
      
        θ
        >
        0
      
    
    {\displaystyle \theta >0}
  
 this simplifies to

  
    
      
        Pr
        (
        
          B
          
            n
          
        
        =
        B
        ∣
        θ
        )
        =
        
          
            
              Γ
              (
              θ
              )
              
              
                θ
                
                  
                    |
                  
                  B
                  
                    |
                  
                
              
            
            
              Γ
              (
              θ
              +
              n
              )
            
          
        
        
          ∏
          
            b
            ∈
            B
          
        
        Γ
        (
        
          |
        
        b
        
          |
        
        )
        .
      
    
    {\displaystyle \Pr(B_{n}=B\mid \theta )={\frac {\Gamma (\theta )\,\theta ^{|B|}}{\Gamma (\theta +n)}}\prod _{b\in B}\Gamma (|b|).}
  

Or, when 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
 is zero, and 
  
    
      
        0
        <
        α
        <
        1
      
    
    {\displaystyle 0<\alpha <1}
  

  
    
      
        Pr
        (
        
          B
          
            n
          
        
        =
        B
        ∣
        α
        )
        =
        
          
            
              
                α
                
                  
                    |
                  
                  B
                  
                    |
                  
                  −
                  1
                
              
              
              Γ
              (
              
                |
              
              B
              
                |
              
              )
            
            
              Γ
              (
              n
              )
            
          
        
        
          ∏
          
            b
            ∈
            B
          
        
        
          
            
              Γ
              (
              
                |
              
              b
              
                |
              
              −
              α
              )
            
            
              Γ
              (
              1
              −
              α
              )
            
          
        
        .
      
    
    {\displaystyle \Pr(B_{n}=B\mid \alpha )={\frac {\alpha ^{|B|-1}\,\Gamma (|B|)}{\Gamma (n)}}\prod _{b\in B}{\frac {\Gamma (|b|-\alpha )}{\Gamma (1-\alpha )}}.}
  

As before, the probability assigned to any particular partition depends only on the block sizes, so as before the random partition is exchangeable in the sense described above.  The consistency property still holds, as before, by construction.
If 
  
    
      
        α
        =
        0
      
    
    {\displaystyle \alpha =0}
  
, the probability distribution of the random partition of the integer 
  
    
      
        n
      
    
    {\displaystyle n}
  
 thus generated is the Ewens distribution with parameter 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  
, used in population genetics and the unified neutral theory of biodiversity.


=== Derivation ===
Here is one way to derive this partition probability.  Let 
  
    
      
        
          C
          
            i
          
        
      
    
    {\displaystyle C_{i}}
  
 be the random block into which the number 
  
    
      
        i
      
    
    {\displaystyle i}
  
 is added, for 
  
    
      
        i
        =
        1
        ,
        2
        ,
        3
        ,
        .
        .
        .
      
    
    {\displaystyle i=1,2,3,...}
  
.  Then

  
    
      
        Pr
        (
        
          C
          
            i
          
        
        =
        c
        ∣
        
          C
          
            1
          
        
        ,
        …
        ,
        
          C
          
            i
            −
            1
          
        
        )
        =
        
          
            {
            
              
                
                  
                    
                      
                        
                          θ
                          +
                          
                            |
                          
                          B
                          
                            |
                          
                          α
                        
                        
                          θ
                          +
                          i
                          −
                          1
                        
                      
                    
                  
                
                
                  
                    if 
                  
                  c
                  ∈
                  
                    new block
                  
                  ,
                
              
              
                
              
              
                
                  
                    
                      
                        
                          
                            |
                          
                          b
                          
                            |
                          
                          −
                          α
                        
                        
                          θ
                          +
                          i
                          −
                          1
                        
                      
                    
                  
                
                
                  
                    if 
                  
                  c
                  ∈
                  b
                  ;
                
              
            
            
          
        
      
    
    {\displaystyle \Pr(C_{i}=c\mid C_{1},\ldots ,C_{i-1})={\begin{cases}{\dfrac {\theta +|B|\alpha }{\theta +i-1}}&{\text{if }}c\in {\text{new block}},\\\\{\dfrac {|b|-\alpha }{\theta +i-1}}&{\text{if }}c\in b;\end{cases}}}
  

The probability that 
  
    
      
        
          B
          
            n
          
        
      
    
    {\displaystyle B_{n}}
  
 is any particular partition of the set 
  
    
      
        {
        1
        ,
        .
        .
        .
        ,
        n
        }
      
    
    {\displaystyle \{1,...,n\}}
  
 is the product of these probabilities as 
  
    
      
        i
      
    
    {\displaystyle i}
  
 runs from 
  
    
      
        1
      
    
    {\displaystyle 1}
  
 to 
  
    
      
        n
      
    
    {\displaystyle n}
  
.  Now consider the size of block 
  
    
      
        b
      
    
    {\displaystyle b}
  
: it increases by one each time we add one element into it. When the last element in block 
  
    
      
        b
      
    
    {\displaystyle b}
  
 is to be added in, the block size is 
  
    
      
        
          |
        
        b
        
          |
        
        −
        1
      
    
    {\displaystyle |b|-1}
  
. For example, consider this sequence of choices: (generate a new block 
  
    
      
        b
      
    
    {\displaystyle b}
  
)(join 
  
    
      
        b
      
    
    {\displaystyle b}
  
)(join 
  
    
      
        b
      
    
    {\displaystyle b}
  
)(join 
  
    
      
        b
      
    
    {\displaystyle b}
  
). In the end, block 
  
    
      
        b
      
    
    {\displaystyle b}
  
 has 4 elements and the product of the numerators in the above equation gets 
  
    
      
        θ
        ⋅
        1
        ⋅
        2
        ⋅
        3
      
    
    {\displaystyle \theta \cdot 1\cdot 2\cdot 3}
  
.  Following this logic, we obtain 
  
    
      
        Pr
        (
        
          B
          
            n
          
        
        =
        B
        )
      
    
    {\displaystyle \Pr(B_{n}=B)}
  
 as above.


=== Expected number of tables ===
For the one parameter case, with 
  
    
      
        α
        =
        0
      
    
    {\displaystyle \alpha =0}
  
 and 
  
    
      
        0
        <
        θ
        <
        ∞
      
    
    {\displaystyle 0<\theta <\infty }
  
, the number of tables is distributed according to the chinese restaurant table distribution. The expected value of this random variable, given that there are 
  
    
      
        n
      
    
    {\displaystyle n}
  
 seated customers, is

  
    
      
        
          
            
              
                
                  ∑
                  
                    k
                    =
                    1
                  
                  
                    n
                  
                
                
                  
                    θ
                    
                      θ
                      +
                      k
                      −
                      1
                    
                  
                
                =
                θ
                ⋅
                (
                Ψ
                (
                θ
                +
                n
                )
                −
                Ψ
                (
                θ
                )
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\sum _{k=1}^{n}{\frac {\theta }{\theta +k-1}}=\theta \cdot (\Psi (\theta +n)-\Psi (\theta ))\end{aligned}}}
  

where 
  
    
      
        Ψ
        (
        θ
        )
      
    
    {\displaystyle \Psi (\theta )}
  
 is the digamma function. For the two-parameter case, for 
  
    
      
        α
        ≠
        0
      
    
    {\displaystyle \alpha \neq 0}
  
, the expected number of occupied tables is

  
    
      
        
          
            
              
                
                  
                    
                      (
                      θ
                      +
                      α
                      
                        )
                        
                          
                            n
                            ¯
                          
                        
                      
                    
                    
                      α
                      (
                      θ
                      +
                      1
                      
                        )
                        
                          
                            
                              n
                              −
                              1
                            
                            ¯
                          
                        
                      
                    
                  
                
                −
                
                  
                    θ
                    α
                  
                
                ,
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\frac {(\theta +\alpha )^{\overline {n}}}{\alpha (\theta +1)^{\overline {n-1}}}}-{\frac {\theta }{\alpha }},\end{aligned}}}
  

where 
  
    
      
        
          x
          
            
              m
              ¯
            
          
        
      
    
    {\displaystyle x^{\overline {m}}}
  
 is the rising factorial (as defined above).


=== The Dirichlet-categorical model ===
For the parameter choice 
  
    
      
        α
        <
        0
      
    
    {\displaystyle \alpha <0}
  
 and 
  
    
      
        θ
        =
        −
        L
        α
      
    
    {\displaystyle \theta =-L\alpha }
  
, where 
  
    
      
        L
        ∈
        {
        1
        ,
        2
        ,
        3
        ,
        …
        }
      
    
    {\displaystyle L\in \{1,2,3,\ldots \}}
  
, the two-parameter Chinese restaurant process is equivalent to the Dirichlet-categorical model, which is a hierarchical model that can be defined as follows. Notice that for this parameter setting, the probability of occupying a new table, when there are already 
  
    
      
        L
      
    
    {\displaystyle L}
  
 occupied tables, is zero; so that the number of occupied tables is upper bounded by 
  
    
      
        L
      
    
    {\displaystyle L}
  
. If we choose to identify tables with labels that take values in 
  
    
      
        {
        1
        ,
        2
        ,
        …
        ,
        L
        }
      
    
    {\displaystyle \{1,2,\ldots ,L\}}
  
, then to generate a random partition of the set 
  
    
      
        [
        n
        ]
        =
        {
        1
        ,
        2
        ,
        …
        ,
        n
        }
      
    
    {\displaystyle [n]=\{1,2,\ldots ,n\}}
  
, the hierarchical model first draws a categorical label distribution, 
  
    
      
        
          p
        
        =
        (
        
          p
          
            1
          
        
        ,
        
          p
          
            2
          
        
        ,
        …
        ,
        
          p
          
            L
          
        
        )
      
    
    {\displaystyle \mathbf {p} =(p_{1},p_{2},\ldots ,p_{L})}
  
 from the symmetric Dirichlet distribution, with concentration parameter 
  
    
      
        γ
        =
        −
        α
        >
        0
      
    
    {\displaystyle \gamma =-\alpha >0}
  
. Then, independently for each of the 
  
    
      
        n
      
    
    {\displaystyle n}
  
 customers, the table label is drawn from the categorical 
  
    
      
        
          p
        
      
    
    {\displaystyle \mathbf {p} }
  
. Since the Dirichlet distribution is conjugate to the categorical, the hidden variable 
  
    
      
        
          p
        
      
    
    {\displaystyle \mathbf {p} }
  
 can be marginalized out to obtain the posterior predictive distribution for the next label state, 
  
    
      
        
          ℓ
          
            n
            +
            1
          
        
      
    
    {\displaystyle \ell _{n+1}}
  
, given 
  
    
      
        n
      
    
    {\displaystyle n}
  
 previous labels

  
    
      
        P
        (
        
          ℓ
          
            n
            +
            1
          
        
        =
        i
        ∣
        
          ℓ
          
            1
          
        
        ,
        …
        ,
        
          ℓ
          
            n
          
        
        )
        =
        
          
            
              γ
              +
              
                |
                
                  
                    b
                    
                      i
                    
                  
                
                |
              
            
            
              L
              γ
              +
              n
            
          
        
      
    
    {\displaystyle P(\ell _{n+1}=i\mid \ell _{1},\ldots ,\ell _{n})={\frac {\gamma +\left|{b_{i}}\right|}{L\gamma +n}}}
  

where 
  
    
      
        
          |
          
            
              b
              
                i
              
            
          
          |
        
        ≥
        0
      
    
    {\displaystyle \left|{b_{i}}\right|\geq 0}
  
 is the number of customers that are already seated at table 
  
    
      
        i
      
    
    {\displaystyle i}
  
. With 
  
    
      
        α
        =
        −
        γ
      
    
    {\displaystyle \alpha =-\gamma }
  
 and 
  
    
      
        θ
        =
        L
        γ
      
    
    {\displaystyle \theta =L\gamma }
  
, this agrees with the above general formula, 
  
    
      
        
          
            
              
                |
              
              
                b
                
                  i
                
              
              
                |
              
              −
              α
            
            
              n
              +
              θ
            
          
        
      
    
    {\displaystyle {\frac {|b_{i}|-\alpha }{n+\theta }}}
  
, for the probability of sitting at an occupied table when 
  
    
      
        
          |
        
        
          b
          
            i
          
        
        
          |
        
        ≥
        1
      
    
    {\displaystyle |b_{i}|\geq 1}
  
. The probability for sitting at any of the 
  
    
      
        L
        −
        
          |
        
        B
        
          |
        
      
    
    {\displaystyle L-|B|}
  
 unoccupied tables, also agrees with the general formula and is given by

  
    
      
        
          ∑
          
            i
            :
            
              |
            
            
              b
              
                i
              
            
            
              |
            
            =
            0
          
        
        P
        (
        
          ℓ
          
            n
            +
            1
          
        
        =
        i
        ∣
        
          ℓ
          
            1
          
        
        ,
        …
        ,
        
          ℓ
          
            n
          
        
        )
        =
        
          
            
              (
              L
              −
              
                |
              
              B
              
                |
              
              )
              γ
            
            
              n
              +
              L
              γ
            
          
        
        =
        
          
            
              θ
              +
              
                |
              
              B
              
                |
              
              α
            
            
              n
              +
              θ
            
          
        
      
    
    {\displaystyle \sum _{i:|b_{i}|=0}P(\ell _{n+1}=i\mid \ell _{1},\ldots ,\ell _{n})={\frac {(L-|B|)\gamma }{n+L\gamma }}={\frac {\theta +|B|\alpha }{n+\theta }}}
  

The marginal probability for the labels is given by

  
    
      
        P
        (
        
          ℓ
          
            1
          
        
        ,
        …
        ,
        
          ℓ
          
            n
          
        
        )
        =
        P
        (
        
          ℓ
          
            1
          
        
        )
        
          ∏
          
            t
            =
            1
          
          
            n
            −
            1
          
        
        P
        (
        
          ℓ
          
            t
            +
            1
          
        
        ∣
        
          ℓ
          
            1
          
        
        ,
        …
        ,
        
          ℓ
          
            t
          
        
        )
        =
        
          
            
              
                ∏
                
                  i
                  =
                  1
                
                
                  L
                
              
              
                γ
                
                  
                    
                      |
                      
                        
                          b
                          
                            i
                          
                        
                      
                      |
                    
                    ¯
                  
                
              
            
            
              (
              L
              γ
              
                )
                
                  
                    n
                    ¯
                  
                
              
            
          
        
      
    
    {\displaystyle P(\ell _{1},\ldots ,\ell _{n})=P(\ell _{1})\prod _{t=1}^{n-1}P(\ell _{t+1}\mid \ell _{1},\ldots ,\ell _{t})={\frac {\prod _{i=1}^{L}\gamma ^{\overline {\left|{b_{i}}\right|}}}{(L\gamma )^{\overline {n}}}}}
  

where 
  
    
      
        P
        (
        
          ℓ
          
            1
          
        
        )
        =
        
          
            1
            L
          
        
      
    
    {\displaystyle P(\ell _{1})={\frac {1}{L}}}
  
 and 
  
    
      
        
          x
          
            
              m
              ¯
            
          
        
        =
        
          ∏
          
            i
            =
            0
          
          
            m
            −
            1
          
        
        (
        x
        +
        i
        )
      
    
    {\displaystyle x^{\overline {m}}=\prod _{i=0}^{m-1}(x+i)}
  
 is the rising factorial. In general, there are however multiple label states that all correspond to the same partition. For a given partition, 
  
    
      
        B
      
    
    {\displaystyle B}
  
, which has 
  
    
      
        
          |
          B
          |
        
        ≤
        L
      
    
    {\displaystyle \left|B\right|\leq L}
  
 blocks, the number of label states that all correspond to this partition is given by the falling factorial, 
  
    
      
        
          L
          
            
              
                |
                B
                |
              
              _
            
          
        
        =
        
          ∏
          
            i
            =
            0
          
          
            
              |
              B
              |
            
            −
            1
          
        
        (
        L
        −
        i
        )
      
    
    {\displaystyle L^{\underline {\left|B\right|}}=\prod _{i=0}^{\left|B\right|-1}(L-i)}
  
. Taking this into account, the probability for the partition is

  
    
      
        
          Pr
        
        (
        
          B
          
            n
          
        
        =
        B
        ∣
        γ
        ,
        L
        )
        =
        
          L
          
            
              
                |
                B
                |
              
              _
            
          
        
        
        
          
            
              
                ∏
                
                  i
                  =
                  1
                
                
                  L
                
              
              
                γ
                
                  
                    
                      |
                      
                        
                          b
                          
                            i
                          
                        
                      
                      |
                    
                    ¯
                  
                
              
            
            
              (
              L
              γ
              
                )
                
                  
                    n
                    ¯
                  
                
              
            
          
        
      
    
    {\displaystyle {\text{Pr}}(B_{n}=B\mid \gamma ,L)=L^{\underline {\left|B\right|}}\,{\frac {\prod _{i=1}^{L}\gamma ^{\overline {\left|{b_{i}}\right|}}}{(L\gamma )^{\overline {n}}}}}
  

which can be verified to agree with the general version of the partition probability that is given above in terms of the Pochhammer k-symbol. Notice again, that if 
  
    
      
        B
      
    
    {\displaystyle B}
  
 is outside of the support, i.e. 
  
    
      
        
          |
        
        B
        
          |
        
        >
        L
      
    
    {\displaystyle |B|>L}
  
, the falling factorial, 
  
    
      
        
          L
          
            
              
                
                  |
                
                B
                
                  |
                
              
              _
            
          
        
      
    
    {\displaystyle L^{\underline {|B|}}}
  
 evaluates to zero as it should. (Practical implementations that evaluate the log probability for partitions via  
  
    
      
        log
        ⁡
        
          L
          
            
              
                
                  |
                
                B
                
                  |
                
              
              _
            
          
        
        =
        log
        ⁡
        
          |
          
            Γ
            (
            L
            +
            1
            )
          
          |
        
        −
        log
        ⁡
        
          |
          
            Γ
            (
            L
            +
            1
            −
            
              |
            
            B
            
              |
            
            )
          
          |
        
      
    
    {\displaystyle \log L^{\underline {|B|}}=\log \left|\Gamma (L+1)\right|-\log \left|\Gamma (L+1-|B|)\right|}
  
 will return 
  
    
      
        −
        ∞
      
    
    {\displaystyle -\infty }
  
, whenever 
  
    
      
        
          |
        
        B
        
          |
        
        >
        L
      
    
    {\displaystyle |B|>L}
  
, as required.)  


==== Relationship between Dirichlet-categorical and one-parameter CRP ====
Consider on the one hand, the one-parameter Chinese restaurant process, with 
  
    
      
        α
        =
        0
      
    
    {\displaystyle \alpha =0}
  
 and 
  
    
      
        θ
        >
        0
      
    
    {\displaystyle \theta >0}
  
, which we denote 
  
    
      
        
          CRP
        
        (
        α
        =
        0
        ,
        θ
        )
      
    
    {\displaystyle {\text{CRP}}(\alpha =0,\theta )}
  
; and on the other hand the Dirichlet-categorical model with 
  
    
      
        L
      
    
    {\displaystyle L}
  
 a positive integer and where we choose 
  
    
      
        γ
        =
        
          
            θ
            L
          
        
      
    
    {\displaystyle \gamma ={\frac {\theta }{L}}}
  
, which as shown above, is equivalent to 
  
    
      
        
          CRP
        
        (
        α
        =
        −
        
          
            θ
            L
          
        
        ,
        θ
        )
      
    
    {\displaystyle {\text{CRP}}(\alpha =-{\frac {\theta }{L}},\theta )}
  
. This shows that the Dirichlet-categorical model can be made arbitrarily close to 
  
    
      
        
          CRP
        
        (
        0
        ,
        θ
        )
      
    
    {\displaystyle {\text{CRP}}(0,\theta )}
  
, by making 
  
    
      
        L
      
    
    {\displaystyle L}
  
 large.


=== Stick-breaking process ===
The two-parameter Chinese restaurant process can equivalently be defined in terms of a stick-breaking process. For the case where 
  
    
      
        0
        ≤
        α
        <
        1
      
    
    {\displaystyle 0\leq \alpha <1}
  
 and 
  
    
      
        θ
        >
        −
        α
      
    
    {\displaystyle \theta >-\alpha }
  
, the stick breaking process can be described as a hierarchical model, much like the above Dirichlet-categorical model, except that there is an infinite number of label states. The table labels are drawn independently from the infinite categorical distribution 
  
    
      
        
          p
        
        =
        (
        
          p
          
            1
          
        
        ,
        
          p
          
            2
          
        
        ,
        …
        )
      
    
    {\displaystyle \mathbf {p} =(p_{1},p_{2},\ldots )}
  
, the components of which are sampled using stick breaking: start with a stick of length 1 and randomly break it in two, the length of the left half is 
  
    
      
        
          p
          
            1
          
        
      
    
    {\displaystyle p_{1}}
  
 and the right half is broken again recursively to give 
  
    
      
        
          p
          
            2
          
        
        ,
        
          p
          
            3
          
        
        ,
        …
      
    
    {\displaystyle p_{2},p_{3},\ldots }
  
. More precisely, the left fraction, 
  
    
      
        
          f
          
            k
          
        
      
    
    {\displaystyle f_{k}}
  
, of the 
  
    
      
        k
      
    
    {\displaystyle k}
  
-th break is sampled from the beta distribution: 

  
    
      
        
          f
          
            k
          
        
        ∼
        B
        (
        1
        −
        α
        ,
        θ
        +
        k
        α
        )
        ,
        
        
          for 
        
        k
        ≥
        1
        
           and 
        
        0
        ≤
        α
        <
        1
      
    
    {\displaystyle f_{k}\sim B(1-\alpha ,\theta +k\alpha ),\;{\text{for }}k\geq 1{\text{ and }}0\leq \alpha <1}
  

The categorical probabilities are:

  
    
      
        
          p
          
            k
          
        
        =
        
          f
          
            k
          
        
        
          ∏
          
            i
            =
            1
          
          
            k
            −
            1
          
        
        (
        1
        −
        
          f
          
            k
          
        
        )
        ,
        
        
          where the empty product evaluates to one.
        
      
    
    {\displaystyle p_{k}=f_{k}\prod _{i=1}^{k-1}(1-f_{k}),\;{\text{where the empty product evaluates to one.}}}
  

For the parameter settings 
  
    
      
        α
        <
        0
      
    
    {\displaystyle \alpha <0}
  
 and 
  
    
      
        θ
        =
        −
        α
        L
      
    
    {\displaystyle \theta =-\alpha L}
  
, where 
  
    
      
        L
      
    
    {\displaystyle L}
  
 is a positive integer, and where the categorical is finite: 
  
    
      
        
          p
        
        =
        (
        
          p
          
            1
          
        
        ,
        …
        ,
        
          p
          
            L
          
        
        )
      
    
    {\displaystyle \mathbf {p} =(p_{1},\ldots ,p_{L})}
  
, we can sample 
  
    
      
        
          p
        
      
    
    {\displaystyle \mathbf {p} }
  
 from an ordinary Dirchlet distribution as explained above, but it can also be sampled with a truncated stick-breaking recipe, where the formula for sampling the fractions is modified to:

  
    
      
        
          f
          
            k
          
        
        ∼
        B
        (
        −
        α
        ,
        θ
        +
        k
        α
        )
        ,
        
        
          for 
        
        1
        ≤
        k
        ≤
        L
        −
        1
        
           and 
        
        α
        <
        0
      
    
    {\displaystyle f_{k}\sim B(-\alpha ,\theta +k\alpha ),\;{\text{for }}1\leq k\leq L-1{\text{ and }}\alpha <0}
  

and 
  
    
      
        
          f
          
            L
          
        
        =
        1
      
    
    {\displaystyle f_{L}=1}
  
.


== The Indian buffet process ==
It is possible to adapt the model such that each data point is no longer uniquely associated with a class (i.e., we are no longer constructing a partition), but may be associated with any combination of the classes. This strains the restaurant-tables analogy and so is instead likened to a process in which a series of diners samples from some subset of an infinite selection of dishes on offer at a buffet. The probability that a particular diner samples a particular dish is proportional to the popularity of the dish among diners so far, and in addition the diner may sample from the untested dishes. This has been named the Indian buffet process
and can be used to infer latent features in data.


== Applications ==
The Chinese restaurant process is closely connected to Dirichlet processes and Pólya's urn scheme, and therefore useful in applications of Bayesian statistics including nonparametric Bayesian methods. The Generalized Chinese Restaurant Process is closely related to Pitman–Yor process. These processes have been used in many applications, including modeling text, clustering biological microarray data, biodiversity modelling, and image reconstruction 


== See also ==
Ewens sampling formula
Preferential attachment
Hilbert's paradox of the Grand Hotel


== References ==


== External links ==
Introduction to the Dirichlet Distribution and Related Processes by Frigyik, Kapila and Gupta
A talk by Michael I. Jordan on the CRP:
http://videolectures.net/icml05_jordan_dpcrp/