In machine learning, semantic analysis of a text corpus is the task of building structures that approximate concepts from a large set of documents. It generally does not involve prior semantic understanding of the documents.
Semantic analysis strategies include:

Metalanguages based on first-order logic, which can analyze the speech of humans.
Understanding the semantics of a text is symbol grounding: if language is grounded, it is equal to recognizing a machine-readable meaning. For the restricted domain of spatial analysis, a computer-based language understanding system was demonstrated.
Latent semantic analysis (LSA), a class of techniques where documents are represented as vectors in a term space. A prominent example is probabilistic latent semantic analysis (PLSA).
Latent Dirichlet allocation, which involves attributing document terms to topics.
n-grams and hidden Markov models, which work by representing the term stream as a Markov chain, in which each term is derived from preceding terms.


== See also ==
Explicit semantic analysis
Information extraction
Semantic similarity
Stochastic semantic analysis
Ontology learning


== References ==