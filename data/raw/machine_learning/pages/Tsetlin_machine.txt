A Tsetlin machine is an artificial intelligence algorithm based on propositional logic.


== Background ==
A Tsetlin machine is a form of learning automaton collective for learning patterns using propositional logic. Ole-Christoffer Granmo created and gave the method its name after Michael Lvovitch Tsetlin, who invented the Tsetlin automaton and worked on Tsetlin automata collectives and games. Collectives of Tsetlin automata were originally constructed, implemented, and studied theoretically by Vadim Stefanuk in 1962.
The Tsetlin machine uses computationally simpler and more efficient primitives compared to more ordinary artificial neural networks.
As of April 2018 it has shown promising results on a number of test sets.


== Types ==
Original Tsetlin machine
Convolutional Tsetlin machine
Regression Tsetlin machine
Relational Tsetlin machine
Weighted Tsetlin machine
Arbitrarily deterministic Tsetlin machine
Parallel asynchronous Tsetlin machine
Coalesced multi-output Tsetlin machine
Tsetlin machine for contextual bandit problems
Tsetlin machine autoencoder
Tsetlin machine composites: plug-and-play collaboration between specialized Tsetlin machines
Contracting Tsetlin machine with absorbing automata
Graph Tsetlin machine
Fuzzy-Pattern Tsetlin Machine


== Applications ==
Keyword spotting
Aspect-based sentiment analysis
Word-sense disambiguation
Novelty detection
Intrusion detection
Semantic relation analysis
Image analysis
Text categorization
Fake news detection
Game playing
Batteryless sensing
Recommendation systems
Word embedding
ECG analysis
Edge computing
Bayesian network learning
Federated learning


== Original Tsetlin machine ==
 


=== Tsetlin automaton ===
The Tsetlin automaton is the fundamental learning unit of the Tsetlin machine. It tackles the multi-armed bandit problem, learning the optimal action in an environment from penalties and rewards. Computationally, it can be seen as a finite-state machine (FSM) that changes its states based on the inputs. The FSM will generate its outputs based on the current states. 
A quintuple describes a two-action Tsetlin automaton:

  
    
      
        {
        
          
            Φ
            _
          
        
        ,
        
          
            α
            _
          
        
        ,
        
          
            β
            _
          
        
        ,
        F
        (
        ⋅
        ,
        ⋅
        )
        ,
        G
        (
        ⋅
        )
        }
        .
      
    
    {\displaystyle \{{\underline {\Phi }},{\underline {\alpha }},{\underline {\beta }},F(\cdot ,\cdot ),G(\cdot )\}.}
  

A Tsetlin automaton has 
  
    
      
        2
        n
      
    
    {\displaystyle 2n}
  
 states, here 6:

  
    
      
        
          
            Φ
            _
          
        
        =
        {
        
          ϕ
          
            1
          
        
        ,
        
          ϕ
          
            2
          
        
        ,
        
          ϕ
          
            3
          
        
        ,
        
          ϕ
          
            4
          
        
        ,
        
          ϕ
          
            5
          
        
        ,
        
          ϕ
          
            6
          
        
        }
      
    
    {\displaystyle {\underline {\Phi }}=\{\phi _{1},\phi _{2},\phi _{3},\phi _{4},\phi _{5},\phi _{6}\}}
  

The FSM can be triggered by two input events

  
    
      
        
          
            β
            _
          
        
        =
        {
        
          β
          
            
              P
              e
              n
              a
              l
              t
              y
            
          
        
        ,
        
          β
          
            
              R
              e
              w
              a
              r
              d
            
          
        
        }
      
    
    {\displaystyle {\underline {\beta }}=\{\beta _{\mathrm {Penalty} },\beta _{\mathrm {Reward} }\}}
  

The rules of state migration of the FSM are stated as

  
    
      
        F
        (
        
          ϕ
          
            u
          
        
        ,
        
          β
          
            v
          
        
        )
        =
        
          
            {
            
              
                
                  
                    ϕ
                    
                      u
                      +
                      1
                    
                  
                  ,
                
                
                  
                    if
                  
                   
                  1
                  ≤
                  u
                  ≤
                  3
                   
                  
                    and
                  
                   
                  v
                  =
                  
                    Penalty
                  
                
              
              
                
                  
                    ϕ
                    
                      u
                      −
                      1
                    
                  
                  ,
                
                
                  
                    if
                  
                   
                  4
                  ≤
                  u
                  ≤
                  6
                   
                  
                    and
                  
                   
                  v
                  =
                  
                    Penalty
                  
                
              
              
                
                  
                    ϕ
                    
                      u
                      −
                      1
                    
                  
                  ,
                
                
                  
                    if
                  
                   
                  1
                  <
                  u
                  ≤
                  3
                   
                  
                    and
                  
                   
                  v
                  =
                  
                    Reward
                  
                
              
              
                
                  
                    ϕ
                    
                      u
                      +
                      1
                    
                  
                  ,
                
                
                  
                    if
                  
                   
                  4
                  ≤
                  u
                  <
                  6
                   
                  
                    and
                  
                   
                  v
                  =
                  
                    Reward
                  
                
              
              
                
                  
                    ϕ
                    
                      u
                    
                  
                  ,
                
                
                  
                    otherwise
                  
                  .
                
              
            
            
          
        
      
    
    {\displaystyle F(\phi _{u},\beta _{v})={\begin{cases}\phi _{u+1},&{\text{if}}~1\leq u\leq 3~{\text{and}}~v={\text{Penalty}}\\\phi _{u-1},&{\text{if}}~4\leq u\leq 6~{\text{and}}~v={\text{Penalty}}\\\phi _{u-1},&{\text{if}}~1<u\leq 3~{\text{and}}~v={\text{Reward}}\\\phi _{u+1},&{\text{if}}~4\leq u<6~{\text{and}}~v={\text{Reward}}\\\phi _{u},&{\text{otherwise}}.\end{cases}}}
  

It includes two output actions

  
    
      
        
          
            α
            _
          
        
        =
        {
        
          α
          
            1
          
        
        ,
        
          α
          
            2
          
        
        }
      
    
    {\displaystyle {\underline {\alpha }}=\{\alpha _{1},\alpha _{2}\}}
  

Which can be generated by the algorithm

  
    
      
        G
        (
        
          ϕ
          
            u
          
        
        )
        =
        
          
            {
            
              
                
                  
                    α
                    
                      1
                    
                  
                  ,
                
                
                  
                    if
                  
                   
                  1
                  ≤
                  u
                  ≤
                  3
                
              
              
                
                  
                    α
                    
                      2
                    
                  
                  ,
                
                
                  
                    if
                  
                   
                  4
                  ≤
                  u
                  ≤
                  6.
                
              
            
            
          
        
      
    
    {\displaystyle G(\phi _{u})={\begin{cases}\alpha _{1},&{\text{if}}~1\leq u\leq 3\\\alpha _{2},&{\text{if}}~4\leq u\leq 6.\end{cases}}}
  


=== Boolean input ===
A basic Tsetlin machine takes a vector 
  
    
      
        X
        =
        [
        
          x
          
            1
          
        
        ,
        …
        ,
        
          x
          
            o
          
        
        ]
      
    
    {\displaystyle X=[x_{1},\ldots ,x_{o}]}
  
 of o Boolean features as input, to be classified into one of two classes, 
  
    
      
        y
        =
        0
      
    
    {\displaystyle y=0}
  
 or 
  
    
      
        y
        =
        1
      
    
    {\displaystyle y=1}
  
. Together with their negated counterparts, 
  
    
      
        
          
            
              
                x
                ¯
              
            
          
          
            k
          
        
        =
        
          ¬
        
        
          
            x
          
          
            k
          
        
        =
        1
        −
        
          x
          
            k
          
        
      
    
    {\displaystyle {\bar {x}}_{k}={\lnot }{x}_{k}=1-x_{k}}
  
, the features form a literal set 
  
    
      
        L
        =
        {
        
          x
          
            1
          
        
        ,
        …
        ,
        
          x
          
            o
          
        
        ,
        
          
            
              
                x
                ¯
              
            
          
          
            1
          
        
        ,
        …
        ,
        
          
            
              
                x
                ¯
              
            
          
          
            o
          
        
        }
      
    
    {\displaystyle L=\{x_{1},\ldots ,x_{o},{\bar {x}}_{1},\ldots ,{\bar {x}}_{o}\}}
  
.


=== Clause computing module ===
A Tsetlin machine pattern is formulated as a conjunctive clause 
  
    
      
        
          C
          
            j
          
        
      
    
    {\displaystyle C_{j}}
  
, formed by ANDing a subset 
  
    
      
        
          L
          
            j
          
        
        
          ⊆
        
        L
      
    
    {\displaystyle L_{j}{\subseteq }L}
  
 of the literal set:
     
  
    
      
        
          C
          
            j
          
        
        (
        X
        )
        =
        
          ⋀
          
            
              l
            
            
              ∈
            
            
              L
              
                j
              
            
          
        
        l
        =
        
          ∏
          
            
              l
            
            
              ∈
            
            
              L
              
                j
              
            
          
        
        l
      
    
    {\displaystyle C_{j}(X)=\bigwedge _{{l}{\in }L_{j}}l=\prod _{{l}{\in }L_{j}}l}
  
.
For example, the clause 
  
    
      
        
          C
          
            j
          
        
        (
        X
        )
        =
        
          x
          
            1
          
        
        ∧
        
          ¬
        
        
          x
          
            2
          
        
        =
        
          x
          
            1
          
        
        
          
            
              
                x
                ¯
              
            
          
          
            2
          
        
      
    
    {\displaystyle C_{j}(X)=x_{1}\land {\lnot }x_{2}=x_{1}{\bar {x}}_{2}}
  
 consists of the literals 
  
    
      
        
          L
          
            j
          
        
        =
        {
        
          x
          
            1
          
        
        ,
        
          
            
              
                x
                ¯
              
            
          
          
            2
          
        
        }
      
    
    {\displaystyle L_{j}=\{x_{1},{\bar {x}}_{2}\}}
  
 and outputs 1 iff 
  
    
      
        
          x
          
            1
          
        
        =
        1
      
    
    {\displaystyle x_{1}=1}
  
 and  
  
    
      
        
          x
          
            2
          
        
        =
        0
      
    
    {\displaystyle x_{2}=0}
  
.


=== Summation and thresholding module ===
The number of clauses employed is a user-configurable parameter n. Half of the clauses are assigned positive polarity. The other half is assigned negative polarity. The clause outputs, in turn, are combined into a classification decision through summation and thresholding using the unit step function 
  
    
      
        u
        (
        v
        )
        =
        1
         
        
          if
        
         
        v
        ≥
        0
         
        
          else
        
         
        0
      
    
    {\displaystyle u(v)=1~{\text{if}}~v\geq 0~{\text{else}}~0}
  
:

  
    
      
        
          
            
              y
              ^
            
          
        
        =
        u
        
          (
          
            
              ∑
              
                j
                =
                1
              
              
                n
                
                  /
                
                2
              
            
            
              C
              
                j
              
              
                +
              
            
            (
            X
            )
            −
            
              ∑
              
                j
                =
                1
              
              
                n
                
                  /
                
                2
              
            
            
              C
              
                j
              
              
                −
              
            
            (
            X
            )
          
          )
        
        .
      
    
    {\displaystyle {\hat {y}}=u\left(\sum _{j=1}^{n/2}C_{j}^{+}(X)-\sum _{j=1}^{n/2}C_{j}^{-}(X)\right).}
  

In other words, classification is based on a majority vote, with the positive clauses voting for 
  
    
      
        y
        =
        1
      
    
    {\displaystyle y=1}
  
 and the negative for 
  
    
      
        y
        =
        0
      
    
    {\displaystyle y=0}
  
. The classifier
     
  
    
      
        
          
            
              y
              ^
            
          
        
        =
        u
        
          (
          
            
              x
              
                1
              
            
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                2
              
            
            +
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                1
              
            
            
              x
              
                2
              
            
            −
            
              x
              
                1
              
            
            
              x
              
                2
              
            
            −
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                1
              
            
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                2
              
            
          
          )
        
      
    
    {\displaystyle {\hat {y}}=u\left(x_{1}{\bar {x}}_{2}+{\bar {x}}_{1}x_{2}-x_{1}x_{2}-{\bar {x}}_{1}{\bar {x}}_{2}\right)}
  
,
for instance, captures the XOR-relation.


=== Feedback module ===


==== Type I feedback ====


==== Type II feedback ====


==== Resource allocation ====
Resource allocation dynamics ensure that clauses distribute themselves across the frequent patterns, rather than missing some and overconcentrating on others. That is, for any input X, the probability of reinforcing a clause gradually drops to zero as the clause output sum

  
    
      
        v
        =
        
          ∑
          
            j
            =
            1
          
          
            n
            
              /
            
            2
          
        
        
          C
          
            j
          
          
            +
          
        
        (
        X
        )
        −
        
          ∑
          
            j
            =
            1
          
          
            n
            
              /
            
            2
          
        
        
          C
          
            j
          
          
            −
          
        
        (
        X
        )
      
    
    {\displaystyle v=\sum _{j=1}^{n/2}C_{j}^{+}(X)-\sum _{j=1}^{n/2}C_{j}^{-}(X)}
  

approaches a user-set target T for 
  
    
      
        y
        =
        1
      
    
    {\displaystyle y=1}
  
 (
  
    
      
        −
        T
      
    
    {\displaystyle -T}
  
 for 
  
    
      
        y
        =
        0
      
    
    {\displaystyle y=0}
  
).
If a clause is not reinforced, it does not give feedback to its Tsetlin automata, and these are thus left unchanged.  In the extreme, when the voting sum v equals or exceeds the target T (the Tsetlin Machine has successfully recognized the input X), no clauses are reinforced. Accordingly, they are free to learn new patterns, naturally balancing the pattern representation resources.


== Implementations ==


=== Software ===
Tsetlin Machine in C, Python, multithreaded Python, CUDA, Julia (programming language)
Convolutional Tsetlin Machine
Weighted Tsetlin Machine in C++


=== Hardware ===
One of the first FPGA-based hardware implementation of the Tsetlin Machine on the Iris flower data set was developed by the μSystems (microSystems) Research Group at Newcastle University.
They also presented the first ASIC implementation of the Tsetlin Machine focusing on energy frugality, claiming it could deliver 10 trillion operation per Joule. The ASIC design had demoed on DATA2020.


== Further reading ==


=== Books ===
An Introduction to Tsetlin Machines


=== Conferences ===
International Symposium on the Tsetlin Machine (ISTM)


=== Videos ===
Tsetlin Machine—A new paradigm for pervasive AI
Keyword Spotting Using Tsetlin Machines
IOLTS Presentation: Explainability and Dependability Analysis of Learning Automata based AI hardware
FPGA and uC co-design: Tsetlin Machine on Iris demo
The-Ruler-of-Tsetlin-Automaton
Interpretable clustering and dimension reduction with Tsetlin automata machine learning.
Predicting and explaining economic growth using real-time interpretable learning
Early detection of breast cancer from a simple blood test
Recent advances in Tsetlin Machines


=== Papers ===
On the Convergence of Tsetlin Machines for the XOR Operator
Learning Automata based Energy-efficient AI Hardware Design for IoT Applications
On the Convergence of Tsetlin Machines for the IDENTITY- and NOT Operators
The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic


=== Publications/news/articles ===
A low-power AI alternative to neural networks
Can a Norwegian invention revolutionise artificial intelligence?


== References ==