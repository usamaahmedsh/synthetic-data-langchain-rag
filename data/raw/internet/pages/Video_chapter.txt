Video chapters on online video platforms divide the videos into sections, with each section having a specific "chapter title", most notably YouTube. Most services offer a manual way to add chapter sections and title them, several platforms also offer automatic tools for this. The purpose is to aid the navigation of the video as well as to encourage video creators to structure the videos coherently. Both of these goals aid users in general, and in particular can be beneficial to persons with disabilities.
Online learning platforms - such as Coursera - were some of the early adopters of chapters marks in the videos that form part of their curricula as a way to aid navigation, and convey the structure of the lectures and their subject matter.


== Accessibility ==
As with many other forms of structured (meta) data, video chapters can improve web accessibility. In particular, it can help persons with disabilities such as visual and hearing impairments. Also as with many other forms of structured (meta) data, the advantages to persons with disabilities are a function of the quality of the metadata (poor quality can instead be detrimental).


== Automatic generation ==
Several online platforms offer automatic generation of chapters, including the detection of the segments, and the labeling of the segments with chapter titles. Video chapter generation as a machine learning problem statement is also conducted academically.


=== Open-source models ===
Several open-source models for automatic segmentation have been described. Video segmentation information is typically processed by means of large language models, or combined with video Optical character recognition information, detecting the largest text in a slide (typically the title), to be used as the chapter title.


== Video editor support ==
Several (offline) video editors such as Final Cut Pro, Adobe Premiere Pro, Shotcut, and OpenShot have support for chapter marks, that can directly be directly uploaded to online video platforms.


== See also ==
Vimeo
Microsoft Stream


== References ==